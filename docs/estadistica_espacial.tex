% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  spanish,
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Estadística Espacial con R},
  pdfauthor={Rubén Fernández Casal (MODES, CITIC, UDC; ruben.fcasal@udc.es); Tomás Cotos Yáñez (SIDOR, UVIGO; cotos@uvigo.es)},
  pdflang={es},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\usepackage[a4paper, top=3.25cm, bottom=2.5cm, left=3cm, right=2.5cm]{geometry}
%\usepackage{animate}
%\usepackage{fontspec}
%\setmainfont{Arial}
% Espacio después de teorema
% https://tex.stackexchange.com/questions/37797/theorem-environment-line-break-after-label
\newtheoremstyle{break}
  {\topsep}{\topsep}%
  {\itshape}{}%
  {\bfseries}{}%
  {\newline}%
  {}%

\theoremstyle{break}

\ifxetex
  \usepackage{polyglossia}
  \setmainlanguage{spanish}
  % Tabla en lugar de cuadro
  \gappto\captionsspanish{\renewcommand{\tablename}{Tabla}
          \renewcommand{\listtablename}{Índice de tablas}}

\else
  \usepackage[spanish,es-tabla]{babel}
\fi
\makeatletter
\def\thm@space@setup{
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\ifxetex
  % Load polyglossia as late as possible: uses bidi with RTL langages (e.g. Hebrew, Arabic)
  \usepackage{polyglossia}
  \setmainlanguage[]{spanish}
\else
  \usepackage[main=spanish]{babel}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\fi
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\title{Estadística Espacial con R}
\author{Rubén Fernández Casal (MODES, CITIC, UDC; \href{mailto:ruben.fcasal@udc.es}{\nolinkurl{ruben.fcasal@udc.es}}) \and Tomás Cotos Yáñez (SIDOR, UVIGO; \href{mailto:cotos@uvigo.es}{\nolinkurl{cotos@uvigo.es}})}
\date{Edición: Enero de 2022. Impresión: 2022-11-28}

\usepackage{amsthm}
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}{Lema}[chapter]
\newtheorem{corollary}{Corolario}[chapter]
\newtheorem{proposition}{Proposición}[chapter]
\newtheorem{conjecture}{Algoritmo}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definición}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Ejemplo}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Ejercicio}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Nota: }
\newtheorem*{solution}{Solución}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{pruxf3logo}{%
\chapter*{Prólogo}\label{pruxf3logo}}
\addcontentsline{toc}{chapter}{Prólogo}

La versión actual del libro \textbf{\emph{se está desarrollando}} principalmente como apoyo a la docencia de la última parte de la asignatura de \href{https://guiadocente.udc.es/guia_docent/index.php?centre=614\&ensenyament=614G02\&assignatura=614G02022\&idioma=cast}{Análisis estadístico de datos con dependencia} del \href{https://estudos.udc.es/es/study/start/614G02V01}{Grado en Ciencia e Ingeniería de Datos} de la \href{https://www.udc.es}{UDC}.
El objetivo es que (futuras versiones del libro con contenidos adicionales) también resulte de utilidad para la docencia de la asignatura de \href{http://eamo.usc.es/pub/mte/index.php?option=com_content\&view=article\&id=2202\&idm=15\&a\%C3\%B1o=2021}{Estadística Espacial} del \href{http://eio.usc.es/pub/mte}{Máster interuniversitario en Técnicas Estadísticas}).

La teoría en este libro está basada en gran parte en la tesis doctoral:

Fernández Casal, R. (2003). \href{https://rubenfcasal.github.io/files/Geoestadistica_espacio-temporal.pdf}{\emph{Geoestadística espacio-temporal: modelos flexibles de variogramas anisotrópicos no separables}}. Tesis doctoral, Universidad de Santiago de Compostela.

donde se puede encontrar información adicional.

Este libro ha sido escrito en \href{http://rmarkdown.rstudio.com}{R-Markdown} empleando el paquete \href{https://bookdown.org/yihui/bookdown/}{\texttt{bookdown}} y está disponible en el repositorio Github: \href{https://github.com/rubenfcasal/estadistica_espacial}{rubenfcasal/estadistica\_espacial}.
Se puede acceder a la versión en línea a través del siguiente enlace:

\url{https://rubenfcasal.github.io/estadistica_espacial} (también \url{https://bit.ly/estadistica_espacial}).

donde puede descargarse en formato \href{https://rubenfcasal.github.io/estadistica_espacial/estadistica_espacial.pdf}{pdf}.

Para ejecutar los ejemplos mostrados en el libro sería necesario tener instalados los siguientes paquetes:
\href{https://CRAN.R-project.org/package=sf}{\texttt{sf}}, \href{https://CRAN.R-project.org/package=sp}{\texttt{sp}}, \href{https://CRAN.R-project.org/package=starts}{\texttt{starts}}, \href{https://CRAN.R-project.org/package=gstat}{\texttt{gstat}}, \href{https://CRAN.R-project.org/package=geoR}{\texttt{geoR}}, \href{https://CRAN.R-project.org/package=spacetime}{\texttt{spacetime}}, \href{https://CRAN.R-project.org/package=sm}{\texttt{sm}}, \href{https://CRAN.R-project.org/package=fields}{\texttt{fields}}, \href{https://CRAN.R-project.org/package=rgdal}{\texttt{rgdal}}, \href{https://CRAN.R-project.org/package=rgeos}{\texttt{rgeos}}, \href{https://CRAN.R-project.org/package=maps}{\texttt{maps}}, \href{https://CRAN.R-project.org/package=maptools}{\texttt{maptools}}, \href{https://CRAN.R-project.org/package=ggplot2}{\texttt{ggplot2}}, \href{https://CRAN.R-project.org/package=plot3D}{\texttt{plot3D}}, \href{https://CRAN.R-project.org/package=lattice}{\texttt{lattice}}, \href{https://CRAN.R-project.org/package=classInt}{\texttt{classInt}}, \href{https://CRAN.R-project.org/package=viridis}{\texttt{viridis}}, \href{https://CRAN.R-project.org/package=dplyr}{\texttt{dplyr}}, \href{https://CRAN.R-project.org/package=mapSpain}{\texttt{mapSpain}}, \href{https://CRAN.R-project.org/package=tmap}{\texttt{tmap}}, \href{https://CRAN.R-project.org/package=mapview}{\texttt{mapview}}, \href{https://CRAN.R-project.org/package=osmdata}{\texttt{osmdata}}, \href{https://CRAN.R-project.org/package=rnaturalearth}{\texttt{rnaturalearth}}, \href{https://CRAN.R-project.org/package=ncdf}{\texttt{ncdf}}, \href{https://CRAN.R-project.org/package=quadprog}{\texttt{quadprog}}, \href{https://CRAN.R-project.org/package=spam}{\texttt{spam}}, \href{https://CRAN.R-project.org/package=DEoptim}{\texttt{DEoptim}}.
Por ejemplo mediante los siguientes comandos:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pkgs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"sf"}\NormalTok{, }\StringTok{"sp"}\NormalTok{, }\StringTok{"starts"}\NormalTok{, }\StringTok{"gstat"}\NormalTok{, }\StringTok{"geoR"}\NormalTok{, }\StringTok{"spacetime"}\NormalTok{, }\StringTok{"sm"}\NormalTok{, }\StringTok{"fields"}\NormalTok{, }
          \StringTok{"rgdal"}\NormalTok{, }\StringTok{"rgeos"}\NormalTok{, }\StringTok{"maps"}\NormalTok{, }\StringTok{"maptools"}\NormalTok{, }\StringTok{"ggplot2"}\NormalTok{, }\StringTok{"plot3D"}\NormalTok{, }\StringTok{"lattice"}\NormalTok{, }
          \StringTok{"classInt"}\NormalTok{, }\StringTok{"viridis"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{, }\StringTok{"mapSpain"}\NormalTok{, }\StringTok{"tmap"}\NormalTok{, }\StringTok{"mapview"}\NormalTok{, }
          \StringTok{"osmdata"}\NormalTok{, }\StringTok{"rnaturalearth"}\NormalTok{, }\StringTok{"ncdf"}\NormalTok{, }\StringTok{"quadprog"}\NormalTok{, }\StringTok{"spam"}\NormalTok{, }\StringTok{"DEoptim"}\NormalTok{ )}

\FunctionTok{install.packages}\NormalTok{(}\FunctionTok{setdiff}\NormalTok{(pkgs, }\FunctionTok{installed.packages}\NormalTok{()[,}\StringTok{"Package"}\NormalTok{]), }\AttributeTok{dependencies =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Si aparecen errores (normalmente debidos a incompatibilidades con versiones ya instaladas), probar a ejecutar en lugar de lo anterior:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(pkgs, }\AttributeTok{dependencies=}\ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# Instala todos...}
\end{Highlighting}
\end{Shaded}

Además, para geoestadística no paramétrica se empleará el paquete \href{https://rubenfcasal.github.io/npsp}{\texttt{npsp}} \textbf{\emph{no disponible actualmente en CRAN}} (aunque esperamos que vuelva a estarlo pronto\ldots{} incluyendo soporte para el paquete \texttt{sf}).
Se puede instalar la versión de desarrollo en GitHub, siguiendo las instrucciones de la \href{https://rubenfcasal.github.io/npsp/\#installation}{web}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages("devtools")}
\NormalTok{devtools}\SpecialCharTok{::}\FunctionTok{install\_github}\NormalTok{(}\StringTok{"rubenfcasal/npsp"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Aunque al necesitar compilación los usuarios de Windows deben tener instalado previamente la versión adecuada de \href{https://cran.r-project.org/bin/windows/Rtools/}{Rtools}, y \href{https://apps.apple.com/us/app/xcode/id497799835}{Xcode} los usuarios de OS X
(para lo que se pueden seguir los pasos descritos \href{https://rubenfcasal.github.io/post/instalacion-de-r}{aquí}).
Alternativamente, los usuarios de Windows (con una versión 4.X.X de R) pueden instalar este paquete ya compilado con el siguiente código:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{\textquotesingle{}https://github.com/rubenfcasal/npsp/releases/download/v0.7{-}8/npsp\_0.7{-}8.zip\textquotesingle{}}\NormalTok{, }
                 \AttributeTok{repos =} \ConstantTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Para generar el libro (compilar) serán necesarios paquetes adicionales,
para lo que se recomendaría consultar el libro de \href{https://rubenfcasal.github.io/bookdown_intro}{``Escritura de libros con bookdown''} en castellano.

\includegraphics[width=1.22in]{images/by-nc-nd-88x31}

Este obra está bajo una licencia de \href{https://creativecommons.org/licenses/by-nc-nd/4.0/deed.es_ES}{Creative Commons Reconocimiento-NoComercial-SinObraDerivada 4.0 Internacional}
(esperamos poder liberarlo bajo una licencia menos restrictiva más adelante\ldots).

\hypertarget{intro-estesp}{%
\chapter{Introducción: Procesos espaciales y Geoestadística}\label{intro-estesp}}

Es bien sabido que al utilizar en la práctica métodos estadísticos no siempre es adecuado suponer que las observaciones del fenómeno de interés han sido tomadas bajo condiciones idénticas e independientes unas de otras (i.e.~que los datos son independientes e idénticamente distribuidos).
Esta falta de homogeneidad en los datos suele ser modelada a través de la suposición de media no constante (por ejemplo suponiendo que ésta es una combinación lineal de ciertas variables explicativas) pero con la consideración de que los errores son independientes e idénticamente distribuidos.
Sin embargo, esta suposición puede influir crucialmente en la inferencia (e.g.~ver \href{https://rubenfcasal.github.io/post/diagnosis-de-la-independencia/}{enlace}), siendo en ocasiones preferible la suposición más realista de errores correlados.

Frecuentemente los datos tienen una componente espacial y/o temporal asociada a ellos y es de esperar que datos cercanos en el espacio o en el tiempo sean más semejantes que aquellos que están más alejados; en cuyo caso no deben ser modelados como estadísticamente independientes, siendo más conveniente emplear modelos que exploten adecuadamente dicha componente espacial o espacio-temporal.
De forma natural surge la hipótesis de que los datos cercanos en el espacio o en el tiempo están correlados y que la correlación disminuye al aumentar la separación entre ellos, por lo que se puede pensar en la presencia de una dependencia espacial o espacio-temporal.
Esto da lugar al concepto de \emph{proceso espacial o espacio-temporal} (Sección \ref{proc-esp}).
La \emph{geoestadística} (Sección \ref{geoestadistica}) es una de las ramas de la estadística que se centra en el estudio de procesos de este tipo.

\begin{quote}
``\ldots{} the first law of geography: everything is related to everything else, but near things are more related than distant things''.

--- Tobler, 1970.
\end{quote}

La metodología espacial y espacio-temporal ha sido utilizada de forma creciente (especialmente durante los últimos 50 años) para resolver problemas en muchos campos.
En muchos casos interesa analizar datos que tienen asociada una componente espacial o espacio-temporal de forma natural, por ejemplo, en campos relacionados con la geología, hidrología, ecología, ciencias medioambientales, meteorología, epidemiología, recursos mineros, geografía, economía, astronomía, proceso de imágenes, experimentos agrícolas, etc.
En estas disciplinas la metodología espacial puede ser de ayuda en alguna o en muchas etapas del estudio, desde el diseño inicial del muestreo hasta la representación final de los resultados obtenidos (p.e. para la generación de mapas o animaciones).

\hypertarget{proc-esp}{%
\section{Procesos espaciales}\label{proc-esp}}

Supongamos que \(Z(\mathbf{s})\) es un valor aleatorio en la posición espacial \(\mathbf{s} \in \mathbb{R}^{d}\).
Entonces, si \(\mathbf{s}\) varía dentro del conjunto índice \(D\subset \mathbb{R}^{d}\) se obtiene el proceso espacial:
\[\left\{ Z(\mathbf{s}) : \mathbf{s} \in D \subset \mathbb{R}^{d} \right\}\]
(también se suele denominar función aleatoria, campo espacial aleatorio o variable regionalizada).
Una realización del proceso espacial se denotará por \(\left\{ z(\mathbf{s}) : \mathbf{s} \in D \right\}\), pero normalmente solo se observará \(\{z(\mathbf{s}_1), z(\mathbf{s}_2), \ldots, z(\mathbf{s}_n)\}\), una realización parcial en \(n\) posiciones espaciales.

Se suele distinguir entre distintos tipos de procesos espaciales dependiendo de las suposiciones acerca del dominio \(D\):

\begin{itemize}
\item
  \textbf{Procesos geoestadísticos} (índice espacial continuo):
  \(D\) es un subconjunto fijo que contiene un rectángulo \(d\)-dimensional de volumen
  positivo. El proceso puede ser observado de forma continua dentro del dominio.
  Un ejemplo claro sería la temperatura, aunque normalmente solo se dispone de datos en
  estaciones meteorológicas fijas, se podría observar en cualquier posición
  (y por tanto tiene sentido predecirla). {[}Figura \ref{fig:aquifer}{]}

  \begin{figure}[!htb]

  {\centering \includegraphics[width=0.7\linewidth]{01-introduccion_files/figure-latex/aquifer-1} 

  }

  \caption{Nivel del agua subterránea en 85 localizaciones del acuífero Wolfcamp (obtenidas durante un estudio sobre el posible emplazamiento de un depósito de residuos nucleares).}\label{fig:aquifer}
  \end{figure}
\item
  \textbf{Procesos reticulares/regionales} (índice espacial discreto):
  \(D\) es un conjunto numerable de posiciones o regiones. El proceso solo puede ser
  observado en determinadas posiciones. Es habitual que los datos se correspondan
  con agregaciones (totales o valores medios) de una determinada zona (por ejemplo,
  países, provincias, ayuntamientos, zonas sanitarias\ldots). Son muy comunes en
  econometría o epidemiología. {[}Figura \ref{fig:mortalidad}{]}

  \begin{figure}[!htb]

  {\centering \includegraphics[width=0.7\linewidth]{01-introduccion_files/figure-latex/mortalidad-1} 

  }

  \caption{Porcentaje de incremento de las defunciones en el año 2020 respecto al 2019 por CCAA (datos [INE](https://www.ine.es/jaxiT3/Tabla.htm?t=6546)).}\label{fig:mortalidad}
  \end{figure}
\item
  \textbf{Procesos/patrones puntuales} (índice espacial aleatorio):
  \(D\) es un proceso puntual en \(\mathbb{R}^{d}\). Las posiciones en las que se
  observa el proceso son aleatorias. En muchas casos interesa únicamente la posición
  donde se observa el evento de interés (por ejemplo la posición en la que creció
  un árbol de una determinada especie). En el caso general, además de la posición
  se podría observar alguna otra característica (una marca; por ejemplo la altura o
  el diámetro del árbol), es lo que se conoce como \emph{proceso puntual marcado}.
  Este tipo de datos son habituales en biología, ecología, criminología, etc.
  {[}Figura \ref{fig:cholera}{]}

  \begin{figure}[!htb]

  {\centering \includegraphics[width=0.7\linewidth]{01-introduccion_files/figure-latex/cholera-1} 

  }

  \caption{Mapa (de John Snow) del brote de cólera de 1854 en Londres.}\label{fig:cholera}
  \end{figure}
\end{itemize}

Nos centraremos en el caso de procesos geoestadísticos (también denominados procesos espaciales continuos).
El caso de posiciones espaciales discretas se considerará como resultado de la discretización de un proceso continuo.
Esto sería válido también para el caso espacio-temporal, por ejemplo podríamos considerar posiciones de la forma \(\mathbf{s}=(s_{1} , \ldots,s_{d-1} ,t) \in \mathbb{R}^{d-1} \times \mathbb{R}^{+,0}\), donde \(\mathbb{R}^{+,0} = \left\{ t \in \mathbb{R} : t \geq 0 \right\}\).
Por tanto, las definiciones y métodos para procesos espaciales son en principio aplicables también al caso espacio-temporal.
Sin embargo, la componente temporal presenta diferencias respecto a la componente espacial\ldots{}

\hypertarget{paquetes-r}{%
\subsection{Paquetes de R}\label{paquetes-r}}

En R hay disponibles una gran cantidad de paquetes para el análisis estadístico de datos espaciales (ver por ejemplo \href{http://cran.r-project.org/web/views/Spatial.html}{CRAN Task View: Analysis of Spatial Data}).
Entre ellos podríamos destacar:

\begin{itemize}
\item
  Procesos geoestadísticos: \texttt{gstat}, \texttt{geoR}, \texttt{geoRglm}, \texttt{fields},
  \texttt{spBayes}, \texttt{RandomFields}, \texttt{VR:spatial}, \texttt{sgeostat}, \texttt{vardiag}, \texttt{npsp}\ldots{}
\item
  Procesos reticulares/regionales: \texttt{spdep}, \texttt{DCluster}, \texttt{spgwr},
  \texttt{ade4}\ldots{}
\item
  Procesos puntuales: \texttt{spatstat}, \texttt{VR:spatial}, \texttt{splancs}\ldots{}
\end{itemize}

Algunos de estos paquetes son la referencia para el análisis de este tipo de datos,
aunque también están disponibles otros, como por ejemplo \texttt{maptools}, \texttt{geosphere}, \texttt{tmap}, \texttt{mapsf}, \texttt{leaflet}, \texttt{mapview}, \texttt{mapdeck}, \texttt{ggmap}, \texttt{rgrass7}, \texttt{RSAGA}, \texttt{RPyGeo}, \texttt{RQGIS} o \texttt{r-arcgis}, que implementan herramientas adicionales y permiten, por ejemplo, generar gráficos interactivos o interactuar con sistemas externos de información geográfica (GIS).

En todos estos paquetes se trabajan con similares tipos de datos (espaciales y espacio-temporales) por lo que se han desarrollado paquetes que facilitan su manejo.
Entre ellos destacan el paquete \href{https://CRAN.R-project.org/package=sp}{\texttt{sp}} \protect\hyperlink{ref-Bivand2013}{Bivand et~al.} (\protect\hyperlink{ref-Bivand2013}{2013}) y el paquete \href{https://r-spatial.github.io/sf}{\texttt{sf}} \protect\hyperlink{ref-Pebesma2021}{E. Pebesma y Bivand} (\protect\hyperlink{ref-Pebesma2021}{2021}).
Otros paquetes para la manipulación de datos que pueden ser de interés son: \href{https://CRAN.R-project.org/package=raster}{\texttt{raster}}, \href{https://CRAN.R-project.org/package=terra}{\texttt{terra}}, \href{https://r-spatial.github.io/stars}{\texttt{starts}}, \href{https://CRAN.R-project.org/package=rgdal}{\texttt{rgdal}} y \href{https://CRAN.R-project.org/package=rgeos}{\texttt{rgeos}}, entre otros.
En la Sección \ref{datos-tipos} se incluye información adicional sobre estos paquetes.

En este libro emplearemos principalmente el paquete \texttt{gstat} para el análisis de datos geoestadísticos (siguiente sección; aunque se incluye una introducción al paquete \texttt{geoR} en el Apéndice \ref{intro-geoR}) y el paquete \texttt{sf} para la manipulación de datos espaciales (en el Apéndice \ref{intro-sp} se incluye una breve introducción a las clases \texttt{sp} para datos espaciales).

\hypertarget{gstat-pkg}{%
\subsection{\texorpdfstring{El paquete \textbf{gstat}}{El paquete gstat}}\label{gstat-pkg}}

El paquete \href{https://r-spatial.github.io/gstat}{\texttt{gstat}} permite la modelización geoestadística (univariante, Capítulo \ref{modelado}, y multivariante, Capítulo \ref{multivar}), espacial y espacio-temporal (Capítulo \ref{esp-temp}), incluyendo predicción y simulación (Capítulo \ref{kriging} y secciones 5.X y 6.X).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gstat)}
\end{Highlighting}
\end{Shaded}

Este paquete implementa su propia estructura de datos (S3, basada en \texttt{data.frame}) pero también es compatible con los objetos \texttt{Spatial*} del paquete \texttt{sp} (Apéndice \ref{intro-sp}) y los objetos de datos de los paquetes \texttt{sf} y \texttt{stars} (Capítulo \ref{datos}).

Para más información se pueden consultar la \href{https://r-spatial.github.io/gstat/reference/index.html}{referencia}, las viñetas del paquete:

\begin{itemize}
\tightlist
\item
  \href{https://cran.r-project.org/web/packages/gstat/vignettes/gstat.pdf}{The meuse data set: a tutorial for the gstat R package},
\item
  \href{https://cran.r-project.org/web/packages/gstat/vignettes/spatio-temporal-kriging.pdf}{Spatio-Temporal Geostatistics using gstat},
\item
  \href{https://cran.r-project.org/web/packages/gstat/vignettes/st.pdf}{Introduction to Spatio-Temporal Variography},
\end{itemize}

el blog \href{https://r-spatial.org/}{r-spatial} o las correspondientes publicaciones (\href{http://www.sciencedirect.com/science/article/pii/S0098300404000676}{Pebesma, 2004}; \href{https://journal.r-project.org/archive/2016-1/na-pebesma-heuvelink.pdf}{Gräler, Pebesma y Heuvelink, 2016}).

Este paquete de R es una evolución de un programa independiente anterior con el mismo nombre (\href{http://www.sciencedirect.com/science/article/pii/S0098300497000824}{Pebesma y Wesseling, 1998}; basado en la librería \href{http://www.gslib.com}{GSLIB}, Deutsch y Journel, 1992).
Puede resultar de interés consultar el \href{http://www.gstat.org/gstat.pdf}{manual original} para información adicional sobre los detalles computacionales.

\hypertarget{geoestadistica}{%
\section{Geoestadística}\label{geoestadistica}}

La geoestadística (Matheron 1962) surgió como una mezcla de varias disciplinas: ingeniería de minas, geología, matemáticas y estadística, para dar respuesta a problemas como, por ejemplo, el de la estimación de los recursos de una explotación minera (se desarrolló principalmente a partir de los años 80).
La diferencia (ventaja) respecto a otras aproximaciones es que, además de tener en cuenta la tendencia espacial (variación de gran escala), también tiene en cuenta la correlación espacial (variación de pequeña escala).
Otros métodos sin embargo, sólo incluyen la variación de larga escala y suponen que los errores son independientes (Sección \ref{modelos-clasicos-espaciales}).
Hoy en día podemos decir que la geoestadística es la rama de la estadística espacial que estudia los procesos con índice espacial continuo.

Uno de los problemas iniciales más importantes de la geoestadística fue la predicción de la riqueza de un bloque minero a partir de una muestra observada.
A este proceso Matheron (1963) lo denominó kriging\footnote{D. G. Krige fue un ingeniero de minas de Sudáfrica que desarrolló
  en los años 50 métodos empíricos para determinar la distribución de
  la riqueza de un mineral a partir de valores observados.
  Sin embargo la formulación de la predicción espacial lineal óptima no
  procede del trabajo de Krige.
  Al mismo tiempo que la geoestadística se desarrollaba en la ingeniería
  de minas por Matheron en Francia, la misma idea se desarrollaba en la
  meteorología por L.S. Gandin en la antigua Unión Soviética.
  El nombre que Gandin le dio a esta aproximación fue análisis objetivo
  y utilizó la terminología de interpolación óptima en lugar de kriging.
  Para más detalles sobre el origen del kriging ver p.e. Cressie (1990).}, y también predicción espacial lineal óptima (estos métodos de predicción se muestran en el Capítulo \ref{kriging}).

El modelo general habitualmente considerado en geoestadística considera que el proceso se descompone en \emph{variabilidad de gran escala} y \emph{variabilidad de pequeña escala}:
\begin{equation}
  Z(\mathbf{s}) = \mu(\mathbf{s}) + \varepsilon(\mathbf{s}),
  \label{eq:modelogeneral}
\end{equation}
donde:

\begin{itemize}
\item
  \(\mu(\mathbf{s}) = E \left( Z(\mathbf{s}) \right)\) es la tendencia (función de regresión, determinística).
\item
  \(\varepsilon(\mathbf{s})\) es un proceso de error de media cero que incorpora la dependencia espacial.
\end{itemize}

Como en condiciones normales únicamente se dispone de una realización parcial del proceso, se suelen asumir hipótesis adicionales de estacionariedad sobre el proceso de error \(\varepsilon(\mathbf{s})\) para hacer posible la inferencia.
En la Sección \ref{procesos-estacionarios} se definen los principales tipos de estacionariedad habitualmente considerados en geoestadística y se introducen dos funciones relacionadas con procesos estacionarios, el covariograma y el variograma.
Algunas propiedades de estas funciones, que podríamos decir que son las herramientas fundamentales de la geoestadística, se muestran en la Sección \ref{procesos-estacionarios}.

\hypertarget{modelos-clasicos-espaciales}{%
\subsection{Modelos clásicos y modelos espaciales}\label{modelos-clasicos-espaciales}}

En general, cuando se considera que la componente espacial (o espacio-temporal) puede ser importante en el modelado y el análisis de los datos es necesaria una aproximación estadística distinta a la tradicionalmente usada.

Uno de los modelos más utilizados en estadística para el caso de datos no homogéneos es el conocido modelo clásico de regresión lineal.
Si \(\left\{ Z(\mathbf{s}):\mathbf{s}\in D\subset \mathbb{R}^{d} \right\}\) es un proceso espacial, podemos suponer que:
\begin{equation}
  Z(\mathbf{s})=\sum\limits_{j=0}^{p}X_{j}(\mathbf{s})\beta_{j} +\varepsilon(\mathbf{s}),\ \mathbf{s}\in D,
  \label{eq:modelolineal}
\end{equation}
(un caso particular del modelo general \eqref{eq:modelogeneral}), donde \(\boldsymbol{\beta }=(\beta_{0}, \ldots,\beta_{p})^{\top}\in \mathbb{R}^{p+1}\) es un vector desconocido, \(\left\{ X_{j} (\cdot):j=0, \ldots,p\right\}\) un conjunto de variables explicativas (típicamente \(X_0(\cdot)=1\)) y \(\varepsilon(\cdot)\) un proceso de media cero incorrelado (i.e.~\(Cov(\varepsilon (\mathbf{u}),\varepsilon (\mathbf{v}))=0\) si \(\mathbf{u}\neq \mathbf{v}\)) con \(Var(\varepsilon (\mathbf{s}))=\sigma^{2}\).

Supongamos por el momento que el objetivo es la estimación eficiente de la tendencia, o lo que es lo mismo la estimación óptima de los parámetros de la \emph{variación de gran escala} \(\boldsymbol{\beta}\), a partir de los datos observados en un conjunto de posiciones espaciales \(\left\{ \mathbf{s}_{1}, \ldots,\mathbf{s}_{n} \right\}\).
Bajo las hipótesis anteriores:
\[\mathbf{Z} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon},\]
siendo \(\mathbf{Z}=\left( Z(\mathbf{s}_{1}), \ldots,Z(\mathbf{s}_{n}) \right)^{\top}\), \(\mathbf{X}\) una matriz \(n\times (p+1)\) con \(\mathbf{X}_{ij}=X_{j-1}(\mathbf{s}_{i})\) y \(\boldsymbol{\varepsilon} = \left( \varepsilon (\mathbf{s}_{1}), \ldots,\varepsilon (\mathbf{s}_{n})\right)^{\top}\); y el estimador lineal insesgado de \(\boldsymbol{\beta}\) más eficiente resulta ser el estimador de mínimos cuadrados ordinarios (OLS, \emph{ordinary least squares}):
\begin{equation} 
  \hat{\boldsymbol{\beta}}_{ols}=(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^{\top}\mathbf{Z},
  \label{eq:beta-ols}
\end{equation}
con \[Var(\hat{\boldsymbol{\beta}}_{ols})=\sigma^{2}(\mathbf{X}^{\top}\mathbf{X})^{-1}.\]

Sin embargo la suposición de que los errores son independientes e idénticamente distribuidos influye crucialmente en la inferencia.
En el modelo anterior, en lugar de errores incorrelados, si suponemos que:
\[Var\left( \boldsymbol{\varepsilon} \right) =\boldsymbol{\Sigma},\]
obtenemos el modelo lineal de regresión generalizado y en este caso el estimador lineal óptimo de \(\boldsymbol{\beta}\) es el estimador de mínimos cuadrados generalizados (GLS, \emph{generalized least squares}):
\begin{equation} 
  \hat{\boldsymbol{\beta}}_{gls} =(\mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{X})^{-1} \mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{Z}.
  \label{eq:beta-gls}
\end{equation}

Si \(\boldsymbol{\Sigma}=\sigma^{2} \mathbf{I}_{n}\), siendo \(\mathbf{I}_{n}\) la matriz identidad \(n\times n\), los estimadores \eqref{eq:beta-ols} y \eqref{eq:beta-gls} coinciden; pero en caso contrario las estimaciones basadas en el modelo anterior pueden llegar a ser altamente ineficientes.
Puede verse fácilmente que en el caso general:
\[Var\left( \hat{\boldsymbol{\beta}}_{gls} \right)=(\mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{X})^{-1}, \\
Var\left( \hat{\boldsymbol{\beta}}_{ols} \right) =(\mathbf{X}^{\top}\mathbf{X})^{-1} (\mathbf{X}^{\top}\boldsymbol{\Sigma}\mathbf{X})(\mathbf{X}^{\top}\mathbf{X})^{-1},\]
resultando además que \(Var( \hat{\boldsymbol{\beta}}_{ols}) - Var( \hat{\boldsymbol{\beta}}_{gls} )\) es una matriz semidefinida positiva (e.g.~Searle, 1971, Sección 3.3).

En muchos casos el objetivo final es la predicción del proceso en una posición espacial \(\mathbf{s}_{0}\):
\[Z(\mathbf{s}_{0} )=\mathbf{x}_0^{\top}\boldsymbol{\beta}+\varepsilon (\mathbf{s}_{0} ),\]
donde \(\mathbf{x}_0=\left( X_{0} (\mathbf{s}_{0} ), \ldots,X_{p} (\mathbf{s}_{0})\right)^{\top}\).
Bajo las hipótesis del modelo clásico el predictor óptimo sería la estimación de la tendencia \(\hat{\mu}(\mathbf{s}_{0} ) = \mathbf{x}_0^\top \hat{\boldsymbol{\beta}}_{ols}\) (el predictor óptimo de un error independiente sería cero).
En el caso general, siguiendo esta aproximación, podríamos pensar en utilizar como predictor el estimador más eficiente de la tendencia:
\[\hat{Z} (\mathbf{s}_{0})=\mathbf{x}_0^\top \hat{\boldsymbol{\beta}}_{gls},\]
sin embargo no es el predictor lineal óptimo. Puede verse (e.g.~Goldberger, 1962; Sección \ref{kriging-residual}) que en este caso el mejor predictor lineal insesgado es:
\begin{equation} 
  \tilde{Z}(\mathbf{s}_{0}) = \mathbf{x}_0^{\top}\hat{\boldsymbol{\beta}}_{gls} + \mathbf{c}^{\top} \boldsymbol{\Sigma}^{-1} \left( \mathbf{Z} - \mathbf{X}\hat{\boldsymbol{\beta}}_{gls} \right),
  \label{eq:predictor-kriging}
\end{equation}
(el denominado predictor del \emph{kriging universal}, Sección \ref{kuniversal}), siendo
\[\mathbf{c} = \left( Cov\left( \varepsilon (\mathbf{s}_{1} ),\varepsilon (\mathbf{s}_{0} )\right), \ldots, Cov\left( \varepsilon (\mathbf{s}_{n} ),\varepsilon (\mathbf{s}_{0} )\right) \right)^{\top},\]
y la diferencia \(Var( \hat{Z} (\mathbf{s}_{0} ) ) - Var( \tilde{Z} (\mathbf{s}_{0} ) ) \ge 0\) puede ser significativamente mayor que cero\footnote{Por ejemplo, para un caso particular, Goldberger (1962, pp.374-375) observó que la mejora en la predicción puede llegar a ser del 50\%. En Cressie (1993, Sección 1.3) se muestran también otros ejemplos del efecto de la presencia de correlación en la estimación.} (si la dependencia espacial no es muy débil).
Naturalmente, si se ignora por completo la dependencia y se emplea únicamente el estimador \(\hat{\boldsymbol{\beta}}_{ols}\) disminuye aún más la eficiencia de las predicciones.

Teniendo en cuenta los resultados anteriores podemos afirmar que al explotar la dependencia presente en los datos el incremento en eficiencia puede ser importante.
Sin embargo el principal inconveniente es que en la práctica normalmente la matriz \(\boldsymbol{\Sigma}\) y el vector \(\mathbf{c}\) son desconocidos.
El procedimiento habitual, para evitar la estimación de \(n+n(n+1)/2\) parámetros adicionales a partir del
conjunto de \(n\) observaciones, suele ser la elección de un modelo paramétrico adecuado (ver Sección \ref{modelos-parametricos}):
\[C(\mathbf{u},\mathbf{v}\left| \boldsymbol{\theta}\right. )\equiv Cov\left( \varepsilon (\mathbf{u}),\varepsilon (\mathbf{v})\right),\]
i.e.~suponer que \(\boldsymbol{\Sigma} \equiv \boldsymbol{\Sigma}\left( \boldsymbol{\theta}\right)\) y \(\mathbf{c}\equiv \mathbf{c}\left( \boldsymbol{\theta}\right)\).
Una hipótesis natural es suponer que los datos cercanos en el espacio o en el tiempo están correlados y que la correlación disminuye al aumentar la separación entre ellos; por tanto es normal pensar en errores espacialmente correlados.
Por ejemplo, podemos considerar:
\[C(\mathbf{u},\mathbf{v}\left| \boldsymbol{\theta}\right. )=\sigma^{2} \rho^{\left\| \mathbf{u}-\mathbf{v}\right\| },\]
con \(\sigma^{2} \geq 0\) y \(0<\rho <1\).
De esta forma, si \(\hat{\boldsymbol{\theta}}\) es un estimador de \(\boldsymbol{\theta}\) (ver Sección \ref{ajuste-variog}), podemos obtener por ejemplo una aproximación del predictor óptimo de \(Z(\mathbf{s}_{0} )\) sustituyendo en \eqref{eq:predictor-kriging} \(\boldsymbol{\Sigma}(\boldsymbol{\theta})\) por \(\boldsymbol{\Sigma}(\hat{\boldsymbol{\theta}} )\) y \(\mathbf{c}(\boldsymbol{\theta})\) por \(\mathbf{c}(\hat{\boldsymbol{\theta}} )\).

\hypertarget{ventajas-de-la-aproximaciuxf3n-espacial-y-espacio-temporal}{%
\subsection{Ventajas de la aproximación espacial (y espacio-temporal)}\label{ventajas-de-la-aproximaciuxf3n-espacial-y-espacio-temporal}}

Algunos de los beneficios de utilizar modelos espaciales para caracterizar y explotar la dependencia espacial de un conjunto de datos son los siguientes:

\begin{itemize}
\item
  Modelos más generales: en la mayoría de los casos, los modelos clásicos no espaciales son un caso particular de un modelo espacial.
\item
  Estimaciones más eficientes: de la tendencia, de los efectos de variables explicativas, de promedios regionales\ldots{}
\item
  Mejora de las predicciones: más eficientes, con propiedades de extrapolación más estables\ldots{}
\item
  La variación espacial no explicada en la estructura de la media debe ser absorbida por la estructura del error, por lo que un modelo que incorpore la dependencia espacial puede decirse que esta protegido frente a una mala especificación de este tipo. Esto en muchos casos tiene como resultado una simplificación en la especificación de la tendencia; en general los modelos con dependencia espacial suelen tener una descripción más parsimoniosa (en ocasiones con muchos menos parámetros) que los clásicos modelos de superficie de tendencia.
\end{itemize}

\hypertarget{procesos-estacionarios}{%
\section{Procesos espaciales estacionarios}\label{procesos-estacionarios}}

Supongamos que \(\left\{ Z(\mathbf{s}) : \mathbf{s} \in D \subset \mathbb{R}^{d} \right\}\) es un proceso geoestadístico.
Este proceso aleatorio se puede caracterizar a través de las funciones de distribución finito-dimensionales:
\[F_{\mathbf{s}_1, \ldots, \mathbf{s}_m}(z_1, \ldots, z_m)
= P\left(Z(\mathbf{s}_1)\leq z_1 , \ldots,Z(\mathbf{s}_m)\leq z_m \right)\]
(o de las funciones de densidad correspondientes \(f_{\mathbf{s}_1, \ldots, \mathbf{s}_m}(z_1, \ldots, z_m)\).
Por ejemplo, el proceso se dice normal (o gaussiano) si para cada posible conjunto de \(m \in \mathbb{N}\) posiciones espaciales, \(\{\mathbf{s}_1, \ldots, \mathbf{s}_m\}\), su función de distribución \(F_{\mathbf{s}_1, \ldots, \mathbf{s}_m}\) es normal (gaussiana).

Como ya se comentó en la Sección \ref{proc-esp}, en general no se puede disponer de una realización completa del proceso \(Z(\cdot)\) y solamente se observan valores en unas posiciones espaciales conocidas \(\left\{ \mathbf{s}_1, \ldots, \mathbf{s}_{n} \right\}\) (que por lo general van a ser irregulares).
Por tanto es necesario hacer algunas suposiciones acerca del proceso de forma que sea posible la inferencia sobre el mismo.
Lo habitual es asumir algún tipo de estacionariedad del proceso (o del proceso de error, suponiendo que el proceso no tiene media constante y sigue el modelo general \eqref{eq:modelogeneral}).

El proceso \(Z(\cdot)\) se dice \emph{estrictamente estacionario} si al trasladar (en cualquier dirección) una configuración cualquiera de posiciones espaciales la distribución conjunta no varia:
\[F_{\mathbf{s}_1 +\mathbf{h}, \ldots,\mathbf{s}_m +\mathbf{h}}(z_1, \ldots, z_m) = F_{\mathbf{s}_1, \ldots, \mathbf{s}_m}(z_1, \ldots, z_m),\ \forall \mathbf{h}\in D,\ \forall m\geq 1.\]

El proceso \(Z(\cdot)\) se dice \emph{estacionario de segundo orden} (también proceso estacionario homogéneo o débilmente estacionario) si tiene media constante y la covarianza entre dos posiciones depende únicamente del salto entre ellas:

\begin{itemize}
\item
  \(E(Z(\mathbf{s}))=\mu,\ \forall \mathbf{s}\in D\).
\item
  \(Cov(Z(\mathbf{s}_1), Z(\mathbf{s}_2)) = C(\mathbf{s}_1 -\mathbf{s}_2),\ \forall \mathbf{s}_1 ,\mathbf{s}_2 \in D\).
\end{itemize}

La función \(C(\cdot)\) se denomina \emph{covariograma} (también autocovariograma o función de covarianzas).
Si además \(C(\mathbf{h}) \equiv C(\left\| \mathbf{h}\right\|)\) (sólo depende de la magnitud y no de la dirección del salto) se dice que el covariograma es \emph{isotrópico} (en caso contrario se dice que es \emph{anisotrópico}; Sección \ref{anisotropia}).

Si un proceso es estrictamente estacionario y \(Var(Z(\mathbf{s}))\) es finita, entonces es estacionario de segundo orden.
Además, como es bien conocido, en el caso de procesos normales ambas propiedades son equivalentes (ya que están caracterizados por su media y covarianza).

En algunos casos en lugar del covariograma se utiliza el correlograma:
\[\rho (\mathbf{h}) = \dfrac{C(\mathbf{h})}{C(\mathbf{0})} \in \left[-1,+1\right],\]
suponiendo que \(C(\mathbf{0}) = Var(Z(\mathbf{s})) >0\).
Sin embargo lo habitual es modelar la dependencia espacial a través del variograma (principalmente por sus ventajas en la estimación; Sección \ref{vario-muestrales}), definido a continuación.

Se dice que el proceso es \emph{intrínsecamente estacionario} (también proceso espacial de incrementos estacionarios u homogéneos) si:

\begin{itemize}
\item
  \(E(Z(\mathbf{s}))=\mu,\ \forall \mathbf{s}\in D\).
\item
  \(Var(Z(\mathbf{s}_1)-Z(\mathbf{s}_2)) = 2\gamma (\mathbf{s}_1 - \mathbf{s}_2),\ \forall \mathbf{s}_1 ,\mathbf{s}_2 \in D\).
\end{itemize}

La función \(2\gamma (\cdot)\) se denomina \emph{variograma} y \(\gamma (\cdot)\) \emph{semivariograma}.
Al igual que en el caso anterior, si además \(\gamma(\mathbf{h}) \equiv \gamma(\left\| \mathbf{h}\right\|)\) (sólo depende de la distancia) se dice que el variograma es isotrópico.

La clase de procesos intrínsecamente estacionarios es más general que la clase de procesos estacionarios de segundo orden.
Si un proceso estacionario de segundo orden tiene covariograma \(C(\cdot)\), como:
\[\begin{aligned}
Var(Z(\mathbf{s}_1)-Z(\mathbf{s}_2)) &= Var(Z(\mathbf{s}_1)) + Var(Z(\mathbf{s}_2))-2Cov(Z(\mathbf{s}_1),Z(\mathbf{s}_2)) \\
&=2\left(C(\mathbf{0})-C(\mathbf{s}_1 -\mathbf{s}_2)\right),
\end{aligned}\]
entonces su semivariograma viene dado por:
\[\gamma (\mathbf{h}) = C(\mathbf{0})-C(\mathbf{h}),\]
y por tanto es un proceso intrínsecamente estacionario.
El reciproco en general no es cierto (por ejemplo el caso de un \href{https://es.wikipedia.org/wiki/Movimiento_browniano\#Matem\%C3\%A1ticas}{movimiento browniano}), aunque sí se verifica en muchos casos.
Normalmente cuando no se verifica es debido a que el proceso no tiene media constante y puede ser modelado como una función de tendencia más un error estacionario de segundo orden (o cuando se consideran los errores del modelo general, la tendencia no está especificada correctamente; ver Sección \ref{trend-fit}).

Si el variograma está acotado y:
\[\lim \limits_{\left\| \mathbf{h}\right\| \rightarrow \infty }\gamma(\mathbf{h})=\sigma^2,\]
entonces\footnote{Suponiendo que \(\lim \limits_{\left\| \mathbf{h}\right\| \rightarrow \infty } C(\mathbf{h})=0\).} podemos obtener el covariograma correspondiente como:
\[C(\mathbf{h})=\sigma^2-\gamma (\mathbf{h}).\]
A \(\sigma^{2} = C(\mathbf{0})\) se le denomina \emph{umbral} (o \emph{meseta}) del semivariograma.
La relación entre el semivariograma y el covariograma se ilustra en la Figura \ref{fig:var-gen}.

\hypertarget{caracteristicas-variograma}{%
\subsection{Características del variograma}\label{caracteristicas-variograma}}

Además del umbral (si existe, ya que el variograma podría no estar acotado; ver sección anterior), hay otras características geométricas del variograma (o del covariograma) de especial importancia\footnote{Además de poder interpretar su influencia en la predicción espacial (Sección \ref{efecto-variog-kriging}), son utilizadas en la parametrización de la mayoría de los modelos de variogramas o covariogramas (Sección \ref{modelos-parametricos}).}, entre ellas destacarían el \emph{efecto pepita} (o \emph{nugget}) y el \emph{rango} (o \emph{alcance}).
La Figura \ref{fig:var-gen} ilustra las distintas características del semivariograma.



\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/var-gen-1} 

}

\caption{Relación entre el covariograma (línea discontinua) y el variograma (línea continua) en el caso unidimensional (o isotrópico), y principales características: nugget (\(c_0\)), umbral (\(\sigma^2\); umbral parcial \(\sigma^2 - c_0\)) y rango (\(a\)).}\label{fig:var-gen}
\end{figure}

Siempre se verifica que \(\gamma (\mathbf{0})=0\), sin embargo puede ser que:
\[\lim \limits_{\mathbf{h}\rightarrow \mathbf{0}} \gamma(\mathbf{h}) = c_0 > 0.\]
entonces \(c_0\) se denomina \emph{efecto pepita} (o \emph{nugget})\footnote{El origen de esta denominación esta relacionado con la terminología minera. En algunos yacimientos de metal, como por ejemplo en el caso del oro, el mineral suele obtenerse como pepitas de material puro y estas pepitas normalmente son más pequeñas que el tamaño de la unidad de muestreo (lo que produce una variabilidad adicional en la muestra).}.
Además, si \(\sigma^{2}\) es el umbral del semivariograma (suponiendo que existe), a \(\sigma ^{2} -c_0\) se le denomina \emph{umbral parcial}.

Las propiedades de continuidad (y derivabilidad) del variograma (o el covariograma) en el origen están relacionadas con las propiedades de continuidad (y diferenciabilidad) en media cuadrática del proceso \(Z(\cdot)\) (ver e.g.~Chilès y Delfiner, 1999, Sección 2.3.1).
Por ejemplo, el proceso es continuo en media cuadrática si y sólo si su variograma (covariograma) es continuo en el origen. Entonces la presencia de efecto nugget indica que (en teoría) el proceso no es continuo y por tanto altamente irregular.

La proporción del efecto nugget en el umbral total \(c_0 /\sigma^{2}\) proporciona mucha información acerca del grado de dependencia espacial presente en los datos.
Por ejemplo, en el caso en que toda la variabilidad es efecto nugget (i.e.~\(\gamma (\mathbf{h})=c_0\), \(\forall \mathbf{h}\neq \mathbf{0}\)) entonces \(Z(\mathbf{s}_1)\) y \(Z(\mathbf{s}_2)\) son incorrelados \(\forall \mathbf{s}_1 ,\mathbf{s}_2 \in D\) independientemente de lo cerca que estén (el proceso \(Z(\cdot)\) es ruido blanco).
Por tanto podemos pensar en \(c_0 /\sigma^{2}\) como la proporción de ``variabilidad independiente'', aunque en la práctica típicamente no se dispone de información sobre el variograma a distancias menores de \(\min \left\{ \left\| \mathbf{s}_{i} -\mathbf{s}_{j} \right\| :1\leq i<j\leq n\right\}\) (la estimación de \(c_0\) se obtiene normalmente extrapolando un variograma experimental cerca del origen).

Si \(\sigma ^{2}\) es el umbral del semivariograma (suponiendo que existe), se define el \emph{rango} (o alcance) del semivariograma en la dirección \(\mathbf{e}_0 \in \mathbb{R}^{d}\) con \(\left\| \mathbf{e}_0 \right\| = 1\), como el mínimo salto en esa dirección en el que se alcanza el umbral:
\[a_0 =\min \left\{ a:\gamma (a\left( 1+\varepsilon \right) \mathbf{e}_0 )=\sigma ^{2} , \forall \varepsilon >0\right\}.\]
El rango en la dirección \(\mathbf{e}_0\) puede interpretarse como el salto \(h\) a partir del cual no hay correlación entre \(Z(\mathbf{s})\) y \(Z(\mathbf{s}\pm h\mathbf{e}_0)\), por tanto está íntimamente ligado a la noción de ``zona de influencia'' (y tiene un papel importante en la determinación de criterios de vecindad).
En los casos en los que el semivariograma alcanza el umbral asintóticamente (rango infinito), se suele considerar el \emph{rango práctico}, definido como el mínimo salto en el que se alcanza el 95\% del umbral parcial.

El variograma y el covariograma son las funciones habitualmente consideradas en geoestadística para el modelado de la dependencia espacial (o espacio-temporal), y son consideradas como un parámetro (de especial interés) del proceso.
En la práctica normalmente se suele utilizar el variograma, no sólo porque es más general (puede existir en casos en que el covariograma no), sino por las ventajas en su estimación (Sección \ref{vario-muestrales}; Cressie, 1993, Sección 2.4.1).
No obstante, en muchos casos los modelos de variograma se obtienen a partir de modelos de covariograma.

\hypertarget{propiedades-elementales}{%
\subsection{Propiedades elementales del covariograma y del variograma}\label{propiedades-elementales}}

El variograma y el covariograma deben verificar ciertas propiedades que sus estimadores no siempre verifican, a continuación se detallan algunas de ellas.

Si \(Z(\cdot)\) es un proceso estacionario de segundo orden con covariograma \(C(\cdot)\),
entonces se verifica que \(C(\mathbf{0}) = Var( Z(\mathbf{s}) ) \geq 0\), es una función par \(C(\mathbf{h})=C(-\mathbf{h})\), y por la desigualdad de Cauchy-Schwarz \(\left| C(\mathbf{h})\right| \leq C(\mathbf{0})\).
Además, el covariograma debe ser semidefinido positivo, es decir:
\[\sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} a_i a_j C(\mathbf{s}_i-\mathbf{s}_j) \geq 0  \\
\forall m\geq 1,\ \forall \mathbf{s}_i \in D,\ \forall a_i \in \mathbb{R};\ i=1, \ldots,m,\]
ya que:
\[\sum\limits_{i=1}^{m}\sum\limits_{j=1}^{m}a_i a_j C(\mathbf{s}_i -\mathbf{s}_j) = Var\left\{\sum\limits_{i=1}^{m}a_i Z(\mathbf{s}_i) \right\}\]
La condición es necesaria y suficiente para que exista un proceso estacionario de segundo orden con covariograma \(C(\cdot)\) (se puede construir un proceso normal multivariante con covarianzas definidas por \(C(\cdot)\)).
Por tanto la clase de covariogramas válidos en \(\mathbb{R}^d\) es equivalente a la clase de funciones semidefinidas positivas en \(\mathbb{R}^d\).

Algunas propiedades adicionales que verifican los covariogramas son las siguientes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Si \(C(\cdot)\) es un covariograma válido en \(\mathbb{R}^d\), entonces \(aC(\cdot)\), \(\forall a\geq 0\), es
  también un covariograma válido en \(\mathbb{R}^d\).
\item
  Si \(C_1 (\cdot)\) y \(C_2 (\cdot)\) son covariogramas válidos en \(\mathbb{R}^d\), entonces \(C_1 (\cdot) + C_2 (\cdot)\) es un
  covariograma válido en \(\mathbb{R}^d\). Lo que equivale a suponer que el proceso \(Z(\cdot)\) se obtiene como suma de dos procesos estacionarios de segundo orden independientes: \(Z(\mathbf{s})=Z_1 (\mathbf{s}) + Z_2 (\mathbf{s})\), con covariogramas \(C_1 (\cdot)\) y \(C_2 (\cdot)\) respectivamente.
\item
  Si \(C_1 (\cdot)\) y \(C_2 (\cdot)\) son covariogramas válidos en \(\mathbb{R}^d\), entonces \(C(\cdot) = C_1 (\cdot)C_2 (\cdot)\)
  es un covariograma válido en \(\mathbb{R}^d\). Lo que equivale a suponer que el proceso se obtiene como producto de dos procesos estacionarios de segundo orden independientes.
\item
  Un covariograma isotrópico válido en \(\mathbb{R}^d\) es también un covariograma isotrópico válido en \(\mathbb{R}^m\), \(\forall m\leq d\) (el recíproco no es en general cierto, ver e.g.~Cressie, 1993, p.~84).
\end{enumerate}

Si \(\gamma (\cdot)\) es el semivariograma de un proceso intrínsecamente estacionario \(Z(\cdot)\), entonces se verifica que \(\gamma (\mathbf{0})=0\), \(\gamma (\mathbf{h})\geq 0\) y \(\gamma (\mathbf{h})=\gamma (-\mathbf{h})\).
El semivariograma debe ser además condicionalmente semidefinido negativo, es decir:
\[\sum\limits_{i=1}^{m}\sum\limits_{j=1}^{m}a_i a_j \gamma(\mathbf{s}_i -\mathbf{s}_j) \leq 0  \\
\forall m\geq 1,\forall \mathbf{s}_i \in D,\forall a_i \in \mathbb{R};i=1, \ldots,m,\text{tales que } \sum\limits_{i=1}^{m}a_i = 0.\]
Esta condición es necesaria pero no suficiente (aunque pocas condiciones adicionales son necesarias para que el recíproco sea cierto; ver Cressie, 1993, Sección 3.5.2).

Algunas propiedades adicionales que verifica un variograma son las siguientes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Si \(\gamma (\cdot)\) es un semivariograma válido en \(\mathbb{R}^d\), entonces \(a\gamma (\cdot)\), \(\forall a\geq 0\), es también un semivariograma válido en \(\mathbb{R}^d\).
\item
  Si \(\gamma_1 (\cdot)\) y \(\gamma_2 (\cdot)\) son semivariogramas válidos en \(\mathbb{R}^d\), entonces \(\gamma_1 (\cdot)+\gamma_2 (\cdot)\), es también un semivariograma válido en \(\mathbb{R}^d\). Lo que equivale a suponer que el proceso \(Z(\cdot)\) se obtiene como suma de dos procesos intrínsecamente estacionarios independientes: \(Z(\mathbf{s})=Z_1 (\mathbf{s})+Z_2 (\mathbf{s})\), con semivariogramas \(\gamma_1 (\cdot)\) y \(\gamma_2 (\cdot)\) respectivamente.
\item
  Un variograma isotrópico válido en \(\mathbb{R}^d\) es también un variograma isotrópico válido en \(\mathbb{R}^m\), \(\forall m\leq d\).
\end{enumerate}

Se suelen emplear estas propiedades para la obtención de modelos de variograma válidos, como por ejemplo en el caso de la anisotropía zonal (Sección \ref{anisotropia}) o del modelo lineal de (co)regionalización (secciones \ref{vario-lin-reg} y 5.X).

\hypertarget{procesos-agregados}{%
\subsection{Procesos agregados}\label{procesos-agregados}}

En algunos casos los datos pueden ser agregaciones espaciales en lugar de observaciones puntuales (e incluso observaciones sobre distintos soportes) o, por ejemplo, puede ser de interés la estimación de medias espaciales a partir de datos puntuales.
Estas agregaciones pueden ser modeladas como el promedio de un proceso puntual, lo que permite deducir fácilmente las relaciones entre covariogramas y variogramas vinculados a diferentes soportes.

Supongamos que el proceso espacial \(Z(\cdot)\) definido sobre \(D\subset \mathbb{R} ^{d}\) es integrable en media cuadrática.
Entonces, si \(B\subset D\) es un subconjunto acotado e integrable con \(\left| B\right| =\int_B d\mathbf{s} > 0\), se puede definir el proceso espacial agregado (también se denomina regularizado) como:
\[Z(B)\equiv \dfrac{1}{\left| B\right| } \int_{B}Z(\mathbf{s})d\mathbf{s}.\]

Si por ejemplo el proceso puntual es intrínsecamente estacionario con semivariograma \(\gamma (\cdot)\), entonces a partir del variograma puntual podemos obtener el variograma del proceso agregado:

\[\begin{aligned}
Var\left( Z(B_1)-Z(B_2)\right) = & -\dfrac{1}{\left| B_1 \right| ^{2} } 
\int_{B_1 }\int_{B_1 }\gamma(\mathbf{s}-\mathbf{u})d\mathbf{s}d\mathbf{u}   \\
  & -\dfrac{1}{\left| B_2 \right|^{2} } \int_{B_2}\int_{B_2}\gamma(\mathbf{s}-\mathbf{u})d\mathbf{s}d\mathbf{u}   \\
 & +\dfrac{1}{\left| B_1 \right| \left| B_2 \right| } \int_{B_1 }\int_{B_2} 2\gamma(\mathbf{s}-\mathbf{u})d\mathbf{s}d\mathbf{u}. 
\end{aligned}\]

Aunque nos centraremos principalmente en el caso de soporte puntual, los métodos descritos en este libro pueden ser extendidos para el caso de distintos soportes (por ejemplo el \emph{block kriging} descrito en la Sección \ref{block-kriging}).
Sin embargo, en la práctica pueden aparecer dificultades, especialmente al combinar observaciones en distintos soportes (esto es lo que se conoce como el problema de cambio de soporte, o el \emph{modifiable areal unit problem}, MAUP).
Para más detalles ver por ejemplo Cressie (1993, Sección 5.2) ó Chilès y Delfiner (1999, Sección 2.4).

\hypertarget{objetivos-esquema}{%
\section{Objetivos y procedimiento}\label{objetivos-esquema}}

A partir de los valores observados \(\{Z(\mathbf{s}_1), \ldots, Z(\mathbf{s}_n)\}\) (o \(\{Z(B_1), \ldots, Z(B_n)\}\)), los objetivos suelen ser:

\begin{itemize}
\item
  Obtener predicciones (kriging) \(\hat{Z}(\mathbf{s}_0)\) (o \(\hat{Z}(B_0)\)).
\item
  Realizar inferencias (estimación, contrastes) sobre las componentes
  del modelo \(\hat{\mu}(\cdot)\), \(\hat{\gamma}(\cdot)\).
\item
  Obtención de mapas de riesgo \(P({Z}(\mathbf{s}_0)\geq c)\).
\item
  Realizar inferencias sobre la distribución (condicional) de la respuesta
  en nuevas localizaciones\ldots{}
\end{itemize}

En cualquier caso en primer lugar habría que estimar las componentes del modelo: la tendencia \(\mu(\mathbf{s})\) y el semivariograma \(\gamma(\mathbf{h})\).
La aproximación tradicional (paramétrica) para el modelado de un proceso geoestadístico consiste en los siguientes pasos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Análisis exploratorio y formulación de un modelo paramétrico inicial (Capítulo \ref{datos}).
\item
  Estimación de los parámetros del modelo (puede ser un proceso iterativo; Capítulo \ref{modelado}):

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Estimar y eliminar la tendencia.
  \item
    Modelar la dependencia (ajustar un modelo de variograma) a partir de los residuos.
  \end{enumerate}
\item
  Validación del modelo (Sección \ref{validacion-cruzada}) o reformulación del mismo.
\item
  Empleo del modelo aceptado (Capítulo \ref{kriging}).
\end{enumerate}

Como ya se comentó, emplearemos el paquete \href{https://r-spatial.github.io/gstat}{\texttt{gstat}} en este proceso (Sección \ref{gstat-pkg}).

\hypertarget{datos}{%
\chapter{Datos espaciales}\label{datos}}

En este capítulo se incluye una breve introducción a los tipos de datos espaciales (Sección \ref{datos-tipos}) y a su manipulación en R con el paquete \texttt{sf} (secciones \ref{sf-intro}, \ref{sf-plot} y \ref{operaciones-datos}).
La parte final se centra en el análisis exploratorio de datos espaciales (Sección \ref{sp-eda}).

\hypertarget{datos-tipos}{%
\section{Tipos de datos espaciales}\label{datos-tipos}}

En el campo de los datos espaciales se suele distinguir entre dos tipos de datos:

\begin{itemize}
\item
  \emph{Datos vectoriales}: en los que se emplean coordenadas para definir las posiciones espaciales ``exactas'' de los datos. Entre ellos estarían los asociados a las geometrías habituales: puntos, líneas, polígonos y rejillas.
\item
  \emph{Datos ráster}: se utilizan habitualmente para representar una superficie continua. Un ráster no es más que una rejilla regular que determina un conjunto de rectángulos denominados celdas (o píxeles en el análisis de imágenes y teledetección) que tienen asociados uno o más valores. Este tipo de datos también se denominan \emph{arrays} o \emph{data cubes} espaciales (o espacio-temporales). El valor de una celda ráster suele ser el valor medio (o el total) de una variable en el área que representa (se trataría de observaciones de un proceso agregado, descritos en la Sección \ref{procesos-agregados}), aunque en algunos casos es el valor puntual correspondiente al centro de la celda (nodo de una rejilla vectorial).
\end{itemize}

En este libro entenderemos que \emph{ráster} hace referencia a agregaciones espaciales y nos centraremos principalmente en datos vectoriales (incluyendo rejillas de datos), aunque hoy en día cada vez es más habitual disponer de datos ráster gracias a la fotografía aérea y a la teledetección por satélite.
Como se comentó en la Sección \ref{procesos-agregados}, muchos métodos geoestadísticos admiten datos en distintos soportes (por ejemplo el \emph{block kriging} descrito en la Sección \ref{block-kriging}), aunque combinar datos en diferentes soportes puede presentar en la práctica serias dificultades (para más detalles ver referencias al final de la Sección \ref{procesos-agregados}).

Como ya se comentó en la Sección \ref{proc-esp}, dependiendo de las suposiciones sobre el soporte del proceso (índice espacial) se distingue entre distintos tipos de procesos espaciales.
Sin embargo, aunque en principio los objetivos pueden ser muy distintos, en todos estos casos se trabaja con datos similares (espaciales y espacio-temporales):

\begin{itemize}
\item
  \textbf{Procesos geoestadísticos} (índice espacial continuo):

  \begin{itemize}
  \item
    \emph{Datos}: coordenadas y valores observados (puntos y datos), opcionalmente se pueden considerar los límites de una región de observación o de múltiples regiones (polígonos).
  \item
    \emph{Resultados}: superficie de predicción (rejilla),
    opcionalmente predicciones por área (polígonos y datos, o raster).
  \end{itemize}
\item
  \textbf{Procesos reticulares/regionales} (índice espacial discreto):

  \begin{itemize}
  \item
    \emph{Datos}: límites de regiones y valores asociados (polígonos y datos, , o raster).
  \item
    \emph{Resultados}: estimaciones por área (polígonos y datos, o raster).
  \end{itemize}
\item
  \textbf{Procesos puntuales} (indice espacial aleatorio):

  \begin{itemize}
  \item
    \emph{Datos}: coordenadas (puntos), opcionalmente con valores asociados (procesos marcados; puntos y datos),
    límites región de observación (polígonos).
  \item
    \emph{Resultados}: superficie de incidencia o probabilidad (rejilla).
  \end{itemize}
\end{itemize}

Este es el principal motivo de que se hayan desarrollado paquetes de R para facilitar su manipulación (y permitiendo el intercambio de datos entre herramientas).
Entre ellos destacan:

\begin{itemize}
\item
  \href{https://CRAN.R-project.org/package=sp}{\texttt{sp}} (Classes and methods for spatial data, \protect\hyperlink{ref-Pebesma2005}{E. J. Pebesma y Bivand, 2005}): se corresponde con \protect\hyperlink{ref-Bivand2013}{Bivand et~al.} (\protect\hyperlink{ref-Bivand2013}{2013}) y emplea clases S4. Se complementa con los paquetes \href{https://CRAN.R-project.org/package=rgdal}{\texttt{rgdal}} (interfaz a la \emph{geospatial data abstraction library}, para la lectura y escritura de datos espaciales) y \href{https://CRAN.R-project.org/package=rgeos}{\texttt{rgeos}} (interfaz a la librería \emph{Geometry Engine Open Source}, para operaciones geométricas).
\item
  \href{https://r-spatial.github.io/sf}{\texttt{sf}} (Simple Features for R, \protect\hyperlink{ref-Pebesma2018}{E. Pebesma, 2018}): alternativa en desarrollo con objetos más simples S3 (compatible con \href{http://tidyverse.org}{\texttt{tidyverse}} y que proporciona una interfaz directa a las librerías \href{https://gdal.org}{GDAL} y \href{https://trac.osgeo.org/geos}{GEOS}) que aspira a reemplazar el paquete \texttt{sp} a corto plazo. Se corresponde con \protect\hyperlink{ref-Pebesma2021}{E. Pebesma y Bivand} (\protect\hyperlink{ref-Pebesma2021}{2021}) (disponible \href{https://keen-swartz-3146c4.netlify.app}{online}).
\end{itemize}

El paquete \texttt{sp} tiene un soporte limitado para datos ráster, este es uno de los motivos por los que surgió el paquete \href{https://CRAN.R-project.org/package=raster}{\texttt{raster}}, que actualmente está siendo reemplazado por el paquete \href{https://CRAN.R-project.org/package=terra}{\texttt{terra}} (información sobre estos paquetes está disponible en el \href{https://rspatial.org/}{manual online}).
El paquete \texttt{sf} no implementa datos ráster (y tiene un soporte muy limitado para rejillas de datos), para manejar este tipo de datos se complementa con el paquete \href{https://r-spatial.github.io/stars}{\texttt{starts}} (Spatiotemporal Arrays: Raster and Vector Datacubes).
Para detalles sobre la conversión entre datos ráster y datos vectoriales ver por ejemplo las secciones \href{https://keen-swartz-3146c4.netlify.app/sf.html\#raster-to-vector}{7.5} y \href{https://keen-swartz-3146c4.netlify.app/sf.html\#warp}{7.7} de \protect\hyperlink{ref-Pebesma2021}{E. Pebesma y Bivand} (\protect\hyperlink{ref-Pebesma2021}{2021}).

En este capítulo emplearemos el paquete \texttt{sf} para la manipulación de datos espaciales, aunque en el Apéndice \ref{intro-sp} se incluye una breve introducción a las clases \texttt{sp}, ya que este tipo de objetos siguen siendo ampliamente empleados en la actualidad (y, de momento, algunas de las herramientas disponibles en R solo admiten las clases de datos definidas en este paquete).

\hypertarget{sf-intro}{%
\section{\texorpdfstring{Introducción al paquete \textbf{sf}}{Introducción al paquete sf}}\label{sf-intro}}

El modelo de geometrías de \emph{\href{https://en.wikipedia.org/wiki/Simple_Features}{características simples}} (o rasgos simples) es un estándar (\href{https://www.iso.org/standard/40114.html}{ISO 19125}) desarrollado por el \href{https://www.ogc.org}{Open Geospatial Consortium} (OGC) para formas geográficas vectoriales, que ha sido adoptado por gran cantidad de software geográfico (entre otros por GeoJSON, ArcGIS, QGIS, PostGIS, MySQL Spatial Extensions, Microsoft SQL Server\ldots).
Como ya se comentó, este tipo de datos espaciales está implementado en R en el paquete \href{https://r-spatial.github.io/sf}{\texttt{sf}}.

Los objetos principales, del tipo \texttt{sf}, son extensiones de \texttt{data.frame} (o \texttt{tibble}) y como mínimo contienen una columna denominada \emph{simple feature geometry list column} que contiene la geometría de cada observación (se trata de una columna tipo \texttt{list}).
Cada fila, incluyendo la geometría y otras posibles variables (denominados atributos de la geometría), se considera una característica simple (SF).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sf)}
\NormalTok{nc }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(}\FunctionTok{system.file}\NormalTok{(}\StringTok{"shape/nc.shp"}\NormalTok{, }\AttributeTok{package=}\StringTok{"sf"}\NormalTok{), }\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{nc }\OtherTok{\textless{}{-}}\NormalTok{ nc[}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{9}\SpecialCharTok{:}\DecValTok{15}\NormalTok{)]}
\NormalTok{nc}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Simple feature collection with 100 features and 7 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965
## Geodetic CRS:  NAD27
## First 10 features:
##           NAME BIR74 SID74 NWBIR74 BIR79 SID79 NWBIR79
## 1         Ashe  1091     1      10  1364     0      19
## 2    Alleghany   487     0      10   542     3      12
## 3        Surry  3188     5     208  3616     6     260
## 4    Currituck   508     1     123   830     2     145
## 5  Northampton  1421     9    1066  1606     3    1197
## 6     Hertford  1452     7     954  1838     5    1237
## 7       Camden   286     0     115   350     2     139
## 8        Gates   420     0     254   594     2     371
## 9       Warren   968     4     748  1190     2     844
## 10      Stokes  1612     1     160  2038     5     176
##                          geometry
## 1  MULTIPOLYGON (((-81.47276 3...
## 2  MULTIPOLYGON (((-81.23989 3...
## 3  MULTIPOLYGON (((-80.45634 3...
## 4  MULTIPOLYGON (((-76.00897 3...
## 5  MULTIPOLYGON (((-77.21767 3...
## 6  MULTIPOLYGON (((-76.74506 3...
## 7  MULTIPOLYGON (((-76.00897 3...
## 8  MULTIPOLYGON (((-76.56251 3...
## 9  MULTIPOLYGON (((-78.30876 3...
## 10 MULTIPOLYGON (((-80.02567 3...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(nc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Classes 'sf' and 'data.frame':   100 obs. of  8 variables:
##  $ NAME    : chr  "Ashe" "Alleghany" "Surry" "Currituck" ...
##  $ BIR74   : num  1091 487 3188 508 1421 ...
##  $ SID74   : num  1 0 5 1 9 7 0 0 4 1 ...
##  $ NWBIR74 : num  10 10 208 123 1066 ...
##  $ BIR79   : num  1364 542 3616 830 1606 ...
##  $ SID79   : num  0 3 6 2 3 5 2 2 2 5 ...
##  $ NWBIR79 : num  19 12 260 145 1197 ...
##  $ geometry:sfc_MULTIPOLYGON of length 100; first list element: List of 1
##   ..$ :List of 1
##   .. ..$ : num [1:27, 1:2] -81.5 -81.5 -81.6 -81.6 -81.7 ...
##   ..- attr(*, "class")= chr [1:3] "XY" "MULTIPOLYGON" "sfg"
##  - attr(*, "sf_column")= chr "geometry"
##  - attr(*, "agr")= Factor w/ 3 levels "constant","aggregate",..: NA NA NA NA NA NA NA
##   ..- attr(*, "names")= chr [1:7] "NAME" "BIR74" "SID74" "NWBIR74" ...
\end{verbatim}

El nombre de la columna de geometrías está almacenado en el atributo \texttt{"sf\_column"} del objeto y se puede acceder a ella mediante la función \texttt{st\_geometry()} (además de poder emplear los procedimientos habituales para acceder a los componentes de un \texttt{data.frame}).
Esta columna es un objeto de tipo \texttt{sfc} (\emph{simple feature geometry list column}), descritos más adelante.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# geom\_name \textless{}{-} attr(nc, "sf\_column")}
\CommentTok{\# nc[, geom\_name]; nc[[geom\_name]]}
\CommentTok{\# nc$geometry}
\FunctionTok{st\_geometry}\NormalTok{(nc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Geometry set for 100 features 
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965
## Geodetic CRS:  NAD27
## First 5 geometries:
\end{verbatim}

\begin{verbatim}
## MULTIPOLYGON (((-81.47276 36.23436, -81.54084 3...
\end{verbatim}

\begin{verbatim}
## MULTIPOLYGON (((-81.23989 36.36536, -81.24069 3...
\end{verbatim}

\begin{verbatim}
## MULTIPOLYGON (((-80.45634 36.24256, -80.47639 3...
\end{verbatim}

\begin{verbatim}
## MULTIPOLYGON (((-76.00897 36.3196, -76.01735 36...
\end{verbatim}

\begin{verbatim}
## MULTIPOLYGON (((-77.21767 36.24098, -77.23461 3...
\end{verbatim}

En este paquete, todos los métodos y funciones que operan sobre datos espaciales comienzan por \texttt{st\_} (\emph{spatial type}; siguiendo la implementación de PostGIS):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{methods}\NormalTok{(}\AttributeTok{class=}\StringTok{"sf"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1] $<-                   [                     [[<-                 
##   [4] aggregate             anti_join             arrange              
##   [7] as.data.frame         cbind                 coerce               
##  [10] dbDataType            dbWriteTable          distinct             
##  [13] dplyr_reconstruct     filter                full_join            
##  [16] gather                group_by              group_split          
##  [19] identify              idw                   initialize           
##  [22] inner_join            krige                 krige.cv             
##  [25] left_join             merge                 mutate               
##  [28] nest                  pivot_longer          plot                 
##  [31] print                 rbind                 rename               
##  [34] right_join            rowwise               sample_frac          
##  [37] sample_n              select                semi_join            
##  [40] separate              separate_rows         show                 
##  [43] slice                 slotsFromS3           spread               
##  [46] st_agr                st_agr<-              st_area              
##  [49] st_as_s2              st_as_sf              st_as_stars          
##  [52] st_bbox               st_boundary           st_buffer            
##  [55] st_cast               st_centroid           st_collection_extract
##  [58] st_convex_hull        st_coordinates        st_crop              
##  [61] st_crs                st_crs<-              st_difference        
##  [64] st_filter             st_geometry           st_geometry<-        
##  [67] st_inscribed_circle   st_interpolate_aw     st_intersection      
##  [70] st_intersects         st_is                 st_is_valid          
##  [73] st_join               st_line_merge         st_m_range           
##  [76] st_make_valid         st_nearest_points     st_node              
##  [79] st_normalize          st_point_on_surface   st_polygonize        
##  [82] st_precision          st_reverse            st_sample            
##  [85] st_segmentize         st_set_precision      st_shift_longitude   
##  [88] st_simplify           st_snap               st_sym_difference    
##  [91] st_transform          st_transform_proj     st_triangulate       
##  [94] st_union              st_voronoi            st_wrap_dateline     
##  [97] st_write              st_z_range            st_zm                
## [100] summarise             transform             transmute            
## [103] ungroup               unite                 unnest               
## see '?methods' for accessing help and source code
\end{verbatim}

Los objetos geométricos básicos son del tipo \texttt{sfg} (\emph{simple feature geometry}) que contienen la geometría de una única característica definida a partir de puntos en dos (XY), tres (XYZ, XYM) o cuatro dimensiones (XYZM).
Admite los 17 tipos de geometrías simples del estándar, pero de forma completa los 7 tipos básicos:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.20}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.61}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.20}}@{}}
\toprule
Tipo & Description & Creación \\
\midrule
\endhead
\texttt{POINT}, \texttt{MULTIPOINT} & Punto o conjunto de puntos & \texttt{st\_point()}, \texttt{st\_multipoint()} \\
\texttt{LINESTRING}, \texttt{MULTILINESTRING} & Línea o conjunto de líneas & \texttt{st\_linestring()}, \texttt{st\_multilinestring()} \\
\texttt{POLYGON}, \texttt{MULTIPOLYGON} & Polígono\footnote{Secuencia de puntos que forma un anillo cerrado, que no se interseca; el primero anillo definen el anillo exterior, anillos posteriores definen agujeros. Según la norma, los puntos del anillo exterior deben especificarse en sentido contrario a las agujas del reloj y los de los agujeros en sentido de las agujas del reloj.} o conjunto de polígonos & \texttt{st\_polygon()}, \texttt{st\_multipolygon()} \\
\texttt{GEOMETRYCOLLECTION} & Conjunto de geometrías de los tipos anteriores & \texttt{st\_geometrycollection()} \\
\bottomrule
\end{longtable}

Las geometrías se imprimen empleando la representación \emph{well-known text} (WKT) del estándar (se exportan empleando la representación \emph{well-known binary}, WKB).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nc}\SpecialCharTok{$}\NormalTok{geometry[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## MULTIPOLYGON (((-81.47276 36.23436, -81.54084 36.27251, -81.56198 36.27359, -81.63306 36.34069, -81.74107 36.39178, -81.69828 36.47178, -81.7028 36.51934, -81.67 36.58965, -81.3453 36.57286, -81.34754 36.53791, -81.32478 36.51368, -81.31332 36.4807, -81.26624 36.43721, -81.26284 36.40504, -81.24069 36.37942, -81.23989 36.36536, -81.26424 36.35241, -81.32899 36.3635, -81.36137 36.35316, -81.36569 36.33905, -81.35413 36.29972, -81.36745 36.2787, -81.40639 36.28505, -81.41233 36.26729, -81.43104 36.26072, -81.45289 36.23959, -81.47276 36.23436)))
\end{verbatim}

Los objetos básicos \texttt{sfg} (normalmente del mismo tipo) se pueden combinar en un objeto \texttt{sfc} (\emph{simple feature geometry list column}) mediante la función \texttt{st\_sfg()}.
Estos objetos pueden incorporar un sistema de referencia de coordenadas (por defecto \texttt{NA\_crs\_}), descritos en la Sección \ref{crs}.
Posteriormente se puede crear un objeto \texttt{sf} mediante la función \texttt{st\_sf()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{st\_point}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{8.395835}\NormalTok{, }\FloatTok{43.37087}\NormalTok{))}
\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{st\_point}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{7.555851}\NormalTok{, }\FloatTok{43.01208}\NormalTok{))}
\NormalTok{p3 }\OtherTok{\textless{}{-}} \FunctionTok{st\_point}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{7.864641}\NormalTok{, }\FloatTok{42.34001}\NormalTok{))}
\NormalTok{p4 }\OtherTok{\textless{}{-}} \FunctionTok{st\_point}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{8.648053}\NormalTok{, }\FloatTok{42.43362}\NormalTok{))}
\NormalTok{sfc }\OtherTok{\textless{}{-}} \FunctionTok{st\_sfc}\NormalTok{(}\FunctionTok{list}\NormalTok{(p1, p2, p3, p4))}
\NormalTok{cprov }\OtherTok{\textless{}{-}} \FunctionTok{st\_sf}\NormalTok{(}\AttributeTok{names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Coruña (A)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Lugo\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Ourense\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Pontevedra\textquotesingle{}}\NormalTok{),}
    \AttributeTok{geom =}\NormalTok{ sfc)}
\NormalTok{cprov}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Simple feature collection with 4 features and 1 field
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -8.648053 ymin: 42.34001 xmax: -7.555851 ymax: 43.37087
## CRS:           NA
##        names                       geom
## 1 Coruña (A) POINT (-8.395835 43.37087)
## 2       Lugo POINT (-7.555851 43.01208)
## 3    Ourense POINT (-7.864641 42.34001)
## 4 Pontevedra POINT (-8.648053 42.43362)
\end{verbatim}

Esta forma de proceder puede resultar de interés cuando se construyen geometrías tipo líneas o polígonos, pero en el caso de datos puntuales (las observaciones habituales en geoestadística), resulta mucho más cómodo emplear un \texttt{data.frame} que incluya las coordenadas en columnas y convertirlo a un objeto \texttt{sf} mediante la función \texttt{st\_as\_sf()}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{exercise}[Creación de una columna de geometrías]
\protect\hypertarget{exr:sfc}{}{\label{exr:sfc} \iffalse (Creación de una columna de geometrías) \fi{} }Crear una geometría (un objeto \texttt{sfc}) formada por: dos puntos en las posiciones
(1,5) y (5,5), una línea entre los puntos (1,1) y (5,1), y un polígono, con vértices
\{(0,0), (6,0), (6,6), (0,6), (0,0)\} y con un agujero con vértices \{(2,2), (2,4),
(4,4), (4,2), (2,2)\} (NOTA: consultar la ayuda \texttt{?st}, puede resultar cómodo emplear
\texttt{matrix(...\ ,\ ncol\ =\ 2,\ byrow\ =\ TRUE)}).
\end{exercise}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Como ejemplo consideraremos el conjunto de datos \texttt{meuse} del paquete \texttt{sp} que contiene concentraciones de metales pesados, junto con otras variables del terreno, en una zona de inundación del río Meuse (cerca de Stein, Holanda)\footnote{Empleado en la \href{https://cran.r-project.org/web/packages/gstat/vignettes/gstat.pdf}{viñeta} del paquete \texttt{gstat} con el paquete \texttt{sp}.} (ver Figura \ref{fig:meuse-sf}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(meuse, }\AttributeTok{package=}\StringTok{"sp"}\NormalTok{)}
\FunctionTok{str}\NormalTok{(meuse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    155 obs. of  14 variables:
##  $ x      : num  181072 181025 181165 181298 181307 ...
##  $ y      : num  333611 333558 333537 333484 333330 ...
##  $ cadmium: num  11.7 8.6 6.5 2.6 2.8 3 3.2 2.8 2.4 1.6 ...
##  $ copper : num  85 81 68 81 48 61 31 29 37 24 ...
##  $ lead   : num  299 277 199 116 117 137 132 150 133 80 ...
##  $ zinc   : num  1022 1141 640 257 269 ...
##  $ elev   : num  7.91 6.98 7.8 7.66 7.48 ...
##  $ dist   : num  0.00136 0.01222 0.10303 0.19009 0.27709 ...
##  $ om     : num  13.6 14 13 8 8.7 7.8 9.2 9.5 10.6 6.3 ...
##  $ ffreq  : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
##  $ soil   : Factor w/ 3 levels "1","2","3": 1 1 1 2 2 2 2 1 1 2 ...
##  $ lime   : Factor w/ 2 levels "0","1": 2 2 2 1 1 1 1 1 1 1 ...
##  $ landuse: Factor w/ 15 levels "Aa","Ab","Ag",..: 4 4 4 11 4 11 4 2 2 15 ...
##  $ dist.m : num  50 30 150 270 380 470 240 120 240 420 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ?meuse }
\CommentTok{\# Sistema de coordenadas Rijksdriehoek (RDH) (Netherlands topographical) }
\CommentTok{\# https://epsg.io/28992 \# EPSG:28992}
\NormalTok{meuse\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_as\_sf}\NormalTok{(meuse, }\AttributeTok{coords =} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{), }\AttributeTok{crs =} \DecValTok{28992}\NormalTok{, }\AttributeTok{agr =} \StringTok{"constant"}\NormalTok{)}

\CommentTok{\# Rio Meuse }
\FunctionTok{data}\NormalTok{(meuse.riv, }\AttributeTok{package=}\StringTok{"sp"}\NormalTok{)}
\FunctionTok{str}\NormalTok{(meuse.riv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  num [1:176, 1:2] 182004 182137 182252 182315 182332 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meuse\_riv }\OtherTok{\textless{}{-}} \FunctionTok{st\_sfc}\NormalTok{(}\FunctionTok{st\_polygon}\NormalTok{(}\FunctionTok{list}\NormalTok{(meuse.riv)), }\AttributeTok{crs =} \DecValTok{28992}\NormalTok{)}

\CommentTok{\# Rejilla}
\FunctionTok{data}\NormalTok{(meuse.grid, }\AttributeTok{package=}\StringTok{"sp"}\NormalTok{)}
\FunctionTok{str}\NormalTok{(meuse.grid)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    3103 obs. of  7 variables:
##  $ x     : num  181180 181140 181180 181220 181100 ...
##  $ y     : num  333740 333700 333700 333700 333660 ...
##  $ part.a: num  1 1 1 1 1 1 1 1 1 1 ...
##  $ part.b: num  0 0 0 0 0 0 0 0 0 0 ...
##  $ dist  : num  0 0 0.0122 0.0435 0 ...
##  $ soil  : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
##  $ ffreq : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meuse\_grid }\OtherTok{\textless{}{-}} \FunctionTok{st\_as\_sf}\NormalTok{(meuse.grid, }\AttributeTok{coords =} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{), }
                       \AttributeTok{crs =} \DecValTok{28992}\NormalTok{, }\AttributeTok{agr =} \StringTok{"constant"}\NormalTok{)}
\CommentTok{\# Almacenar}
\CommentTok{\# save(meuse\_sf, meuse\_riv, meuse\_grid, file = "datos/st\_meuse.RData")}

\CommentTok{\# Representar}
\FunctionTok{plot}\NormalTok{(meuse\_sf[}\StringTok{"zinc"}\NormalTok{], }\AttributeTok{pch =} \DecValTok{16}\NormalTok{, }\AttributeTok{cex =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{main =} \StringTok{""}\NormalTok{,}
     \AttributeTok{breaks =} \StringTok{"quantile"}\NormalTok{, }\AttributeTok{key.pos =} \DecValTok{4}\NormalTok{, }\AttributeTok{reset =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(meuse\_riv, }\AttributeTok{col =} \StringTok{"lightblue"}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(}\FunctionTok{st\_geometry}\NormalTok{(meuse\_grid), }\AttributeTok{pch =} \DecValTok{3}\NormalTok{, }\AttributeTok{cex =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{col =} \StringTok{"lightgray"}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{02-datos_files/figure-latex/meuse-sf-1} 

}

\caption{Concentración de zinc (ppm) en el entorno del río Meuse (datos `sp::meuse`).}\label{fig:meuse-sf}
\end{figure}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{exercise}[Creación y representación de datos espaciales]
\protect\hypertarget{exr:aquifer1}{}{\label{exr:aquifer1} \iffalse (Creación y representación de datos espaciales) \fi{} }Cargar los datos del acuífero Wolfcamp (\emph{aquifer.RData}), generar el correspondiente
objeto \texttt{sf} y representarlo mostrando los ejes.
\end{exercise}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{crs}{%
\subsection{Sistemas de referencia de coordenadas}\label{crs}}

El sistema de referencia de coordenadas (CRS) especifica la correspondencia entre valores de las coordenadas y puntos concretos en la superficie de la Tierra (o del espacio), y resulta fundamental cuando se combinan datos espaciales.
En general se consideran dos tipos de CRS:

\begin{itemize}
\item
  Geodésico: las coordenadas en tres dimensiones (latitud, longitud y altura) se basan en un elipsoide de referencia (global o local) que sirve como aproximación del globo terrestre (se tiene en cuenta que no es una esfera perfecta e incluso que puede haber variaciones locales). Este elipsoide, junto con información adicional sobre como interpretar las coordenadas (incluyendo el orden y el origen), define el denominado \emph{datum}. Normalmente se asume que las coordenadas son en la superficie terrestre y solo se consideran:

  \begin{itemize}
  \tightlist
  \item
    latitud: ángulo entre el plano ecuatorial y la línea que une la posición con el centro de la Tierra. Varía desde -90 (polo sur) hasta 90 (polo norte). Un grado equivale aproximadamente a 110.6 km. Los paralelos son las líneas en la superficie terrestre correspondientes a la misma latitud (siendo el 0 el ecuador).
  \item
    longitud: ángulo (paralelo al plano ecuatorial) entre un meridiano de referencia (arco máximo que une los polos pasando por una determinado punto, normalmente el observatorio de Greenwich) y la línea que une la posición con el centro de la Tierra. Varía desde -180 (oeste) hasta 180 (este). Un grado en el ecuador equivale a aproximadamente a 111.3 km. Los meridianos son las líneas en la superficie terrestre correspondientes a la misma longitud (siendo el 0 el meridiano de Greenwich y -180 o 180 el correspondiente antimeridiano).
  \end{itemize}

  La rejilla correspondiente a un conjunto de paralelos y meridianos se denomina \emph{gratícula} (ver \texttt{st\_graticule()}).

  \begin{figure}[!htb]

    {\centering \includegraphics[width=0.85\linewidth]{images/Latitud_y_Longitud} 

    }

    \caption{Coordenadas geográficas en la superficie terrestre (Fuente Wikimedia Commons).}\label{fig:latlon}
    \end{figure}

  Uno de los CRS más empleados es el WGS84 (\emph{World Geodetic System 1984}) en el que se basa el \emph{Sistema de Posicionamiento Global} (GPS).
\item
  Proyectado (cartesiano): sistema (local) en dos dimensiones que facilita algún tipo de cálculo (normalmente distancias o áreas). Por ejemplo el UTM (\emph{Universal Transverse Mercator}), que emplea coordenadas en metros respecto a una cuadrícula de referencia (se divide la tierra en 60 husos de longitud, numerados, y 20 bandas de latitud, etiquetadas con letras; por ejemplo Galicia se encuentra en la cuadricula 29T). Se define relacionando estas coordenadas cartesianas con coordenadas geodésicas con un determinado datum.
\end{itemize}

En \texttt{sf} se emplea la librería \href{http://proj.org/}{PRØJ} para definir el CRS y convertir coordenadas en distintos sistemas\footnote{El paquete \texttt{sf} admite las últimas versiones PROJ 5 y 6, incluyendo el formato WKT-2 de 2019, mientras que el paquete \texttt{sp} está diseñado para cadenas de texto \emph{PROJ.4} que se recomiendan abandonar (las últimas versiones permiten añadir una cadena WKT2 como \texttt{comment}).}.
Para obtener o establecer el CRS se puede emplear la función \texttt{st\_crs()}.
Se puede especificar mediante una cadena de texto que admita \href{https://gdal.org/tutorials/osr_api_tut.html}{GDAL} (por ejemplo \texttt{"WGS84"}, que se corresponde con el \emph{World Geodetic System 1984}), que típicamente es de la forma ESTÁNDAR:CÓDIGO (también puede ser una cadena de texto \emph{PROJ.4}).
El estándar más empleado es el \href{https://epsg.org}{EPSG} (\emph{European Petroleum Survey Group}), y es que que da por hecho el paquete \texttt{sf} cuando se especifica el CRS mediante un número.
También admite el estándar \href{http://www.opengeospatial.org/standards/wkt-crs}{OGC WKT} (\emph{Open Geospatial Consortium well-known text}) que es el que emplea internamente, pero resulta complicado manejar en la práctica.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{st\_crs}\NormalTok{(}\StringTok{"WGS84"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Coordinate Reference System:
##   User input: WGS84 
##   wkt:
## GEOGCRS["WGS 84",
##     DATUM["World Geodetic System 1984",
##         ELLIPSOID["WGS 84",6378137,298.257223563,
##             LENGTHUNIT["metre",1]]],
##     PRIMEM["Greenwich",0,
##         ANGLEUNIT["degree",0.0174532925199433]],
##     CS[ellipsoidal,2],
##         AXIS["geodetic latitude (Lat)",north,
##             ORDER[1],
##             ANGLEUNIT["degree",0.0174532925199433]],
##         AXIS["geodetic longitude (Lon)",east,
##             ORDER[2],
##             ANGLEUNIT["degree",0.0174532925199433]],
##     ID["EPSG",4326]]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all.equal}\NormalTok{(}\FunctionTok{st\_crs}\NormalTok{(}\DecValTok{4326}\NormalTok{), }\FunctionTok{st\_crs}\NormalTok{(}\StringTok{"EPSG:4326"}\NormalTok{), }\FunctionTok{st\_crs}\NormalTok{(}\StringTok{"WGS84"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{st\_crs}\NormalTok{(nc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Coordinate Reference System:
##   User input: NAD27 
##   wkt:
## GEOGCRS["NAD27",
##     DATUM["North American Datum 1927",
##         ELLIPSOID["Clarke 1866",6378206.4,294.978698213898,
##             LENGTHUNIT["metre",1]]],
##     PRIMEM["Greenwich",0,
##         ANGLEUNIT["degree",0.0174532925199433]],
##     CS[ellipsoidal,2],
##         AXIS["latitude",north,
##             ORDER[1],
##             ANGLEUNIT["degree",0.0174532925199433]],
##         AXIS["longitude",east,
##             ORDER[2],
##             ANGLEUNIT["degree",0.0174532925199433]],
##     ID["EPSG",4267]]
\end{verbatim}

En \href{https://spatialreference.org}{spatialreference.org} se puede obtener información detallada sobre una gran cantidad de proyecciones (y permite realizar búsquedas).
También puede ser de utilidad \href{https://epsg.io}{epsg.io} o este \href{https://proj.org/operations/projections}{listado} con detalles de los parámetros.

El CRS ideal dependerá del tipo de problema y de la zona cubierta por los datos (ver e.g Lovelace et al, 2021, \href{https://geocompr.robinlovelace.net/reproj-geo-data.html\#which-crs-to-use}{Sección 6.3}, para más información).
En general en estadística espacial nos interesará trabajar con coordenadas proyectadas, de forma que tenga sentido emplear la distancia euclídea (algo que puede ser poco o nada razonable si se trabaja con coordenadas geodésicas en una zona muy amplia del globo o cerca de los polos).
En el caso de coordenadas sin proyectar (latitud/longitud) puede ser preferible trabajar con distancias ortodrómicas (longitud del arco del círculo máximo que une los puntos, \emph{great circle distances})\footnote{Algo que ya hace de forma automática el paquete \texttt{gstat}.}.
Es importante destacar que cambiar el CRS no reproyecta los datos, hay que emplear \texttt{st\_transform()} para hacerlo, como se describe en la Sección \ref{operaciones-datos}.

Finalmente hay que insistir también en que el campo de aplicación de la estadística espacial no se restringe al análisis de datos geográficos (por ejemplo nos puede interesar analizar el desgaste en la pared de un crisol empleado en fundición) y en estos casos los CRS geográficos carecen de sentido.
De todos modos habrá que emplear un sistema de coordenadas que permita calcular algún tipo de salto o distancia entre puntos (aunque siempre se pueden considerar coordenadas espaciales tres dimensiones con la distancia euclídea).

\hypertarget{tidyverse-sf}{%
\subsection{\texorpdfstring{Integración con el ecosistema \textbf{tidyverse}}{Integración con el ecosistema tidyverse}}\label{tidyverse-sf}}

El paquete \texttt{sf} es compatible con \href{http://tidyverse.org}{\texttt{tidyverse}} y proporciona métodos para interactuar con los paquetes \href{https://dplyr.tidyverse.org}{\texttt{dplyr}},
\href{http://tidyr.tidyverse.org}{\texttt{tidyr}} y \href{https://ggplot2.tidyverse.org}{\texttt{ggplot2}}.

Algunos de los métodos de interés para manipular datos espaciales con el paquete \href{https://dplyr.tidyverse.org}{\texttt{dplyr}} son:

\begin{itemize}
\tightlist
\item
  \texttt{filter()}, \texttt{select()}, \texttt{mutate()}, \texttt{summarise(...,\ do\_union\ =\ TRUE,\ is\_coverage\ =\ FALSE)}, \texttt{group\_by()}, \texttt{ungroup()}, etc.
\item
  \texttt{inner\_join()}, \texttt{left\_join()}, \texttt{right\_join()}, \texttt{full\_join()}, \texttt{semi\_join()}, \texttt{anti\_join()}, \texttt{st\_join()}.
\item
  \texttt{st\_drop\_geometry()}, \texttt{st\_set\_crs()}.
\end{itemize}

Para detalles ver la \href{https://r-spatial.github.io/sf/reference/tidyverse.html}{referencia}.

En el caso del paquete \href{https://ggplot2.tidyverse.org}{\texttt{ggplot2}} se puede consultar la \href{https://ggplot2.tidyverse.org/reference/ggsf.html}{referencia} y el tutorial \emph{Drawing beautiful maps programmatically with R, sf and ggplot2}:

\begin{itemize}
\tightlist
\item
  \href{https://r-spatial.org/r/2018/10/25/ggplot2-sf.html}{Part 1: Basics (General concepts illustrated with the world Map)}.
\item
  \href{https://r-spatial.org/r/2018/10/25/ggplot2-sf-2.html}{Part 2: Layers (Adding additional layers: an example with points and polygons)}.
\item
  \href{https://r-spatial.org/r/2018/10/25/ggplot2-sf-3.html}{Part 3: Layouts (Positioning and layout for complex maps)}.
\end{itemize}

Por ejemplo, se puede generar un gráfico similar al de la Figura \ref{fig:mortalidad} (porcentaje de incremento de las defunciones en el año 2020 respecto al 2019 en las CCAA españolas; datos \href{https://www.ine.es/jaxiT3/Tabla.htm?t=6546}{INE}), con el siguiente código:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(tidyr)}
\FunctionTok{library}\NormalTok{(sf)}
\FunctionTok{library}\NormalTok{(mapSpain) }\CommentTok{\# install.packages("mapSpain")}
\FunctionTok{load}\NormalTok{(}\StringTok{"datos/mortalidad.RData"}\NormalTok{)}

\NormalTok{mort\_sf }\OtherTok{\textless{}{-}}\NormalTok{ mortalidad }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\NormalTok{ccaa.code }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"00"}\NormalTok{, }\StringTok{"99"}\NormalTok{), periodo }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"2019"}\NormalTok{, }\StringTok{"2020"}\NormalTok{), sexo }\SpecialCharTok{==} \StringTok{"Total"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{sexo, }\SpecialCharTok{{-}}\NormalTok{ccaa.name) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ periodo, }\AttributeTok{values\_from =}\NormalTok{ value, }\AttributeTok{names\_prefix =} \StringTok{"mort."}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{incremento =} \DecValTok{100}\SpecialCharTok{*}\NormalTok{(mort}\FloatTok{.2020} \SpecialCharTok{{-}}\NormalTok{ mort}\FloatTok{.2019}\NormalTok{)}\SpecialCharTok{/}\NormalTok{mort}\FloatTok{.2019}\NormalTok{)}

\CommentTok{\# CUIDADO: el primer elemento de xxx\_join debe ser un objeto sf}
\CommentTok{\# para que lo procese el paquete sf}
\NormalTok{mort\_sf }\OtherTok{\textless{}{-}} \FunctionTok{esp\_get\_ccaa}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(mort\_sf, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"codauto"} \OtherTok{=} \StringTok{"ccaa.code"}\NormalTok{))}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{ggplot}\NormalTok{(mort\_sf) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ incremento), }\AttributeTok{color =} \StringTok{"grey70"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_gradientn}\NormalTok{(}\AttributeTok{colors =} \FunctionTok{hcl.colors}\NormalTok{(}\DecValTok{10}\NormalTok{, }\StringTok{"Blues"}\NormalTok{, }\AttributeTok{rev =} \ConstantTok{TRUE}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf\_label}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =} \FunctionTok{paste0}\NormalTok{(}\FunctionTok{round}\NormalTok{(incremento, }\DecValTok{1}\NormalTok{), }\StringTok{"\%"}\NormalTok{)), }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{data =} \FunctionTok{esp\_get\_can\_box}\NormalTok{(), }\AttributeTok{color =} \StringTok{"grey70"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme\_void}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{02-datos_files/figure-latex/dplyr-ggplot-1} 

}

\caption{Ejemplo de gráfico generado empleando los paquetes `dplyr` y `ggplot2`.}\label{fig:dplyr-ggplot}
\end{figure}

{[}Figura \ref{fig:dplyr-ggplot}{]}

Sin embargo, en este libro se supone que no se está familiarizado con estas herramientas y se evitará su uso (aunque pueden resultar más cómodas después de su aprendizaje).
Para una introducción a \href{https://dplyr.tidyverse.org}{\texttt{dplyr}}, ver por ejemplo la viñeta \href{https://cran.rstudio.com/web/packages/dplyr/vignettes/dplyr.html}{Introduction to dplyr},
el \href{http://r4ds.had.co.nz/transform.html}{Capítulo 5} del libro \href{http://r4ds.had.co.nz}{R for Data Science} o el \href{https://gltaboada.github.io/tgdbook/dplyr.html}{Capítulo 4} de los apuntes \href{https://gltaboada.github.io/tgdbook}{Prácticas de Tecnologías de Gestión y Manipulación de Datos}.

No obstante, en ciertas ocasiones emplearemos el operador \emph{pipe} \texttt{\%\textgreater{}\%} (tubería, redirección) por comodidad.
Este operador permite canalizar la salida de una función a la entrada de otra.
Por ejemplo \texttt{segundo(primero(datos))} se traduce en \texttt{datos\ \%\textgreater{}\%\ primero\ \%\textgreater{}\%\ segundo}
(facilitando la lectura de expresiones de izquierda a derecha).

\hypertarget{sf-plot}{%
\section{Representación de datos espaciales}\label{sf-plot}}

El paquete \texttt{sf} implementa métodos \texttt{plot()} para la representación de objetos espaciales (ver \href{https://r-spatial.github.io/sf/reference/plot.html}{\texttt{?plot.sf}}).
Estos métodos suelen ser la forma más rápida de generar gráficos básicos (estáticos), pero también se pueden emplear otros paquetes como \href{https://ggplot2.tidyverse.org}{\texttt{ggplot2}} (Sección \ref{tidyverse-sf}), \href{https://r-tmap.github.io/tmap}{\texttt{tmap}}, \href{https://riatelab.github.io/mapsf}{\texttt{mapsf}}, \href{https://rstudio.github.io/leaflet}{\texttt{leaflet}}, \href{https://r-spatial.github.io/mapview}{\texttt{mapview}}, \href{https://symbolixau.github.io/mapdeck}{\texttt{mapdeck}} o \href{https://github.com/dkahle/ggmap}{\texttt{ggmap}}, para generar mapas más avanzados, incluyendo mapas dinámicos.
Para una introducción a las posibilidades gráficas con el paquete \texttt{sf} se puede consultar la viñeta \href{https://r-spatial.github.io/sf/articles/sf5.html}{\emph{Plotting Simple Features}}.

El método \texttt{plot()} es de la forma:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, ..., max.plot, }\AttributeTok{pal =} \ConstantTok{NULL}\NormalTok{, nbreaks, }\AttributeTok{breaks =} \StringTok{"pretty"}\NormalTok{, }
\NormalTok{     key.pos, key.length, key.width, }\AttributeTok{extent =}\NormalTok{ x, }\AttributeTok{axes =} \ConstantTok{FALSE}\NormalTok{, }
     \AttributeTok{graticule =}\NormalTok{ NA\_crs\_, }\AttributeTok{col\_graticule =} \StringTok{"grey"}\NormalTok{, border, }\AttributeTok{reset =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \texttt{x}: objeto de tipo \texttt{sf} o \texttt{sfc}.
\item
  \texttt{max.plot}: número máximo de atributos que se representarán.
\item
  \texttt{pal}: función que genera la paleta de colores (ver e.g.~\texttt{?rainbow}), por defecto \texttt{sf.colors} (ver Figura \ref{fig:multi-plot-sf}).
\item
  \texttt{nbreaks}: número de puntos de corte para la clave de color.
\item
  \texttt{breaks}: vector de puntos de corte o cadena de texto válida para el argumento \texttt{style} de \texttt{classIntervals} (ver figuras: \ref{fig:meuse-sf}, \ref{fig:multi-plot-sf}).
\item
  \texttt{key.pos}: posición de la leyenda, -1 = automática, 0 = error?, 1 = abajo, 2 = izquierda, 3 = arriba, 4 = derecha, NULL = omitir. Cuando se representan múltiples atributos se añade una única leyenda común únicamente si se establece (ver figuras: \ref{fig:multi-plot-sf}, \ref{fig:transform}).
\item
  \texttt{key.length}, \texttt{key.width}: dimensiones de la leyenda (proporción de espacio).
\item
  \texttt{extent}: objeto con método \texttt{st\_bbox()} para definir los límites (sustituyendo a \texttt{xlim} e \texttt{ylim}).
\item
  \texttt{axes}: lógico; \texttt{TRUE} para dibujar los ejes.
\item
  \texttt{graticule}: lógico, objeto de clase \texttt{crs} (\texttt{st\_crs()}) u objeto creado por \texttt{st\_graticule}; \texttt{TRUE} representará la gratícula \texttt{st\_graticule(x)} (ver Figura \ref{fig:transform}).
\item
  \texttt{col\_graticule}: color de la gratícula.
\item
  \texttt{border}: color de los bordes de polígonos.
\item
  \texttt{reset}: lógico; si el gráfico contiene una leyenda se modifican los parámetros gráficos y por defecto los restaura (\texttt{reset\ =\ TRUE}). Solo en ese caso es necesario establecer \texttt{reset\ =\ FALSE} para continuar añadiendo elementos, con \texttt{add\ =\ TRUE} (para restaurarlos hay que ejecutar \texttt{dev.off()}) (ver figuras: \ref{fig:meuse-sf}, \ref{fig:transform}).
\item
  \texttt{...}: otros parámetros gráficos (ver \texttt{?plot.default} y \texttt{?par}).
\end{itemize}

Ejemplo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(viridis)}
\FunctionTok{plot}\NormalTok{(nc[}\FunctionTok{c}\NormalTok{(}\StringTok{"SID74"}\NormalTok{, }\StringTok{"SID79"}\NormalTok{)], }\AttributeTok{pal =}\NormalTok{ viridis, }\AttributeTok{border =} \StringTok{\textquotesingle{}grey70\textquotesingle{}}\NormalTok{, }\AttributeTok{logz =} \ConstantTok{TRUE}\NormalTok{, }
     \AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{, }\AttributeTok{len =} \DecValTok{9}\NormalTok{), }\AttributeTok{at =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{1.5}\NormalTok{, }\DecValTok{2}\NormalTok{), }
     \AttributeTok{key.pos =} \DecValTok{1}\NormalTok{, }\AttributeTok{key.width =} \FunctionTok{lcm}\NormalTok{(}\FloatTok{1.2}\NormalTok{), }\AttributeTok{key.length =} \FloatTok{0.8}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{02-datos_files/figure-latex/multi-plot-sf-1} 

}

\caption{Ejemplo de gráfico con múltiples atributos (con colores personalizados y leyenda común, en escala logarítmica personalizada).}\label{fig:multi-plot-sf}
\end{figure}

El paquete \href{https://r-tmap.github.io/tmap}{\texttt{tmap}} permite generar mapas temáticos con una gramática similar a la de \texttt{ggplot2} pero enfocada a mapas.
Por defecto crea mapas estáticos (\texttt{tmap\_mode("plot")}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tmap)}
\FunctionTok{tm\_shape}\NormalTok{(nc) }\SpecialCharTok{+} \FunctionTok{tm\_polygons}\NormalTok{(}\StringTok{"SID79"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{02-datos_files/figure-latex/tmap-plot-1} 

}

\caption{Ejemplo de mapa estático creado con `tmap`.}\label{fig:tmap-plot}
\end{figure}

Aunque puede crear mapas interactivos, en páginas html, utilizando el paquete \href{https://rstudio.github.io/leaflet}{\texttt{leaflet}} (interfaz a la librería JavaScript \href{https://leafletjs.com}{Leaflet}), implementando también leyendas, ventanas emergentes al pulsar con el ratón en las características y soporte para datos rasterizados.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tmap\_mode}\NormalTok{(}\StringTok{"view"}\NormalTok{)}
\FunctionTok{tmap\_last}\NormalTok{()}
\CommentTok{\# Error en bookdown}
\end{Highlighting}
\end{Shaded}

Para más información ver el capítulo \href{https://geocompr.robinlovelace.net/adv-map.html\#adv-map}{Making maps with R} del libro \href{https://geocompr.robinlovelace.net}{Geocomputation with R}, la \href{https://r-tmap.github.io/tmap/articles/tmap-getstarted.html}{viñeta} del paquete, o el borrador del libro \href{https://r-tmap.github.io}{Elegant and informative maps with tmap}.

El paquete \href{https://r-spatial.github.io/mapview}{\texttt{mapview}} también permite crear mapas interactivos utilizando el paquete \href{https://rstudio.github.io/leaflet}{\texttt{leaflet}} (con funcionalidades añadidas) o el paquete \href{https://symbolixau.github.io/mapdeck}{\texttt{mapdeck}} (diseñado para grandes conjuntos de datos espaciales).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mapview)}
\FunctionTok{mapview}\NormalTok{(nc, }\AttributeTok{zcol =} \StringTok{"SID79"}\NormalTok{)}
\CommentTok{\# Error en bookdown}
\end{Highlighting}
\end{Shaded}

Para más información ver las \href{https://r-spatial.github.io/mapview/articles/articles/mapview_01-basics.html}{viñetas} del paquete.

\hypertarget{operaciones-datos}{%
\section{Operaciones con datos espaciales}\label{operaciones-datos}}

A continuación se describe una selección de las herramientas disponibles para datos espaciales.
Para un listado completo de las funciones implementadas en el paquete \texttt{sf} se puede consultar la \href{https://r-spatial.github.io/sf/reference/index.html}{referencia} (o la ``\href{https://github.com/rstudio/cheatsheets/blob/master/sf.pdf}{chuleta}'', aunque puede contener algunos errores).

Puede que algunas herramientas (o recursos) admitan únicamente objetos \texttt{Spatial*} del paquete \texttt{sp}, aunque siempre se pueden emplear las funciones para convertir tipos de objetos:

\begin{itemize}
\tightlist
\item
  \texttt{st\_as\_sf(x,\ ...)}: convierte \texttt{x} a un objeto \texttt{sf} (por ejemplo objetos \texttt{Spatial*}).
\item
  \texttt{as(x,\ "Spatial")}: convierte \texttt{x} a un objeto \texttt{Spatial*}.
\end{itemize}

\hypertarget{importaciuxf3n-y-exportaciuxf3n-de-datos-espaciales}{%
\subsection{Importación y exportación de datos espaciales}\label{importaciuxf3n-y-exportaciuxf3n-de-datos-espaciales}}

El paquete \texttt{sf} permite importar y exportar una gran cantidad de formatos de datos espaciales, almacenados en ficheros o en bases de datos, mediante las funciones \texttt{st\_read()} y \texttt{st\_write()}.
Como se mostró al principio de la Sección \ref{sf-intro}, estas funciones deducen el formato automáticamente a partir de la extensión del archivo (por ejemplo \emph{.shp} para \emph{ESRI Shapefile}) o a partir del prefijo (por ejemplo \emph{PG:} para \emph{PostGIS/PostgreSQL}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dir }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"shape"}\NormalTok{, }\AttributeTok{package=}\StringTok{"sf"}\NormalTok{)}
\FunctionTok{list.files}\NormalTok{(dir, }\AttributeTok{pattern=}\StringTok{"\^{}[nc]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "nc.dbf" "nc.prj" "nc.shp" "nc.shx"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ESRI Shapefile, consta de por lo menos de 3 ficheros, el principal .shp}
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(dir, }\StringTok{"/nc.shp"}\NormalTok{)}
\NormalTok{file}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "C:/Program Files/R/R-4.1.1/library/sf/shape/nc.shp"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nc\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Reading layer `nc' from data source 
##   `C:\Program Files\R\R-4.1.1\library\sf\shape\nc.shp' using driver `ESRI Shapefile'
## Simple feature collection with 100 features and 14 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965
## Geodetic CRS:  NAD27
\end{verbatim}

Se admiten los formatos de datos vectoriales \href{https://gdal.org/drivers/vector/index.html}{soportados por GDAL} (que emplea internamente),
se puede obtener un listado con la función \texttt{st\_drivers()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{drivers }\OtherTok{\textless{}{-}} \FunctionTok{st\_drivers}\NormalTok{()}
\FunctionTok{str}\NormalTok{(drivers)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    89 obs. of  7 variables:
##  $ name     : chr  "ESRIC" "FITS" "PCIDSK" "netCDF" ...
##  $ long_name: chr  "Esri Compact Cache" "Flexible Image Transport System" "PCIDSK Database File" "Network Common Data Format" ...
##  $ write    : logi  FALSE TRUE TRUE TRUE TRUE TRUE ...
##  $ copy     : logi  FALSE FALSE FALSE TRUE TRUE TRUE ...
##  $ is_raster: logi  TRUE TRUE TRUE TRUE TRUE TRUE ...
##  $ is_vector: logi  TRUE TRUE TRUE TRUE TRUE TRUE ...
##  $ vsi      : logi  TRUE FALSE TRUE FALSE TRUE TRUE ...
\end{verbatim}

Además, se han desarrollado una gran cantidad de paquetes de R que permiten acceder directamente desde R a datos espaciales.
Muchos incluyen conjuntos de datos espaciales y otros implementan interfaces a bases de datos espaciales o geoportales disponibles en Internet.
Algunos de ellos son los siguientes:

\begin{itemize}
\tightlist
\item
  \href{https://docs.ropensci.org/rnaturalearth/}{\texttt{rnaturalearth}}: permite importar una gran cantidad de datos vectoriales y rasterizados de \href{http://www.naturalearthdata.com}{Natural Earth}, incluyendo datos administrativos/culturales (fronteras de países, aeropuertos, carreteras, vías férreas\ldots) y físicos (costas, lagos\ldots).
\item
  \href{https://ropengov.github.io/giscoR/}{\texttt{giscoR}}: permite importar datos de \href{https://ec.europa.eu/eurostat/web/gisco}{Eurostat - GISCO} (\emph{Geographic Information System of the COmmission}).
\item
  \href{https://ropenspain.github.io/mapSpain}{\texttt{mapSpain}}: permite importar límites administrativos de España (CCAA, provincias, municipios\ldots).
\item
  \href{https://CRAN.R-project.org/package=osmdata}{\texttt{osmdata}}: permite importar ``pequeños'' conjuntos de datos de \href{https://www.openstreetmap.org}{OpenStreetMap} (OSM).
\item
  \href{https://CRAN.R-project.org/package=osmextract}{\texttt{osmextract}}: permite importar grandes conjuntos de datos de OSM.
\item
  \href{https://github.com/eblondel/ows4R/wiki}{\texttt{ows4R}}: (en desarrollo) proporciona una interfaz para \emph{\href{https://www.ogc.org/docs/is}{OGC standard Web-Services}} (OWS).
\item
  \href{https://open-eo.github.io/openeo-r-client}{\texttt{openeo}}: permite importar datos de servidores \href{https://openeo.org}{openEO} (\emph{Open Earth Observation data}).
\item
  \href{https://CRAN.R-project.org/package=rnoaa}{\texttt{rnoaa}}: permite importar datos climáticos de la \href{https://www.ncdc.noaa.gov/cdo-web/webservices/v2}{National Oceanic and Atmospheric Administration} (NOAA).
\item
  \href{https://ropenspain.github.io/climaemet}{\texttt{climaemet}}: permite importar datos climáticos proporcionados por la \href{https://opendata.aemet.es}{Agencia Estatal de Meteorología de España} (AEMET).
\item
  \href{https://github.com/oscarperpinan/meteoForecast}{\texttt{meteoForecast}}: permite importar resultados de los modelos numéricos de predicción meteorológica \href{https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs}{GFS},
  \href{https://www.meteogalicia.gal/web/modelos/threddsIndex.action}{MeteoGalicia}, \href{https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/north-american-mesoscale-forecast-system-nam}{NAM} y \href{https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/rapid-refresh-rap}{RAP}.
\item
  \href{https://github.com/skgrange/saqgetr}{\texttt{saqgetr}}: permite importar datos de calidad del aire de Europa.
\item
  \href{https://github.com/spatialstatisticsupna/RGISTools}{\texttt{RGISTools}}: permite importar datos de imágenes de satélite de Landsat, MODIS y Sentinel.
\item
  \href{https://CRAN.R-project.org/package=maptools}{\texttt{maptools}},\href{https://CRAN.R-project.org/package=spData}{\texttt{spData}},\href{https://CRAN.R-project.org/package=spDataLarge}{\texttt{spDataLarge}},\href{https://CRAN.R-project.org/package=getlandsat}{\texttt{getlandsat}}\ldots{}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(osmdata) }
\CommentTok{\# Cuidado: descarga mucha información}
\CommentTok{\# https://nominatim.openstreetmap.org/ui/search.html}
\CommentTok{\# https://wiki.openstreetmap.org/wiki/Map\_features}
\NormalTok{osm\_coru }\OtherTok{\textless{}{-}} \FunctionTok{opq}\NormalTok{(}\StringTok{\textquotesingle{}A Coruña\textquotesingle{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{add\_osm\_feature}\NormalTok{(}\AttributeTok{key =} \StringTok{\textquotesingle{}highway\textquotesingle{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{osmdata\_sf}\NormalTok{() }
\FunctionTok{plot}\NormalTok{(}\FunctionTok{st\_geometry}\NormalTok{(osm\_coru}\SpecialCharTok{$}\NormalTok{osm\_lines), }\AttributeTok{main =} \StringTok{""}\NormalTok{, }
     \AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{8.45}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{8.38}\NormalTok{), }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\FloatTok{43.32}\NormalTok{, }\FloatTok{43.39}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

{[}Figura \ref{fig:osm-coru-plot}{]}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{images/osmdata-1} 

}

\caption{Representación de las carreteras, calles y caminos en A Coruña (generado con el paquete `osmdata`).}\label{fig:osm-coru-plot}
\end{figure}

También están disponibles una gran cantidad de páginas web y geoportales desde donde es posible descargar datos espaciales (algo que se puede hacer directamente desde R).
Algunas de ellas son:

\begin{itemize}
\item
  \href{https://www.gadm.org}{CGADM database of Global Administrative Areas}: permite descargar límites administrativos a distintos niveles (e.g.~0 = pais, 1 = CCAA, 2 = provincias, 3 = comarcas, 4 = ayuntamientos).
\item
  \href{https://earthdata.nasa.gov}{NASA Earth Science Data}.
\item
  \href{https://inspire-geoportal.ec.europa.eu}{INSPIRE Geoportal}: \emph{Enhancing access to European spatial data}.
\item
  \href{https://scihub.copernicus.eu}{Copernicus Open Access Hub}: \emph{Europe's eyes on Earth}.
\item
  \href{http://www.soest.hawaii.edu/pwessel/gshhg/index.html}{GSHHG} \emph{A Global Self-consistent, Hierarchical, High-resolution Geography Database}.
\end{itemize}

Muchos de los archivos de datos están en formato \href{https://www.unidata.ucar.edu/software/netcdf}{NetCDF} (\emph{Network Common Data Form}) y se pueden importar a R con el paquete \href{http://cirrus.ucsd.edu/~pierce/ncdf}{\texttt{ncdf4}}.

\hypertarget{operaciones-geometrias}{%
\subsection{Operaciones con geometrías}\label{operaciones-geometrias}}

Operaciones \href{https://r-spatial.github.io/sf/reference/geos_unary.html}{unarias} (operan sobre un único conjunto de geometrías simples, el primer argumento) con resultado geométrico:

\begin{itemize}
\tightlist
\item
  \texttt{st\_geometry()}: devuelve (o establece) la columna \texttt{sfc} de un objeto \texttt{sf}.
\item
  \texttt{st\_transform(x,\ crs,\ ...)}: transforma o convierte las coordenadas de \texttt{x} a un nuevo sistema de referencia.
\item
  \texttt{st\_cast(x,\ to,\ ...)}: cambia la geometría \texttt{x} a otro tipo de geometría.
\item
  \texttt{st\_centroid()}: devuelve los centroides de las geometrías.
\item
  \texttt{st\_buffer()}: crea un buffer en torno a la geometría o a cada geometría.
\item
  \texttt{st\_boundary()}: devuelve la frontera de la geometría.
\item
  \texttt{st\_convex\_hull()}: crea el envoltorio convexo de un conjunto de puntos.
\item
  \texttt{st\_voronoi()}: crea una \href{https://en.wikipedia.org/wiki/Voronoi_diagram}{teselación de Voronoi}.
\item
  \texttt{st\_make\_grid(x,\ cellsize,\ offset,\ n,\ what\ =\ c("polygons",\ "corners",\ "centers"))}: genera una rejilla rectangular (o exagonal) de geometrías (\texttt{what}) que cubre los límites de \texttt{x}.
\end{itemize}

Como ya se comentó en la Sección \ref{crs}, nos puede interesar transformar las coordenadas a un nuevo sistema de referencia (algo necesario para poder combinar conjuntos de datos espaciales con distintos CRS).
Por ejemplo podemos utilizar la \href{https://en.wikipedia.org/wiki/Mollweide_projection}{proyección de Mollweide} para representar datos globales (en este caso estimaciones de la población de países; Figura \ref{fig:transform} derecha).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rnaturalearth) }
\NormalTok{par\_old }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\AttributeTok{bottom =} \DecValTok{0}\NormalTok{, }\AttributeTok{left =} \DecValTok{0}\NormalTok{, }\AttributeTok{top =} \DecValTok{0}\NormalTok{, }\AttributeTok{right =} \DecValTok{0}\NormalTok{))}
\CommentTok{\# NOTA: plot.sf() con escala no es compatible con mfrow }
\NormalTok{world\_pop }\OtherTok{\textless{}{-}} \FunctionTok{ne\_countries}\NormalTok{(}\AttributeTok{returnclass =} \StringTok{"sf"}\NormalTok{)[}\StringTok{"pop\_est"}\NormalTok{]}
\FunctionTok{plot}\NormalTok{(world\_pop, }\AttributeTok{logz =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{main =} \StringTok{""}\NormalTok{, }\AttributeTok{key.pos =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{reset =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{grat }\OtherTok{\textless{}{-}} \FunctionTok{st\_graticule}\NormalTok{(}\AttributeTok{crs=}\FunctionTok{st\_crs}\NormalTok{(}\StringTok{"WGS84"}\NormalTok{), }\AttributeTok{lon =} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{180}\NormalTok{, }\DecValTok{180}\NormalTok{, }\AttributeTok{by =} \DecValTok{20}\NormalTok{), }\AttributeTok{lat =} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{90}\NormalTok{, }\DecValTok{90}\NormalTok{, }\AttributeTok{by =} \DecValTok{10}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(grat[}\DecValTok{1}\NormalTok{], }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\# https://spatialreference.org/ref/esri/54009/}
\NormalTok{world\_pop2 }\OtherTok{\textless{}{-}} \FunctionTok{st\_transform}\NormalTok{(world\_pop, }\StringTok{"ESRI:54009"}\NormalTok{) }
\FunctionTok{plot}\NormalTok{(world\_pop2, }\AttributeTok{logz =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{main =} \StringTok{""}\NormalTok{, }\AttributeTok{key.pos =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{reset =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{grat }\OtherTok{\textless{}{-}} \FunctionTok{st\_graticule}\NormalTok{(world\_pop2, }\AttributeTok{lon =} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{180}\NormalTok{, }\DecValTok{180}\NormalTok{, }\AttributeTok{by =} \DecValTok{20}\NormalTok{), }\AttributeTok{lat =} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{90}\NormalTok{, }\DecValTok{90}\NormalTok{, }\AttributeTok{by =} \DecValTok{10}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(grat[}\DecValTok{1}\NormalTok{], }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=1\linewidth]{02-datos_files/figure-latex/transform-1} 

}

\caption{Mapa de la población estimada por paises (en escala logarítmica), datos sin proyectar (izquierda) y con proyección de Mollweide (derecha).}\label{fig:transform}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(par\_old)}
\end{Highlighting}
\end{Shaded}

Operaciones \href{https://r-spatial.github.io/sf/reference/geos_binary_ops.html}{binarias} (operan sobre dos conjuntos de geometrías simples) con resultado geométrico:

\begin{itemize}
\tightlist
\item
  \texttt{st\_union(x,\ y,\ ...,\ by\_feature)}: une varias geometrías.
\item
  \texttt{st\_intersection(x,\ y,\ ...)}: intersección de pares de geometrías.
\item
  \texttt{st\_crop(x,\ y,\ ...,\ xmin,\ ymin,\ xmax,\ ymax)}: intersección con rectángulo delimitador o especificado.
\item
  \texttt{st\_difference(x,\ y,\ ...)}: diferencia de pares de geometrías.
\item
  \texttt{st\_sym\_difference(x,\ y,\ ...)}: diferencia simétrica (xor) de pares de geometrías.
\item
  \texttt{st\_nearest\_points(x,\ y,\ ...)}: obtiene los puntos más cercanos entre pares de geometrías.
\end{itemize}

Operaciones unarias con resultado numérico o lógico:

\begin{itemize}
\tightlist
\item
  \texttt{st\_coordinates(x)}: devuelve una matriz con las coordenadas.
\item
  \texttt{st\_bbox(obj,\ ...)}: devuelve los límites del conjunto de geometrías.
\item
  \texttt{st\_area(x,\ ...)}: devuelve el área de polígonos.
\item
  \texttt{st\_length(x,\ ...)}: devuelve la longitud de líneas.
\item
  \texttt{st\_is(x,\ type)}: verifica si la geometría es de un determinado tipo o conjunto de clases.
\end{itemize}

Operaciones binarias con resultado numérico o \href{https://r-spatial.github.io/sf/reference/geos_binary_pred.html}{lógico}:

\begin{itemize}
\tightlist
\item
  \texttt{st\_distance(x,\ y,\ ...,\ by\_element,\ which)}: devuelve la matriz de distancias mínimas entre geometrías.
\item
  \texttt{st\_nearest\_feature(x,\ y)}: devuelve el índice de la geometría de \texttt{y} más cercana a cada geometría de \texttt{x}.
\item
  \texttt{st\_intersects(x,\ y,\ ...)}: determina si las geometrías se solapan o tocan.
\item
  \texttt{st\_disjoint(x,\ y,\ ...)}: determina si las geometrías no se solapan o tocan.
\item
  \texttt{st\_touches(x,\ y,\ ...)}: determina si las geometrías se tocan.
\item
  \texttt{st\_overlaps(x,\ y,\ ...)}: determina si las geometrías se solapan, pero no están completamente contenidas la una en la otra.
\item
  \texttt{st\_crosses(x,\ y,\ ...)}: determina si las geometrías se cruzan, pero no se tocan.
\item
  \texttt{st\_within(x,\ y,\ ...)}: determina si \texttt{x} está en \texttt{y}.
\item
  \texttt{st\_contains(x,\ y,\ ...)}: determina si \texttt{y} está en \texttt{x}.
\item
  \texttt{st\_covers(x,\ y,\ ...)}: determina si todos los puntos de \texttt{y} están dentro de \texttt{x}.
\item
  \texttt{st\_covered\_by(x,\ y,\ ...)}: determina si todos los puntos de \texttt{x} están dentro de \texttt{y}.
\item
  \texttt{st\_equals(x,\ y,\ ...)}: determina si \texttt{x} es geométricamente igual a \texttt{y}.
\item
  \texttt{st\_equals\_exact(x,\ y,\ par,\ ...)}: determina si \texttt{x} es igual a \texttt{y} con cierta tolerancia.
\end{itemize}

El resultado de las operaciones lógicas es una matriz dispersa (de clase \texttt{sgbp}, \emph{sparse geometry binary predicate}), que se puede convertir a una matriz densa con \texttt{as.matrix()}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{example}[Creación de una rejilla de predicción]
\protect\hypertarget{exm:aquifer2}{}{\label{exm:aquifer2} \iffalse (Creación de una rejilla de predicción) \fi{} }
Continuando con los datos del Ejercicio \ref{exr:aquifer1}, para crear un objeto con las posiciones de predicción, podríamos generar un buffer (\texttt{st\_buffer()}) de radio 40 en torno a las posiciones de observación y a partir de él crear una rejilla vectorial (\texttt{st\_make\_grid(...,\ what\ =\ "centers")}) de dimensiones 50 por 50 e intersecarla con el buffer.
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"datos/aquifer.RData"}\NormalTok{)}
\NormalTok{aquifer}\SpecialCharTok{$}\NormalTok{head }\OtherTok{\textless{}{-}}\NormalTok{ aquifer}\SpecialCharTok{$}\NormalTok{head}\SpecialCharTok{/}\DecValTok{100} \CommentTok{\# en cientos de pies}
\NormalTok{aquifer\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_as\_sf}\NormalTok{(aquifer, }\AttributeTok{coords =} \FunctionTok{c}\NormalTok{(}\StringTok{"lon"}\NormalTok{, }\StringTok{"lat"}\NormalTok{), }\AttributeTok{agr =} \StringTok{"constant"}\NormalTok{)}
\NormalTok{buffer }\OtherTok{\textless{}{-}}\NormalTok{ aquifer\_sf }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{st\_geometry}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}  \FunctionTok{st\_buffer}\NormalTok{(}\DecValTok{40}\NormalTok{)}
\NormalTok{grid }\OtherTok{\textless{}{-}}\NormalTok{ buffer }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{st\_make\_grid}\NormalTok{(}\AttributeTok{n =} \FunctionTok{c}\NormalTok{(}\DecValTok{50}\NormalTok{, }\DecValTok{50}\NormalTok{), }\AttributeTok{what =} \StringTok{"centers"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{st\_intersection}\NormalTok{(buffer)}
\FunctionTok{plot}\NormalTok{(buffer)}
\FunctionTok{plot}\NormalTok{(grid, }\AttributeTok{pch =} \DecValTok{3}\NormalTok{, }\AttributeTok{cex =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{02-datos_files/figure-latex/aquifer2-grid-1} 

}

\caption{Rejilla en torno a las posiciones de los datos de `aquifer`.}\label{fig:aquifer2-grid}
\end{figure}

Sin embargo, en lugar de emplear una rejilla \texttt{sf}, puede resultar preferible (por ejemplo para la representación gráfica) emplear una rejilla \texttt{stars}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(stars)}
\NormalTok{grid }\OtherTok{\textless{}{-}}\NormalTok{ buffer }\SpecialCharTok{\%\textgreater{}\%}  \FunctionTok{st\_as\_stars}\NormalTok{(}\AttributeTok{nx =} \DecValTok{50}\NormalTok{, }\AttributeTok{ny =} \DecValTok{50}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{st\_crop}\NormalTok{(buffer)}
\NormalTok{idw }\OtherTok{\textless{}{-}}\NormalTok{ gstat}\SpecialCharTok{::}\FunctionTok{idw}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ head }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{locations =}\NormalTok{ aquifer\_sf, }\AttributeTok{newdata =}\NormalTok{ grid)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [inverse distance weighted interpolation]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(idw[}\StringTok{"var1.pred"}\NormalTok{], }\AttributeTok{col =} \FunctionTok{sf.colors}\NormalTok{(}\DecValTok{64}\NormalTok{), }\AttributeTok{main =} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{02-datos_files/figure-latex/aquifer2-idw-1} 

}

\caption{Interpolación por IDW (Inverse Distance Weighting) de los datos del acuífero Wolfcamp.}\label{fig:aquifer2-idw}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Error gstat::idw, cambia las coordenadas del objeto stars}
\CommentTok{\# summary(st\_coordinates(grid))}
\CommentTok{\# summary(st\_coordinates(idw))}
\CommentTok{\# Posible solución: añadir el resultado a \textasciigrave{}grid\textasciigrave{} y emplearlo en lugar de \textasciigrave{}idw\textasciigrave{}}
\CommentTok{\# grid$var1.pred \textless{}{-} idw$var1.pred}
\CommentTok{\# plot(grid["var1.pred"], col = sf.colors(64), axes = TRUE, main = "")}
\end{Highlighting}
\end{Shaded}

\hypertarget{sp-eda}{%
\section{Análisis exploratorio de datos espaciales}\label{sp-eda}}

Como se comentó en la Sección \ref{objetivos-esquema}, el primer paso para estimar las componentes del modelo, la tendencia \(\mu(\mathbf{s})\) y el semivariograma \(\gamma(\mathbf{h})\), es realizar un análisis exploratorio de los datos.

Normalmente comenzaremos por un análisis descriptivo de la respuesta.
Sería deseable que su distribución fuese aproximadamente simétrica (de forma que los métodos basados en mínimos cuadrados sean adecuados).
Si además la distribución es aproximadamente normal (después de eliminar la tendencia) tendría sentido emplear métodos basados en máxima verosimilitud (Sección \ref{ml-fit}) y los predictores kriging serían los más eficientes (Sección \ref{consideraciones-kriging}).
Si su distribución es muy asimétrica se puede pensar en transformarla como punto de partida (aunque podría cambiarse posteriormente dependiendo del modelo final para la tendencia).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"datos/aquifer.RData"}\NormalTok{)}
\FunctionTok{str}\NormalTok{(aquifer)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    85 obs. of  3 variables:
##  $ lon : num  42.78 -27.4 -1.16 -18.62 96.47 ...
##  $ lat : num  127.6 90.8 84.9 76.5 64.6 ...
##  $ head: num  1464 2553 2158 2455 1756 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sf)}
\NormalTok{aquifer\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_as\_sf}\NormalTok{(aquifer, }\AttributeTok{coords =} \FunctionTok{c}\NormalTok{(}\StringTok{"lon"}\NormalTok{, }\StringTok{"lat"}\NormalTok{), }\AttributeTok{agr =} \StringTok{"constant"}\NormalTok{)}
\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ aquifer\_sf}\SpecialCharTok{$}\NormalTok{head}\SpecialCharTok{/}\DecValTok{100}
\FunctionTok{summary}\NormalTok{(z)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   10.24   15.48   17.97   20.02   25.40   35.71
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(z, }\AttributeTok{xlab =} \StringTok{"piezometric{-}head"}\NormalTok{, }\AttributeTok{main =} \StringTok{""}\NormalTok{, }\AttributeTok{freq =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{density}\NormalTok{(z), }\AttributeTok{col =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{02-datos_files/figure-latex/hist-aquifer-1} 

}

\caption{Distribución del nivel del agua subterránea en el acuífero Wolfcamp.}\label{fig:hist-aquifer}
\end{figure}

En un segundo paso se podría tener en cuenta las coordenadas espaciales.
Por ejemplo, podríamos generar un gráfico de dispersión para ver si se observa algún patrón claro (lo que nos haría sospechar que la tendencia no es constante).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(aquifer\_sf, }\AttributeTok{pch =} \DecValTok{20}\NormalTok{, }\AttributeTok{cex =} \DecValTok{3}\NormalTok{, }\AttributeTok{breaks =} \StringTok{"quantile"}\NormalTok{, }\AttributeTok{nbreaks =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{02-datos_files/figure-latex/plot-aquifer-1} 

}

\caption{Distribución espacial de las observaciones del nivel del agua subterránea en el acuífero Wolfcamp.}\label{fig:plot-aquifer}
\end{figure}

Gráficos de dispersión de la respuesta frente a las coordenadas nos pueden ayudar a determinar si hay una tendencia (al estilo de las funciones \texttt{geoR::plot.geodata()} o \texttt{npsp::scattersplot()}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coord }\OtherTok{\textless{}{-}} \FunctionTok{st\_coordinates}\NormalTok{(aquifer\_sf)}
\NormalTok{old.par }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{omd =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.05}\NormalTok{, }\FloatTok{0.95}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.95}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(coord[, }\DecValTok{1}\NormalTok{], z, }\AttributeTok{xlab =} \StringTok{"x"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"z"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{lowess}\NormalTok{(coord[, }\DecValTok{1}\NormalTok{], z), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{col =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(coord[, }\DecValTok{2}\NormalTok{], z, }\AttributeTok{xlab =} \StringTok{"y"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"z"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{lowess}\NormalTok{(coord[, }\DecValTok{2}\NormalTok{], z), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{col =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.9\linewidth]{02-datos_files/figure-latex/scattersplot-1} 

}

\caption{Gráficos de dispersión del nivel del agua subterránea frente a coordenadas (acuífero Wolfcamp).}\label{fig:scattersplot}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(old.par)}
\end{Highlighting}
\end{Shaded}

En este caso concreto parece que una tendencia lineal es adecuada.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{exercise}[Análisis exploratorio de la tendencia]
\protect\hypertarget{exr:descriptiva}{}{\label{exr:descriptiva} \iffalse (Análisis exploratorio de la tendencia) \fi{} }
Realizar un análisis exploratorio del conjunto de datos \texttt{s100} del paquete \texttt{geoR}
(que contiene una simulación de un proceso espacial estacionario, sin tendencia;
ver Sección \ref{vario-muestrales}).
\end{exercise}

\begin{exercise}[Análisis exploratorio con variables explicativas]
\protect\hypertarget{exr:descriptiva2}{}{\label{exr:descriptiva2} \iffalse (Análisis exploratorio con variables explicativas) \fi{} }
Realizar un análisis exploratorio del conjunto de datos \texttt{meuse\_sf} (almacenado en
el archivo \emph{st\_meuse.RData}; ver Figura \ref{fig:meuse-sf}) considerando como
respuesta la concentración de zinc y como variables explicativas, además de las
coordenadas espaciales, las variables que comparte con la rejilla \texttt{meuse\_grid}
(y que se podrían emplear en la predicción kriging; Capítulo \ref{kriging}).

Realizar también un análisis exploratorio multivariante, considerando la respuesta
y el resto de variables explicativas (que podrían considerarse realizaciones de
otros procesos espaciales y emplearlas para predicción multivariante, cokriging;
Capítulo \ref{multivar}).
\end{exercise}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Para el análisis exploratorio de la dependencia se suelen emplear las semivarianzas muestrales o los estimadores experimentales del variograma, como se describe en la Sección \ref{vario-muestrales}.

\hypertarget{modelado}{%
\chapter{Modelado de procesos geoestadísticos}\label{modelado}}

Como se comentó en la Sección \ref{objetivos-esquema} la aproximación tradicional (paramétrica) para el modelado de un proceso geoestadístico, es decir, estimar la tendencia \(\mu(\mathbf{s})\) y el semivariograma \(\gamma(\mathbf{h})\), consiste en los siguientes pasos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Análisis exploratorio y formulación de un modelo paramétrico (inicial).
\item
  Estimación de los parámetros del modelo:

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Estimar y eliminar la tendencia (suponiendo que no es constante).
  \item
    Modelar la dependencia (ajustar un modelo de variograma) a partir de los residuos
    (o directamente de las observaciones si la tendencia se supone constante).
  \end{enumerate}
\item
  Validación del modelo o reformulación del mismo.
\item
  Empleo del modelo aceptado.
\end{enumerate}

El procedimiento habitual para el modelado de la dependencia en el paso 2 (también denominado \emph{análisis estructural}) consiste en obtener una estimación inicial del semivariograma utilizando algún tipo de estimador experimental (Sección \ref{vario-muestrales}) y posteriormente ajustar un modelo paramétrico válido de semivariograma a las estimaciones ``piloto'' obtenidas en el primer paso (secciones \ref{modelos-variog} y \ref{ajuste-variog}).

El principal problema con esta aproximación aparece cuando no se puede asumir que la tendencia es constante, ya que los estimadores muestrales descritos en la siguiente sección solo son adecuados para procesos estacionarios.
En este caso, como la media es constante, entonces:
\begin{equation} 
  E(Z(\mathbf{s}_1) - Z(\mathbf{s}_{2}))^2 = 2\gamma(\mathbf{s}_1 -\mathbf{s}_{2}),
  \ \forall \mathbf{s}_1 ,\mathbf{s}_{2} \in D.
\label{eq:vario-est}
\end{equation}
Sin embargo, cuando la tendencia no es constante:
\begin{equation} 
  E(Z(\mathbf{s}_1) - Z(\mathbf{s}_{2}))^2 = 2\gamma(\mathbf{s}_1 - \mathbf{s}_{2}) 
  + \left( \mu(\mathbf{s}_1)-\mu(\mathbf{s}_{2})\right)^2,
\label{eq:vario-nest}
\end{equation}
y no es necesariamente función de \(\mathbf{s}_1 -\mathbf{s}_{2}\), ni tiene por qué verificar las propiedades de un variograma.
Por este motivo, estos estimadores no deben ser utilizados mientras que no se elimine la tendencia de los datos.

Si no se puede asumir que la tendencia es constante, para poder estimarla de forma eficiente sería necesario conocer la dependencia (i.e.~conocer \(\gamma(\cdot)\)).
Este problema circular se suele resolver en la práctica realizando el paso 2 de forma iterativa, como se describe en la Sección \ref{trend-fit}.
Otra alternativa sería asumir normalidad y estimar ambos componentes de forma conjunta empleando alguno de los métodos basados en máxima verosimilitud descritos en la Sección \ref{ml-fit}.

Finalmente, en el paso 3, para verificar si el modelo (de tendencia y variograma) describe adecuadamente la variabilidad espacial de los datos (y para comparar modelos), se emplea normalmente la técnica de validación cruzada, descrita en la Sección \ref{validacion-cruzada} del siguiente capítulo (en el que también se describe los principales métodos empleados en el paso 4).

\hypertarget{vario-muestrales}{%
\section{Estimadores muestrales del semivariograma}\label{vario-muestrales}}

Suponiendo que el proceso es intrísecamente estacionario, a partir de \eqref{eq:vario-est}, empleando el método de los momentos, se obtiene el denominado \emph{estimador empírico} (o clásico) del semivariograma (Matheron, 1962):
\[\hat{\gamma}(\mathbf{h}) = \dfrac{1}{2\left| N(\mathbf{h})\right| }
\sum\limits_{N(\mathbf{h})}\left( Z(\mathbf{s}_{i})-Z(\mathbf{s}_{j} )\right) ^2 ,\ \mathbf{h}\in \mathbb{R}^{d},\]
donde:
\[N(\mathbf{h}) = \left\{ (i,j):\mathbf{s}_{i} -\mathbf{s}_{j} \in Tol(\mathbf{h});i,j=1,\ldots,n\right\},\]
\(Tol(\mathbf{h})\subset \mathbb{R}^{d}\) es una región de tolerancia en torno a \(\mathbf{h}\) y \(\left| N(\mathbf{h})\right|\) es el número de pares distintos en \(N(\mathbf{h})\).
La región de tolerancia debería ser lo suficientemente grande como para que no aparezcan inestabilidades, por lo que se recomienda (Journel y Huijbregts 1978, p.194) que el numero de aportaciones a la estimación en un salto \(\mathbf{h}\) sea por lo menos de treinta (i.e.~\(\left| N(\mathbf{h})\right| \geq 30\)).

De forma análoga, suponiendo estacionariedad de segundo orden, se obtiene el estimador clásico del covariograma:
\[\hat{C} (\mathbf{h}) = \dfrac{1}{\left| N(\mathbf{h})\right| }
\sum\limits_{N(\mathbf{h})}\left( Z(\mathbf{s}_{i})-\bar{Z} \right)
\left( Z(\mathbf{s}_{j})-\bar{Z} \right),\ \mathbf{h}\in \mathbb{R}^{d},\]
siendo \(\bar{Z} =\frac{1}{n} \sum_{i=1}^{n}Z(\mathbf{s}_{i})\) la media muestral.
El principal problema con este estimador es la necesidad de estimar la media \(\mu\) del proceso, lo que produce que sea sesgado.
Por otra parte, además de que la suposición de estacionariedad de segundo orden es menos general (Sección \ref{procesos-estacionarios}, si el proceso es intrínsecamente estacionario el estimador del variograma es insesgado y también tiene mejores propiedades cuando la estimación se basa en residuos (aunque en este caso ambos estimadores son sesgados).
Más información sobre la distribución y propiedades de estos estimadores se tienen por ejemplo en Cressie (1993, pp.~71-74).
Estos resultados justifican que el modelado de la dependencia espacial se realice a través del semivariograma.

Uno de los problemas con el estimador empírico del semivariograma es su falta de robustez frente a observaciones atípicas.
Por este motivo se han propuesto numerosas alternativas robustas.
Hawkins y Cressie (1984) sugirieron promediar la raíz cuadrada de las diferencias en valor absoluto\footnote{Si el proceso \(Z(\cdot)\) es normal entonces \((Z(\mathbf{s})-Z(\mathbf{s}+\mathbf{h}))^2\) sigue una distribución \(2\gamma(\mathbf{h})\chi_1^2\), sin embargo esta distribución es muy asimétrica y la transformación de potencia que hace que se aproxime más a la simetría (normalidad) es la raíz cuarta. Otra ventaja de utilizar la raíz cuadrada de las diferencias es que, en general, están menos correladas que las diferencias al cuadrado (ver e.g.~Cressie, 1993, p.~76).} y posteriormente transformar el resultado a la escala original tratando de obtener un estimador aproximadamente insesgado (utilizando del método delta), obteniéndose el estimador:

\[2\tilde{\gamma}(\mathbf{h}) = \left( \dfrac{1}{\left| N(\mathbf{h})\right| }
\sum\limits_{N(\mathbf{h})}\left| Z(\mathbf{s}_{i})-Z(\mathbf{s}_{j}
)\right|^{\frac{1}{2} } \right)^{4} /\left( \text{0.457+}
\dfrac{\text{0.494} }{\left| N(\mathbf{h})\right| } +\dfrac{\text{0.045}
}{\left| N(\mathbf{h})\right|^2 } \right).\]

Los estimadores locales tipo núcleo son herramientas frecuentemente utilizadas en la estimación de curvas y superficies.
Entre los más conocidos podemos señalar los estimadores tipo Nadaraya-Watson y los polinómicos locales (e.g.~Fan y Gijbels,1996).
Recientemente se han considerado también estas ideas para la estimación del covariograma (e.g.~Hall et al., 1994) y del semivariograma.
La expresión general de un estimador no paramétrico de un semivariograma isotrópico es de la forma:
\[\hat{\gamma}(r) = \dfrac{\sum\limits_{i=1}^{n-1}\sum\limits_{j=i+1}^{n}\omega_{ij}
(r)\left( Z(\mathbf{s}_{i})-Z(\mathbf{s}_{j})\right)^2  
}{2\sum\limits_{i=1}^{n-1}\sum\limits_{j=i+1}^{n}\omega_{ij}(r)},\]
donde \(\omega_{ij}(r) \geq 0\), \(\forall i,j\) y \(\sum_{i,j}\omega_{ij}(r) > 0\).
Dependiendo de la elección de estos pesos obtenemos distintos estimadores:

\begin{itemize}
\tightlist
\item
  \(\omega_{ij}(r) = \mathcal{I}_{Tol(r)} \left( \left\| \mathbf{s}_{i} - \mathbf{s}_{j} \right\| \right)\), siendo \(Tol(r)\subset \mathbb{R}\) una región de tolerancia en torno a \(r\) (y denotando por \(\mathcal{I}_{A}(\cdot)\) función indicadora del conjunto \(A\)), obtenemos el estimador clásico del semivariograma.
\item
  \(\omega_{ij}(r)=K\left( \frac{\left\| \mathbf{s}_{i} -\mathbf{s}_{j} \right\| -r}{h} \right)\), es el estimador Nadaraya-Watson (Hall et al., 1994).
\item
  \(\omega_{ij}(r)=K\left( \frac{\left\| \mathbf{s}_{i} -\mathbf{s}_{j} \right\| -r}{h} \right) \times\) \(\sum\limits_{k}\sum\limits_{l}K\left( \frac{\left\| \mathbf{s}_{k} -\mathbf{s}_{l} \right\| -r}{h} \right) \left( \left\| \mathbf{s}_{k} -\mathbf{s}_{l} \right\| -r\right) \left( \left\| \mathbf{s}_{k} -\mathbf{s}_{l} \right\| -\left\| \mathbf{s}_{i} -\mathbf{s}_{j} \right\| \right)\) se obtiene el estimador lineal local del semivariograma (García-Soidán et al., 2003).
\end{itemize}

La función \href{https://r-spatial.github.io/gstat/reference/variogram.html}{\texttt{variogram()}} del paquete \texttt{gstat}:

\begin{verbatim}
variogram(formula, locations = coordinates(data), data, cutoff, width = cutoff/15,
          cressie = FALSE, cloud = FALSE, covariogram = FALSE, ...)
\end{verbatim}

permite obtener la nube de semivarianzas (\texttt{cloud\ =\ TRUE}) y las estimaciones
empíricas o robustas (\texttt{cressie\ =\ TRUE}), además de otras posibilidades.

En primer lugar emplearemos el conjunto de datos \texttt{s100} del paquete \texttt{geoR}, que contiene una simulación de un proceso espacial estacionario (sin tendencia).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Cargamos los datos y los transformamos a un objeto \textasciigrave{}sf\textasciigrave{}}
\FunctionTok{library}\NormalTok{(sf)}
\FunctionTok{data}\NormalTok{(s100, }\AttributeTok{package =} \StringTok{"geoR"}\NormalTok{)}
\NormalTok{datos }\OtherTok{\textless{}{-}} \FunctionTok{st\_as\_sf}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(s100}\SpecialCharTok{$}\NormalTok{coords, }\AttributeTok{z =}\NormalTok{ s100}\SpecialCharTok{$}\NormalTok{data), }
                  \AttributeTok{coords =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{agr =} \StringTok{"constant"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gstat)}
\NormalTok{vario.cloud }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, datos, }\AttributeTok{cloud =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{cutoff =} \FloatTok{0.6}\NormalTok{)}
\NormalTok{vario }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, datos, }\AttributeTok{cloud =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{cutoff =} \FloatTok{0.6}\NormalTok{)}
\CommentTok{\# Si se quiere tomar el 50\% del máximo salto (posible) cutoff = maxlag}
\CommentTok{\# maxlag \textless{}{-} 0.5*sqrt(sum(diff(apply(s100$coord, 2, range))\^{}2)) }
\CommentTok{\# maxlag \textless{}{-} 0.5*sqrt(sum(diff(matrix(st\_bbox(datos), nrow = 2, byrow = TRUE))\^{}2))}
\FunctionTok{names}\NormalTok{(vario)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "np"      "dist"    "gamma"   "dir.hor" "dir.ver" "id"
\end{verbatim}

En el resultado, la componente \texttt{dist} contiene los saltos, \texttt{gamma} las estimaciones del semivariograma (o las semivarianzas) y \texttt{np} el número de aportaciones.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rvario.cloud }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, datos, }\AttributeTok{cloud =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{cressie =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{cutoff =} \FloatTok{0.6}\NormalTok{)}
\NormalTok{rvario }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, datos, }\AttributeTok{cloud =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{cressie =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{cutoff =} \FloatTok{0.6}\NormalTok{)}
\CommentTok{\# Representar}
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\CommentTok{\# Nube de semivarianzas clásicas}
\FunctionTok{with}\NormalTok{(vario.cloud,  }\FunctionTok{plot}\NormalTok{(dist, gamma, }\AttributeTok{xlab =} \StringTok{"distance"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"semivariances"}\NormalTok{))}
\CommentTok{\# Nube de semivarianzas robustas}
\FunctionTok{with}\NormalTok{(rvario.cloud,  }\FunctionTok{plot}\NormalTok{(dist, gamma, }\AttributeTok{xlab =} \StringTok{"distance"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"semivariances"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.9\linewidth]{03-modelado_files/figure-latex/vario-rvario-cloud-1} 

}

\caption{Nubes de semivarianzas clásicas (izquierda) y robustas (derecha) del conjunto de datos simulado.}\label{fig:vario-rvario-cloud}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(vario, }\FunctionTok{plot}\NormalTok{(dist, gamma, }\AttributeTok{pch =} \DecValTok{19}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{),}
                        \AttributeTok{xlab =} \StringTok{"distance"}\NormalTok{, }\AttributeTok{ylab =}  \StringTok{"semivariance"}\NormalTok{))}
\FunctionTok{with}\NormalTok{(rvario, }\FunctionTok{points}\NormalTok{(dist, gamma))}
\FunctionTok{legend}\NormalTok{(}\StringTok{"bottomright"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"clásico"}\NormalTok{, }\StringTok{"robusto"}\NormalTok{), }\AttributeTok{pch =} \FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/vario-rvario-1} 

}

\caption{Estimaciones clásicas y robustas del semivariograma (datos simulados).}\label{fig:vario-rvario}
\end{figure}

Para detectar observaciones atípicas podríamos emplear la nube de semivarianzas (preferiblemente las robustas, ya que tienen una distribución más próxima a la normalidad)\footnote{Estableciendo \texttt{identify\ =\ TRUE} (o \texttt{digitize\ =\ TRUE}) en \texttt{plot.variogramCloud()} podríamos identificar semivarianzas atípicas (o pares de datos atípicos) de forma interactiva.}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(rvario.cloud)}
\NormalTok{boundaries }\OtherTok{\textless{}{-}} \FunctionTok{attr}\NormalTok{(rvario, }\StringTok{"boundaries"}\NormalTok{)}
\NormalTok{res}\SpecialCharTok{$}\NormalTok{lag }\OtherTok{\textless{}{-}} \FunctionTok{cut}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{dist, }\AttributeTok{breaks =}\NormalTok{ boundaries, }\AttributeTok{labels =} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(boundaries)}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{))}
\NormalTok{res}\SpecialCharTok{$}\NormalTok{labels }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(res, }\FunctionTok{paste}\NormalTok{(left, right, }\AttributeTok{sep=}\StringTok{"{-}"}\NormalTok{))}
\FunctionTok{with}\NormalTok{(res, car}\SpecialCharTok{::}\FunctionTok{Boxplot}\NormalTok{(gamma }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lag, }\AttributeTok{id =} \FunctionTok{list}\NormalTok{(}\AttributeTok{labels =}\NormalTok{ labels)))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/unnamed-chunk-4-1} \end{center}

\begin{verbatim}
## [1] "87-52" "87-39" "57-52" "57-39"
\end{verbatim}

Nos preocuparía especialmente la presencia de datos atípicos en saltos pequeños (indicaría que observaciones cercanas tienen valores muy distintos).

Para un análisis exploratorio de la anisotropía, podemos obtener variogramas direccionales indicando el ángulo y los grados de tolerancia en cada eje:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{variogram}\NormalTok{(z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, datos, }\AttributeTok{cutoff =} \FloatTok{0.6}\NormalTok{, }\AttributeTok{alpha =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{45}\NormalTok{, }\DecValTok{90}\NormalTok{, }\DecValTok{135}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/unnamed-chunk-5-1} \end{center}

Complementariamente, se puede obtener un mapa de semivarianzas discretizadas en dos dimensiones:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{variogram.map }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, datos, }\AttributeTok{cutoff =} \FloatTok{0.6}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.6} \SpecialCharTok{/} \DecValTok{15}\NormalTok{, }\AttributeTok{map =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(variogram.map)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/unnamed-chunk-6-1} \end{center}

Para estudiar si hay dependencia espacial (estadísticamente significativa) se puede emplear la rutina \texttt{sm.variogram} del paquete \texttt{sm}.
Estableciendo \texttt{model\ =\ "independent"} devuelve un p-valor para contrastar la hipótesis nula de independencia
(i.e.~se acepta que hay una dependencia espacial si \(p \leq \alpha = 0.05\)) y un gráfico en el que se muestra el estimador empírico robusto, un estimador suavizado y una región de confianza para el variograma suponiendo que el proceso es independiente (i.e.~consideraríamos que hay dependencia espacial si el variograma suavizado no está contenido en esa región).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sm)}
\FunctionTok{sm.variogram}\NormalTok{(s100}\SpecialCharTok{$}\NormalTok{coords, s100}\SpecialCharTok{$}\NormalTok{data, }\AttributeTok{model =} \StringTok{"independent"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Test of spatial independence: p =  0.024
\end{verbatim}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/sm-variogram-1} 

}

\caption{Estimaciones robustas y suavizadas del semivariograma, junto con una región de confianza para el semivariograma suponiendo que el proceso es independiente.}\label{fig:sm-variogram}
\end{figure}

También se puede realizar contrastes adicionales estableciendo el parámetro \texttt{model} a \texttt{"isotropic"} o \texttt{"stationary"}.

\hypertarget{modelos-variog}{%
\section{Modelos de semivariogramas}\label{modelos-variog}}

Los variogramas deben ser condicionalmente semidefinidos negativos, una propiedad que los estimadores tradicionales normalmente no poseen.
Tradicionalmente esto se remedia ajustando un modelo paramétrico válido al estimador muestral (Sección \ref{ajuste-variog}).
En la Sección \ref{modelos-parametricos} se presentan algunos de los modelos isotrópicos tradicionalmente utilizados en geoestadística.
Estos modelos son empleados también en ciertos casos como estructuras básicas a partir de las cuales se construyen modelos más complejos, como modelos anisotrópicos (Sección \ref{anisotropia}) o los denominados modelos lineales de regionalización (Sección \ref{vario-lin-reg}).

\hypertarget{modelos-parametricos}{%
\subsection{Modelos paramétricos isotrópicos}\label{modelos-parametricos}}

A continuación se presentan algunos de los modelos isotrópicos de semivariograma más utilizados en geoestadística (una revisión más completa se tiene por ejemplo en Chilès y Delfiner, 1999, Sección 2.5.1).
En la notación utilizada en las parametrizaciones \(c_0 \geq 0\) representa el efecto nugget, \(c_1 \geq 0\) el umbral parcial (en el caso de variogramas acotados, con \(\sigma^2= c_0 + c_1\)) y \(a>0\) el rango (si existe) o el parámetro de escala.
En el caso de semivariogramas acotados que alcanzan el umbral asintóticamente (rango infinito), el parámetro \(a\) representa el rango práctico, definido como la distancia en la que el valor del semivariograma es el 95\% del umbral parcial.
En la Figura \ref{fig:show-vgms} se tienen algunos ejemplos de las formas de algunos de
estos semivariogramas.

\begin{itemize}
\item
  Modelo esférico:
  \[\gamma(\mathbf{h}\left| \boldsymbol{\theta}\right. ) = \left\{ 
  \begin{array}{ll}
  0 & \text{si} \left\| \mathbf{h}\right\| =0 \\
  c_0 +c_1 \left\{ \dfrac{3}{2} \dfrac{\left\| \mathbf{h}\right\| }{a}
  -\dfrac{1}{2} \left( \dfrac{\left\| \mathbf{h}\right\| }{a} \right)
  3\right\}  & \text{si} 0<\left\| \mathbf{h}\right\| \leq a \\
  c_0 +c_1  & \text{si} \left\| \mathbf{h}\right\| >a
  \end{array}
  \right.\]
  válido en \(\mathbb{R}^{d}\), \(d=1,2,3\).
\item
  Modelo exponencial:
  \[\gamma(\mathbf{h}\left| \boldsymbol{\theta}\right. )\ =\ \left\{ 
  \begin{array}{ll}
  0 & \text{si}\  \mathbf{h}=\mathbf{0} \\
  c_0 + c_1 \left( 1-\exp \left( -\dfrac{3\left\|
  \mathbf{h}\right\| }{a} \right) \right)  & \text{si}\  \mathbf{h}\neq
  \mathbf{0}
  \end{array}
  \right.\]
  válido en \(\mathbb{R}^{d}\), \(\forall d \geq 1\).
\item
  Modelo racional cuadrático:
  \[\gamma(\mathbf{h}\left| \boldsymbol{\theta}\right. )\ =\ \left\{ 
  \begin{array}{ll}
  0 & \text{si}\  \mathbf{h}=\mathbf{0} \\
  c_0 + c_1 \dfrac{\left\| \mathbf{h}\right\|^2
  }{\frac{1}{19} a^2 +\left\| \mathbf{h}\right\|^2 }  & \text{si}\ 
  \mathbf{h}\neq \mathbf{0}
  \end{array}
  \right.\]
  válido en \(\mathbb{R}^{d}\), \(\forall d \geq 1\).
\item
  Modelo potencial:
  \[\gamma(\mathbf{h}\left| \boldsymbol{\theta}\right. )\ =\ \left\{ 
  \begin{array}{ll}
  0 & \text{si}\  \mathbf{h}=\mathbf{0} \\
  c_0 + a\left\| \mathbf{h}\right\|^{\lambda }  & \text{si}\ 
  \mathbf{h}\neq \mathbf{0}
  \end{array}
  \right.\]
  con \(0\leq \lambda <2\) y válido en \(\mathbb{R}^{d}\), \(\forall d \geq 1\).
  En el caso de \(\lambda =1\) se obtiene el conocido modelo lineal.
\item
  Modelo exponencial-potencial:
  \[\gamma(\mathbf{h}\left| \boldsymbol{\theta}\right. )\ =\ \left\{ 
  \begin{array}{ll}
  0 & \text{si}\  \mathbf{h}=\mathbf{0} \\
  c_0 + c_1 \left( 1-\exp \left( -3\left( \dfrac{\left\|
  \mathbf{h}\right\| }{a} \right)^{\lambda } \right) \right)  & \text{si}\ 
  \mathbf{h}\neq \mathbf{0}
  \end{array}
  \right.\]
  con \(0\leq \lambda \leq 2\) y válido en \(\mathbb{R}^{d}\), \(\forall d \geq 1\).
  Cuando \(\lambda =2\) es denominado modelo gausiano;
  este modelo sin embargo no debería ser utilizado en la predicción
  espacial debido a las inestabilidades numéricas que produce en los
  algoritmos kriging (especialmente cuando el efecto nugget es grande; ver
  e.g.~Wackernagel, 1998, pp.~120-123).
  El modelo exponencial se obtiene también como caso particular cuando \(\lambda =1\).
\item
  Modelo oscilatorio:
  \[\gamma(\mathbf{h}\left| \boldsymbol{\theta}\right. )\ =\ \left\{ 
  \begin{array}{ll}
  0 & \text{si}\  \mathbf{h}=\mathbf{0} \\
  c_0 + c_1 \left( 1-\dfrac{a}{\left\| \mathbf{h}\right\| }
  \text{sen} \left( \dfrac{\left\| \mathbf{h}\right\| }{a} \right) \right) 
  & \text{si}\  \mathbf{h}\neq \mathbf{0}
  \end{array}
  \right.\]
  válido en \(\mathbb{R}^{d}\), \(d=1,2,3\).
  Este modelo con forma de onda (hay correlaciones negativas) alcanza su valor máximo ( \(c_0 +1.218c_1\)) cuando \(\left\| \mathbf{h}\right\| \simeq 4.5a\), siendo \(a\) el parámetro de escala.
\item
  Modelo de Matérn (o K-Bessel):
  \[\gamma(\mathbf{h}\left| \boldsymbol{\theta}\right. )\ =\ \left\{ 
  \begin{array}{ll}
  0 & \text{si}\  \mathbf{h}=\mathbf{0} \\
  c_0 + c_1 \left( 1-\dfrac{1}{2^{\nu -1} \gamma(\nu )} \left(
  \dfrac{\left\| \mathbf{h}\right\| }{a} \right)^{\nu } K_{\nu } \left(
  \dfrac{\left\| \mathbf{h}\right\| }{a} \right) \right)  & \text{si}\ 
  \mathbf{h}\neq \mathbf{0}
  \end{array}
  \right.\]
  siendo \(\nu \geq 0\) (un parámetro de suavizado) y \(K_{\nu }\) la función de Bessel modificada de tercera clase de orden \(\nu\) (ver e.g.~Abramowitz y Stegun, 1965, pp.~374-379).
  Este modelo es válido en \(\mathbb{R}^{d}\), \(\forall d \geq 1\). El modelo exponencial se obtiene como caso particular cuando \(\nu =\frac{1}{2}\) y en el límite \(\nu \rightarrow \infty\) el modelo gausiano.
\end{itemize}

En \texttt{gstat} se emplea la función \texttt{vgm()} (\emph{Variogram Model}) para definir un modelo de variograma:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vgm}\NormalTok{(}\AttributeTok{psill =} \ConstantTok{NA}\NormalTok{, model, }\AttributeTok{range =} \ConstantTok{NA}\NormalTok{, nugget, add.to, anis, }\AttributeTok{kappa =} \FloatTok{0.5}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \texttt{psill}: umbral parcial (\(c_1\)).
\item
  \texttt{model}: cadena de texto que identifica el modelo (e.g.~\texttt{"Exp"}, \texttt{"Sph"}, \texttt{"Gau"}, \texttt{"Mat"}\ldots).
\item
  \texttt{range}: rango o parámetro de escala (proporcional a \(a\)).
\item
  \texttt{nugget}: efecto nugget (\(c_0\)).
\item
  \texttt{kappa}: parametro de suavizado (\(\nu\) en el modelo de Matérn).
\item
  \texttt{add.to}: permite combinar modelos (Sección \ref{vario-lin-reg}).
\item
  \texttt{anis}: parámetros de anisotropía (Sección \ref{anisotropia}).
\end{itemize}

Lo habitual es definir un modelo para posteriormente estimar sus parámetros utilizando los empleados en la definición como valores iniciales. También se puede llamar a esta función con el modelo como primer y único argumento, indicando que los parámetros son desconocidos (para que tome los valores por defecto en el ajuste). Por defecto considerará que el nugget es nulo (y no se estimará), únicamente se considerará un efecto nugget si se especifica, aunque sea \texttt{nugget\ =\ NA}.
Si se ejecuta sin argumentos devuelve un listado de todos los modelos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vgm}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    short                                      long
## 1    Nug                              Nug (nugget)
## 2    Exp                         Exp (exponential)
## 3    Sph                           Sph (spherical)
## 4    Gau                            Gau (gaussian)
## 5    Exc        Exclass (Exponential class/stable)
## 6    Mat                              Mat (Matern)
## 7    Ste Mat (Matern, M. Stein's parameterization)
## 8    Cir                            Cir (circular)
## 9    Lin                              Lin (linear)
## 10   Bes                              Bes (bessel)
## 11   Pen                      Pen (pentaspherical)
## 12   Per                            Per (periodic)
## 13   Wav                                Wav (wave)
## 14   Hol                                Hol (hole)
## 15   Log                         Log (logarithmic)
## 16   Pow                               Pow (power)
## 17   Spl                              Spl (spline)
## 18   Leg                            Leg (Legendre)
## 19   Err                   Err (Measurement error)
## 20   Int                           Int (Intercept)
\end{verbatim}

La función \texttt{show.vgms()} genera gráficos con los distintos modelos (por defecto los 17 primeros):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{show.vgms}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/show-vgms-1} 

}

\caption{Representaciones de los modelos paramétricos isotrópicos de semivariogramas implementados en el paquete `gstat`.}\label{fig:show-vgms}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{show.vgms}\NormalTok{(}\AttributeTok{kappa.range =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{), }\AttributeTok{max =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/show-matern-1} 

}

\caption{Modelo de Matérn con distintos valores del parámetro de suavizado.}\label{fig:show-matern}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v1 }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{psill =} \DecValTok{1}\NormalTok{, }\AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{range =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{nugget =} \DecValTok{0}\NormalTok{)}
\NormalTok{v1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model psill range
## 1   Nug     0   0.0
## 2   Exp     1   0.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(v1, }\AttributeTok{cutoff =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/vgm-exp-1} 

}

\caption{Ejemplo de modelo exponencial.}\label{fig:vgm-exp}
\end{figure}

\hypertarget{anisotropia}{%
\subsection{Modelado de anisotropía}\label{anisotropia}}

La hipótesis de isotropía simplifica notablemente el modelado de la dependencia espacial por lo que la mayoría de los modelos (básicos) de semivariogramas considerados en geoestadística son isotrópicos (Sección \ref{modelos-parametricos}).
Sin embargo, en muchos casos no se puede asumir que la dependencia es igual en cualquier dirección (uno de los ejemplos más claros es el caso espacio-temporal, donde en principio no es razonable pensar que un salto espacial es equivalente a un salto temporal).
En esos casos se suelen considerar ligeras variaciones de la hipótesis de isotropía para modelar la dependencia espacial.
En esta sección se comentan brevemente las distintas aproximaciones tradicionalmente consideradas en geoestadística (para más detalles ver e.g.~Chilès y Delfiner, 1999, Sección 2.5.2, o Goovaerts, 1997, Sección 4.2.2), otras aproximaciones adicionales se tratarán en el Capítulo 7 (caso espacio-temporal).

Cuando el variograma es función de la dirección además de la magnitud del salto, se dice que el variograma es anisotrópico (no isotrópico).
Los tipos de anisotropía habitualmente considerados son:

\begin{itemize}
\tightlist
\item
  \emph{Anisotropía geométrica}: cuando el umbral permanece constante mientras que el rango varía con la dirección.
\item
  \emph{Anisotropía zonal}: cuando el umbral del semivariograma varía con la dirección (también se denomina anisotropía estratificada).
\item
  \emph{Anisotropía mixta}: combinación de las anteriores.
\end{itemize}

La anisotropía geométrica se puede corregir mediante una transformación lineal del vector de salto \(\mathbf{h}\):
\[\gamma(\mathbf{h})=\gamma^{0} \left( \left\| \mathbf{A}\mathbf{h}\right\| \right) ,\forall \mathbf{h}\in \mathbb{R}^{d},\]
siendo \(\mathbf{A}\) una matriz cuadrada \(d\times d\) y \(\gamma^{0} (\cdot)\) un semivariograma isotrópico\footnote{Esta idea (que el espacio euclídeo no es apropiado para medir distancias entre posiciones espaciales pero una transformación lineal de él sí) ha sido también generalizada para el caso de deformaciones no lineales del espacio. Por ejemplo, Sampson y Guttorp (1992) consideraron transformaciones no lineales obtenidas mediante técnicas de escalamiento óptimo multidimensional.}.
En este caso se dice que el variograma es \emph{geométricamente anisotrópico}.
Por ejemplo, en el caso bidimensional, se suele considerar una matriz de la forma:
\[\mathbf{A}=\left( 
\begin{array}{cc}
1  & 0 \\
0 & a_2/a_1 
\end{array}
\right) \left( 
\begin{array}{cc}
\cos \phi  & \sin\phi  \\
\text{-} \sin\phi  & \cos \phi 
\end{array}
\right),\]
que se corresponde con las direcciones principales de anisotropía \(\phi\) y \(\phi + \frac{\pi }{\text{2}}\) (normalmente se toma \(\phi\) igual a la dirección de máximo rango).
Esto puede extenderse fácilmente para el caso tridimensional (ver e.g.~Chilès y Delfiner, 1999, pp.~94-95).

En \texttt{gstat} se puede definir\footnote{Sin embargo no permite ajustar los parámetros de anisotropía, algo que se puede hacer con las herramientas implementadas en el paquete \texttt{geoR} (ver Sección \ref{geor-ajuste}).} anisotropía mediante el argumento \texttt{anis} de la función \texttt{vgm()}.
En dos dimensiones es un vector con dos componentes \texttt{anis\ =\ c(alpha,\ ratio)}, \texttt{alpha} es el ángulo para la dirección principal de variabilidad (en grados, medido en el sentido del reloj partiendo de la dirección norte, i.e.~\texttt{phi\ =\ (90\ -\ alpha)*pi/180}) y \texttt{ratio} la relación entre el rango mínimo y máximo (\(0 \leq ratio = a_2/a_1 \leq 1\)).

Ejemplo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\StringTok{"Exp"}\NormalTok{, }\DecValTok{5}\NormalTok{, }\AttributeTok{anis =} \FunctionTok{c}\NormalTok{(}\DecValTok{30}\NormalTok{, }\FloatTok{0.1}\NormalTok{))}
\FunctionTok{str}\NormalTok{(v)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Classes 'variogramModel' and 'data.frame':   1 obs. of  9 variables:
##  $ model: Factor w/ 20 levels "Nug","Exp","Sph",..: 2
##  $ psill: num 1
##  $ range: num 5
##  $ kappa: num 0.5
##  $ ang1 : num 30
##  $ ang2 : num 0
##  $ ang3 : num 0
##  $ anis1: num 0.1
##  $ anis2: num 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot\_ellipse\_2d }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(}\AttributeTok{xc =} \DecValTok{0}\NormalTok{, }\AttributeTok{yc =} \DecValTok{0}\NormalTok{, }\AttributeTok{l1 =} \DecValTok{10}\NormalTok{, }\AttributeTok{l2 =} \DecValTok{1}\NormalTok{, }\AttributeTok{phi =}\NormalTok{ pi}\SpecialCharTok{/}\DecValTok{3}\NormalTok{, }
                            \AttributeTok{by =} \FloatTok{0.01}\NormalTok{, }\AttributeTok{asp =} \DecValTok{1}\NormalTok{, ...) \{}
    \CommentTok{\# xc, yc: centro}
    \CommentTok{\# l1, l2: longitud semiejes}
    \CommentTok{\# phi: angulo del eje 1 respecto al eje x}
\NormalTok{    t }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\SpecialCharTok{*}\NormalTok{pi, by)}
\NormalTok{    x }\OtherTok{\textless{}{-}}\NormalTok{ xc }\SpecialCharTok{+}\NormalTok{ l1}\SpecialCharTok{*}\FunctionTok{cos}\NormalTok{(t)}\SpecialCharTok{*}\FunctionTok{cos}\NormalTok{(phi) }\SpecialCharTok{{-}}\NormalTok{ l2}\SpecialCharTok{*}\FunctionTok{sin}\NormalTok{(t)}\SpecialCharTok{*}\FunctionTok{sin}\NormalTok{(phi)}
\NormalTok{    y }\OtherTok{\textless{}{-}}\NormalTok{ yc }\SpecialCharTok{+}\NormalTok{ l1}\SpecialCharTok{*}\FunctionTok{cos}\NormalTok{(t)}\SpecialCharTok{*}\FunctionTok{sin}\NormalTok{(phi) }\SpecialCharTok{+}\NormalTok{ l2}\SpecialCharTok{*}\FunctionTok{sin}\NormalTok{(t)}\SpecialCharTok{*}\FunctionTok{cos}\NormalTok{(phi)}
    \FunctionTok{plot}\NormalTok{(x, y, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{asp =}\NormalTok{ asp, ...)}
\NormalTok{\}}

\FunctionTok{with}\NormalTok{(v, }\FunctionTok{plot\_ellipse\_2d}\NormalTok{(}\AttributeTok{l1 =}\NormalTok{ range, }\AttributeTok{l2 =}\NormalTok{ range}\SpecialCharTok{*}\NormalTok{anis1, }
                        \AttributeTok{phi =}\NormalTok{ (}\DecValTok{90} \SpecialCharTok{{-}}\NormalTok{ ang1)}\SpecialCharTok{*}\NormalTok{pi}\SpecialCharTok{/}\DecValTok{180}\NormalTok{))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \DecValTok{0}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \DecValTok{0}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/unnamed-chunk-9-1} \end{center}

En el caso de la anisotropía zonal se suele considerar una combinación de un semivariograma isotrópico más otros ``zonales'' que depende solamente de la distancia en ciertas direcciones (o componentes del vector de salto).
Por ejemplo, en el caso bidimensional, si \(\phi\) es la dirección de mayor varianza se suele considerar una combinación de la forma:
\[\gamma(\mathbf{h})=\gamma_1 (\left\| \mathbf{h}\right\|)+\gamma_2(h_{\phi }),\]
siendo \(\gamma_1 (\cdot)\) y \(\gamma_2 (\cdot)\) semivariogramas isotrópicos, y \(h_{\phi } =\cos (\phi)h_1 +\sin(\phi)h_2\) el salto en la dirección \(\phi\), para \(\mathbf{h}=(h_1 ,h_2)\in \mathbb{R} ^{2}\).
Es importante destacar que este tipo de anisotropías pueden causar la aparición de problemas al realizar predicción espacial (ver e.g.~Myers y Journel, 1990; y Rouhani y Myers, 1990), como por ejemplo dar lugar a sistemas kriging no válidos con ciertas configuraciones de los datos.
Hay que tener un especial cuidado cuando el covariograma es expresado como suma de covariogramas unidimensionales, en cuyo caso el resultado puede ser únicamente condicionalmente semidefinido positivo sobre un dominio multidimensional.
Este tipo de modelos son casos particulares del modelo lineal de regionalización descrito en la siguiente sección.

Una variante de la anisotropía zonal es el caso de covariogramas separables (también denominados factorizables) en componentes del vector de salto.
Por ejemplo, un covariograma completamente separable en \(\mathbb{R}^2\) es de la forma \(C(h_1, h_2)= C_1(h_1)C_2(h_2)\), siendo \(C_1(\cdot)\) y \(C_2(\cdot)\) covariogramas en \(\mathbb{R}^{1}\).
En este caso se puede pensar que el proceso espacial se obtiene como producto de procesos unidimensionales independientes definidos sobre cada uno de los ejes de coordenadas.
Este tipo de modelos se utilizan habitualmente en geoestadística espacio-temporal (aunque no permiten modelar interacciones).

\hypertarget{vario-lin-reg}{%
\subsection{El modelo lineal de regionalización}\label{vario-lin-reg}}

A partir de las propiedades 1 y 2 del semivariograma mostradas en la Sección \ref{propiedades-elementales}, se obtienen los denominados \emph{modelos lineales de regionalización} (también \emph{modelos anidados} o \emph{nested models}):
\[\gamma(\mathbf{h}) = \sum\limits_{k=0}^{q}b_{k} \gamma_{k}(\mathbf{h}),\]
siendo \(b_k \ge 0\) y \(\gamma_{k}(\mathbf{h})\) modelos básicos de semivariogramas, \(k=1, \ldots, q\).
La denominación de ``modelos lineales'' surge porque estos modelos se obtienen al suponer que el proceso espacial es una combinación lineal procesos espaciales intrínsecamente estacionarios mutuamente independientes.

Los modelos básicos suelen incluir un efecto nugget y algunos de los modelos mostrados en la sección anterior con efecto nugget nulo y umbral unidad.
Además, cada modelo básico puede incorporar algún tipo de anisotropía (Sección \ref{anisotropia}), típicamente anisotropía geométrica:
\[\gamma_{k}(\mathbf{h})\equiv \gamma_{k}^{} \left( \left\| \mathbf{A}_{k} \mathbf{h}\right\| \right)\]
siendo \(\mathbf{A}_{k} ,k=0,\ldots,q\) matrices \(d\times d\).
De esta forma los modelos pueden ser lo suficientemente flexibles como para modelar la mayoría de situaciones que se pueden presentar en la práctica.
Sin embargo, es difícil establecer un procedimiento automático (o semi-automático) para la selección y el ajuste de este tipo de modelos.
Esto provoca que el proceso normalmente se realice en la práctica de forma interactiva por el usuario y utilizando principalmente herramientas gráficas\footnote{Ver por ejemplo Goovaerts (1997, Sección 4.2.4) para detalles sobre el uso en la práctica de éste tipo de modelos.}; siendo por tanto poco recomendables para algunos casos.
En primer lugar hay que especificar el número y tipo de estructuras básicas, y en segundo lugar (aunque se suele hacer en la práctica de forma simultánea) está el problema de la estimación de los parámetros, donde puede ser especialmente complicado la determinación de los rangos y los parámetros de anisotropía de los distintos componentes (es de esperar que aparezcan problemas en la optimización).

En \texttt{gstat} se pueden definir modelos de este tipo empleando el parámetro \texttt{add.to} de la función \texttt{vgm()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v2 }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{psill =} \DecValTok{1}\NormalTok{, }\AttributeTok{model =} \StringTok{"Gau"}\NormalTok{, }\AttributeTok{range =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{v12 }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{psill =} \DecValTok{1}\NormalTok{, }\AttributeTok{model =} \StringTok{"Gau"}\NormalTok{, }\AttributeTok{range =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{add.to =}\NormalTok{ v1)}
\NormalTok{v12}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model psill range
## 1   Nug     0   0.0
## 2   Exp     1   0.5
## 3   Gau     1   0.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Cuidado con plot.variogramModel() si se pretende añadir elementos}
\FunctionTok{plot}\NormalTok{(}\FunctionTok{variogramLine}\NormalTok{(v12, }\AttributeTok{maxdist =} \DecValTok{3}\NormalTok{), }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{2.25}\NormalTok{))}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{variogramLine}\NormalTok{(v1, }\AttributeTok{maxdist =} \DecValTok{3}\NormalTok{), }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{variogramLine}\NormalTok{(v2, }\AttributeTok{maxdist =} \DecValTok{3}\NormalTok{), }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"bottomright"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"Exponencial"}\NormalTok{, }\StringTok{"Gaussiano"}\NormalTok{, }\StringTok{"Anidado"}\NormalTok{), }\AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{), }
       \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"black"}\NormalTok{), }\AttributeTok{cex =} \FloatTok{0.75}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/unnamed-chunk-10-1} \end{center}

\hypertarget{ajuste-variog}{%
\section{Ajuste de un modelo válido}\label{ajuste-variog}}

Como ya se comentó anteriormente, en general los estimadores del variograma no pueden ser usados directamente en la predicción espacial;
no son condicionalmente semidefinidos negativos y eso puede causar por ejemplo sistemas kriging inválidos o estimaciones negativas de la varianza kriging.
Este problema normalmente se remedia buscando un modelo paramétrico válido que describa adecuadamente la dependencia espacial presente en los datos.
Supongamos que \(P=\left\{ 2\gamma(\mathbf{h};\boldsymbol{\theta}):\boldsymbol{\theta}\in \Theta \right\}\), donde \(2\gamma(\mathbf{h};\boldsymbol{\theta})\) es un variograma válido en \(\mathbb{R}^{d}\) (normalmente isotrópico), es la familia parametrizada de variogramas escogida.
Se trata de encontrar el mejor elemento de \(P\), para lo que se han propuesto diversos criterios de bondad de ajuste (ver e.g.~Cressie, 1993, Sección 2.6).
Entre ellos hay que destacar los basados en mínimos cuadrados y en máxima verosimilitud, descritos a continuación.

\hypertarget{ls-fit}{%
\subsection{Estimación por mínimos cuadrados}\label{ls-fit}}

Supongamos que \(2\gamma(\mathbf{h};\boldsymbol{\theta}_0)\) es el variograma teórico y que \(\hat{\gamma}_{i} =\hat{\gamma}(\mathbf{h}_{i})\), \(i = 1,\ldots,K\), son las estimaciones del semivariograma obtenidas utilizando algún tipo de estimador piloto (e.g.~alguno de los mostrados en la Sección 4.1.1).
Normalmente, siguiendo las recomendaciones sugeridas por Journel y Huijbregts (1978, p.~194), solamente se consideran en el ajuste saltos menores o iguales que la mitad del máximo salto (i.e.~\(\left\| \mathbf{h}_{i} \right\| \leq \frac{1}{2} \max \left\{ \left\| \mathbf{s}_{k} -\mathbf{s}_{l} \right\| \right\}\)); y, si se utiliza el estimador empírico (o uno similar), de forma que el número de aportaciones a cada estimación sea por lo menos de treinta (i.e.~\(\left| N(\mathbf{h}_{i})\right| \geq 30\)).
Habitualmente (e.g.~Cressie, 1993, p.~96-97) la estimación por mínimos cuadrados de \(\boldsymbol{\theta}_0\) se obtiene al minimizar:
\begin{equation} 
  \left( \hat{\boldsymbol{\gamma}} - \boldsymbol{\gamma}(\boldsymbol{\theta})\right)^{\top } \mathbf{V}(\boldsymbol{\theta})\left( \hat{\boldsymbol{\gamma}} - \boldsymbol{\gamma}(\boldsymbol{\theta})\right),
  \label{eq:ls-obj}
\end{equation}
siendo \(\hat{\boldsymbol{\gamma}} =(\hat{\gamma}(\mathbf{h}_1),\ldots,\hat{\gamma} (\mathbf{h}_{K}))^\top\), \(\boldsymbol{\gamma}(\boldsymbol{\theta})=(\gamma(\mathbf{h}_1 ;\boldsymbol{\theta}),\ldots,\gamma(\mathbf{h}_{K} ;\boldsymbol{\theta}))^\top\)
y \(\mathbf{V}(\boldsymbol{\theta})\) una matriz \(K\times K\) semidefinida positiva que puede
depender de \(\boldsymbol{\theta}\), considerando alguno de los siguientes casos:

\begin{itemize}
\item
  Mínimos cuadrados ordinarios (OLS): \(\mathbf{V}(\boldsymbol{\theta}) = \mathbf{I}_{K}\),
  la matriz identidad \(K\times K\).
\item
  Mínimos cuadrados ponderados (WLS): \(\mathbf{V}(\boldsymbol{\theta}) = \text{diag}(w_1 (\boldsymbol{\theta}),\ldots,w_{K}(\boldsymbol{\theta}))\),
  con \(w_{i}(\boldsymbol{\theta})\geq 0\), \(i=1,\ldots,K\).
  Normalmente se suele tomar estos pesos inversamente proporcionales a \(Var(\hat{\gamma}(\mathbf{h}_{i}))\).
\item
  Mínimos cuadrados generalizados (GLS): \(\mathbf{V}(\boldsymbol{\theta})=\boldsymbol{\Sigma}_{\hat{\boldsymbol{\gamma}}} (\boldsymbol{\theta})^{-1}\),
  la inversa de la matriz de covarianzas (asintótica) de \(\hat{\boldsymbol{\gamma}}\) obtenida suponiendo que el variograma teórico es \(2\gamma(\mathbf{h};\boldsymbol{\theta})\).
\end{itemize}

Es importante señalar que al utilizar el criterio GLS el cálculo de la matriz de covarianzas \(\boldsymbol{\Sigma}_{\hat{\boldsymbol{\gamma}}} (\boldsymbol{\theta})\) generalmente no resulta fácil (por ejemplo en Cressie 1993, p.~96, se tienen las expresiones para el estimador empírico y el estimador robusto, suponiendo normalidad).
Esto produce que la minimización de la función objetivo \eqref{eq:ls-obj} sea computacionalmente prohibitiva en muchos casos.
El método de mínimos cuadrados ponderados puede verse como un compromiso entre la eficiencia del método de GLS y la simplicidad del método de OLS.
Además, suponiendo normalidad y que el variograma teórico es \(2\gamma(\mathbf{h};\boldsymbol{\theta})\), Cressie (1985) probó que:
\[Var(\hat{\gamma}(\mathbf{h}_{i}))\simeq 2\dfrac{\gamma(\mathbf{h}_{i}
;\boldsymbol{\theta})^2 }{\left| N(\mathbf{h}_{i})\right| },\]
en el caso del estimador empírico; y para el estimador robusto:
\[Var(\tilde{\gamma}(\mathbf{h}_{i}))\simeq 2.885\dfrac{\gamma
(\mathbf{h}_{i} ;\boldsymbol{\theta})^2 }{\left| N(\mathbf{h}_{i})\right| },\]
siendo esta aproximación incluso mejor que en el caso anterior.
Proponiendo en estos casos la minimización de:
\[\sum\limits_{i=1}^{K} w_{i}(\boldsymbol{\theta}) \left( \hat{\gamma}(\mathbf{h}_{i}) - \gamma(\mathbf{h}_{i};\boldsymbol{\theta}) \right)^2,\]
siendo \(w_{i}(\boldsymbol{\theta}) = \left| N(\mathbf{h}_{i})\right| /\gamma(\mathbf{h}_{i} ;\boldsymbol{\theta})^2\), como aproximación al criterio WLS.

Estos métodos de ajuste tiene unas propiedades interesantes, cuanto mayor sea \(\left| N(\mathbf{h}_{i})\right|\) mayor peso recibe el residuo en el salto \(\mathbf{h}_{i}\) y además, cuanto más pequeño sea el valor del variograma teórico mayor peso recibe también el residuo correspondiente.
Por este motivo, los saltos próximos al origen típicamente reciben mayor peso con lo que se consigue un buen ajuste del modelo de variograma cerca del origen (esto es especialmente importante; ver e.g.~Stein, 1988, y comentarios en la Sección \ref{consideraciones-kriging}).
Adicionalmente estos métodos pueden ser implementados fácilmente en la práctica (de forma similar al OLS).

Aunque para obtener las expresiones (o aproximaciones) de las varianzas y covarianzas de las estimaciones piloto se supone habitualmente que la distribución de los datos es normal, se puede probar fácilmente que los procedimientos de ajuste obtenidos son también válidos para el caso de datos normales transformados (ver e.g.~Cressie, 1993, p.~98).
Esta es una de las principales ventajas de los métodos WLS o GLS frente a otras alternativas (como los métodos basados en máxima verosimilitud); como utilizan solamente la estructura de segundo orden (asintótica) del estimador del variograma, no es necesario hacer suposiciones sobre la distribución completa de los datos\footnote{La distribución y eficiencia asintótica de los estimadores mínimo cuadráticos ha sido estudiada por Lahiri et al.~(2003), demostrando su consistencia y normalidad asintótica bajo condiciones muy generales.}.

Como comentario final, en la función objetivo \eqref{eq:ls-obj} de los criterios WLS y GLS anteriores, la matriz de pesos utilizada en el ajuste \(\mathbf{V}(\boldsymbol{\theta})\) depende también del parámetro sobre el que se realiza la minimización (y al minimizar \eqref{eq:ls-obj} en cierto sentido se están maximizando también las varianzas), por lo que puede ser preferible utilizar un algoritmo iterativo.
Por ejemplo comenzar con pesos OLS (o WLS con \(w_{i} = \left| N(\mathbf{h}_{i})\right| / \| \mathbf{h}_{i} \|^2\)) y posteriormente en cada etapa \(k\) obtener una nueva aproximación \(\hat{\boldsymbol{\theta}}_0^{(k)}\) al minimizar:
\[\left( \hat{\boldsymbol{\gamma}} - \boldsymbol{\gamma}(\boldsymbol{\theta})\right)^{\top } \mathbf{V}(\hat{\boldsymbol{\theta}}_0^{(k-1)})\left( \hat{\boldsymbol{\gamma}} - \boldsymbol{\gamma}(\boldsymbol{\theta})\right),\]
repitiendo este proceso hasta convergencia (realmente muchos de los algoritmos diseñados para el ajuste por mínimos cuadrados proceden de esta forma).

En \texttt{gstat} el ajuste OLS y WLS se realiza mediante la función:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fit.variogram}\NormalTok{(object, model, }\AttributeTok{fit.sills =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{fit.ranges =} \ConstantTok{TRUE}\NormalTok{,}
              \AttributeTok{fit.method =} \DecValTok{7}\NormalTok{, }\AttributeTok{fit.kappa =} \ConstantTok{FALSE}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  \texttt{object}: semivariograma empírico, obtenido con la función \texttt{variogram()}.
\item
  \texttt{model}: modelo de semivariograma, generado con la función \texttt{vgm()}.
\item
  \texttt{fit.sills}, \texttt{fit.ranges}, \texttt{fit.kappa}: determinan si se ajustan los correspondientes parámetros (\texttt{TRUE}) o se mantienen fijos (\texttt{FALSE}).
\item
  \texttt{fit.method}: selección de los pesos en el criterio WLS.

  \begin{itemize}
  \tightlist
  \item
    \texttt{fit.method\ =\ 6}: \(w_{i} = 1\), OLS.
  \item
    \texttt{fit.method\ =\ 1}: \(w_{i} = \left| N(\mathbf{h}_{i})\right|\).
  \item
    \texttt{fit.method\ =\ 7}: \(w_{i} = \left| N(\mathbf{h}_{i})\right| / \| \mathbf{h}_{i} \|^2\).
  \item
    \texttt{fit.method\ =\ 2}: \(w_{i} = \left| N(\mathbf{h}_{i})\right| /\gamma(\mathbf{h}_{i} ;\boldsymbol{\theta})^2\).
  \end{itemize}
\end{itemize}

Los parámetros iniciales se fijan a los establecidos en \texttt{model}. Si alguno es desconocido (\texttt{NA}), le asigna un valor por defecto:

\begin{itemize}
\tightlist
\item
  el rango se establece a 1/3 de la distancia máxima del variograma empírico,
\item
  al umbral parcial se le asigna el promedio de los últimos 5 valores del variograma empírico,
\item
  y el efecto nugget (siempre que haya sido establecido explícitamente con \texttt{nugget\ =\ NA}) se toma como la media de los tres primeros valores del variograma empírico.
\end{itemize}

Como ejemplo, a continuación se ajusta un modelo exponencial al variograma empírico calculado en la Sección \ref{vario-muestrales}, mediante OLS y WLS con diferentes pesos:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{nugget =} \ConstantTok{NA}\NormalTok{) }\CommentTok{\# Valores iniciales por defecto, incluyendo nugget}
\CommentTok{\# modelo \textless{}{-} vgm(psill = 0.6, model = "Exp", range = 0.2, nugget = 0.0) \# Valores iniciales}
\NormalTok{fit.ols }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(vario, }\AttributeTok{model =}\NormalTok{ modelo, }\AttributeTok{fit.method =} \DecValTok{6}\NormalTok{)}
\CommentTok{\# fit.npairs \textless{}{-} fit.variogram(vario, model = modelo, fit.method = 1) \# Warning: No convergence}
\NormalTok{fit.npairs }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(vario, }\AttributeTok{model =}\NormalTok{ fit.ols, }\AttributeTok{fit.method =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in fit.variogram(vario, model = fit.ols, fit.method = 1): No convergence
## after 200 iterations: try different initial values?
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.lin }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(vario, }\AttributeTok{model =}\NormalTok{ modelo, }\AttributeTok{fit.method =} \DecValTok{7}\NormalTok{)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(vario, }\AttributeTok{model =}\NormalTok{ fit.lin, }\AttributeTok{fit.method =} \DecValTok{2}\NormalTok{) }
\CommentTok{\# Representar:}
\CommentTok{\# Cuidado con plot.variogramModel() si se pretende añadir elementos}
\FunctionTok{plot}\NormalTok{(vario}\SpecialCharTok{$}\NormalTok{dist, vario}\SpecialCharTok{$}\NormalTok{gamma, }\AttributeTok{xlab =} \StringTok{"distance"}\NormalTok{, }\AttributeTok{ylab =}  \StringTok{"semivariance"}\NormalTok{, }
     \AttributeTok{pch =} \DecValTok{19}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{variogramLine}\NormalTok{(fit.ols, }\AttributeTok{maxdist =} \FloatTok{0.6}\NormalTok{), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{variogramLine}\NormalTok{(fit.npairs, }\AttributeTok{maxdist =} \FloatTok{0.6}\NormalTok{), }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{variogramLine}\NormalTok{(fit.lin, }\AttributeTok{maxdist =} \FloatTok{0.6}\NormalTok{), }\AttributeTok{lty =} \DecValTok{4}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{variogramLine}\NormalTok{(fit, }\AttributeTok{maxdist =} \FloatTok{0.6}\NormalTok{))}
\FunctionTok{legend}\NormalTok{(}\StringTok{"bottomright"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"ols"}\NormalTok{, }\StringTok{"npairs"}\NormalTok{, }\StringTok{"default (linear)"}\NormalTok{, }\StringTok{"cressie"}\NormalTok{), }\AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/unnamed-chunk-12-1} \end{center}

En general, se recomendaría emplear pesos inversamente proporcionales a la varianza (\texttt{fit.method\ =\ 2}).
Si quisiésemos comparar el ajuste de distintos modelos (con el mismo criterio de ajuste) se podría considerar el valor mínimo de la función objetivo WLS, almacenado como un atributo del resultado (aunque la recomendación sería emplear validación cruzada, Sección \ref{validacion-cruzada}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{attr}\NormalTok{(fit, }\StringTok{"SSErr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 52.83535
\end{verbatim}

Imprimiendo el resultado del ajuste obtenemos las estimaciones de los parámetros, que podríamos interpretar (ver Sección \ref{caracteristicas-variograma} y Sección \ref{efecto-variog-kriging}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model   psill     range
## 1   Nug 0.13495 0.0000000
## 2   Exp 1.15982 0.6403818
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nugget }\OtherTok{\textless{}{-}}\NormalTok{ fit}\SpecialCharTok{$}\NormalTok{psill[}\DecValTok{1}\NormalTok{]}
\NormalTok{sill }\OtherTok{\textless{}{-}}\NormalTok{ nugget }\SpecialCharTok{+}\NormalTok{ fit}\SpecialCharTok{$}\NormalTok{psill[}\DecValTok{2}\NormalTok{]}
\NormalTok{range }\OtherTok{\textless{}{-}} \DecValTok{3}\SpecialCharTok{*}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{range[}\DecValTok{2}\NormalTok{] }\CommentTok{\# Parámetro de escala en model = "Exp"}
\end{Highlighting}
\end{Shaded}

NOTA: Cuidado, en el caso del modelo exponencial, el parámetro que aparece como \texttt{range} es un parámetro de escala proporcional al verdadero rango práctico (tres veces ese valor).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(vario}\SpecialCharTok{$}\NormalTok{dist, vario}\SpecialCharTok{$}\NormalTok{gamma, }\AttributeTok{xlab =} \StringTok{"distance"}\NormalTok{, }\AttributeTok{ylab =}  \StringTok{"semivariance"}\NormalTok{, }
     \AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, range}\SpecialCharTok{*}\FloatTok{1.1}\NormalTok{), }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, sill}\SpecialCharTok{*}\FloatTok{1.1}\NormalTok{))}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{variogramLine}\NormalTok{(fit, }\AttributeTok{maxdist =}\NormalTok{ range}\SpecialCharTok{*}\FloatTok{1.1}\NormalTok{))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \DecValTok{0}\NormalTok{, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ range, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ nugget, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ sill, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/unnamed-chunk-15-1} \end{center}

En \texttt{gstat} el ajuste con el criterio GLS se podría realizar mediante la función:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fit.variogram.gls}\NormalTok{(formula, data, model, }\AttributeTok{maxiter =} \DecValTok{30}\NormalTok{, }\AttributeTok{eps =}\NormalTok{ .}\DecValTok{01}\NormalTok{, }
      \AttributeTok{trace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{ignoreInitial =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{cutoff =} \ConstantTok{Inf}\NormalTok{, }\AttributeTok{plot =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Sin embargo, actualmente solo admite datos tipo \texttt{Spatial*} del paquete \texttt{sp} y además es habitual que aparezcan problemas computacionales, por lo que no se recomendaría su uso.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fit.variogram.gls}\NormalTok{(z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\FunctionTok{as}\NormalTok{(datos, }\StringTok{"Spatial"}\NormalTok{), modelo, }
                  \AttributeTok{maxiter =} \DecValTok{2}\NormalTok{, }\AttributeTok{cutoff =} \FloatTok{0.6}\NormalTok{, }\AttributeTok{plot =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\# Error in if (any(model$range \textless{} 0)) \{ :  missing value where TRUE/FALSE needed}
\end{Highlighting}
\end{Shaded}

\hypertarget{trend-fit}{%
\subsection{Modelado del variograma en procesos no estacionarios}\label{trend-fit}}

Como ya se comentó en la introducción de este capítulo, si no se puede asumir que la tendencia es constante no es apropiado utilizar directamente los estimadores del semivariograma mostrados en la Sección \ref{vario-muestrales}.
Por ejemplo, considerando el modelo lineal \eqref{eq:modelolineal} de la Sección \ref{modelos-clasicos-espaciales} (el modelo del \emph{kriging universal}, Sección \ref{kuniversal}; que emplearemos en el resto de este capítulo), tendríamos que:
\[E(Z(\mathbf{s}_1)-Z(\mathbf{s}_{2}))^2 =2\gamma(\mathbf{s}_1
-\mathbf{s}_{2}) + \left( \sum\limits_{j=0}^{p}\beta_{j}  \left( X_{j}
(\mathbf{s}_1)-X_{j}(\mathbf{s}_{2})\right) \right)^2.\]
Muchas veces, cuando las estimaciones experimentales del semivariograma aparentan no estar acotadas (e.g.~Figura \ref{fig:aquifer-var-trend} izquierda), es debido a que la tendencia no está especificada correctamente.

El procedimiento habitual en geoestadística es eliminar la tendencia y estimar el variograma a partir de los residuos. Por ejemplo, en este caso, podríamos considerar los residuos de un ajuste OLS de la tendencia:
\[\mathbf{r}_{ols} =\mathbf{Z}-\mathbf{X}\hat{\boldsymbol{\beta}}_{ols} =\left( \mathbf{I}_{n}
- (\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^{\top} \right)\mathbf{Z}.\]
Esto se puede hacer con la función \texttt{variogram()} del paquete \texttt{gstat} especificando la fórmula del modelo como primer argumento (ver Figura \ref{fig:aquifer-var-trend} derecha).

Como ejemplo consideraremos los datos del acuífero Wolfcamp:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"datos/aquifer.RData"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(sf)}
\NormalTok{aquifer}\SpecialCharTok{$}\NormalTok{head }\OtherTok{\textless{}{-}}\NormalTok{ aquifer}\SpecialCharTok{$}\NormalTok{head}\SpecialCharTok{/}\DecValTok{100} \CommentTok{\# en cientos de pies}
\NormalTok{aquifer\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_as\_sf}\NormalTok{(aquifer, }\AttributeTok{coords =} \FunctionTok{c}\NormalTok{(}\StringTok{"lon"}\NormalTok{, }\StringTok{"lat"}\NormalTok{), }\AttributeTok{remove =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{agr =} \StringTok{"constant"}\NormalTok{)}
\CommentTok{\# maxlag \textless{}{-} 0.5*sqrt(sum(diff(matrix(st\_bbox(aquifer\_sf), nrow = 2, byrow = TRUE))\^{}2))}

\NormalTok{vario.est }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(head }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, aquifer\_sf, }\AttributeTok{cutoff =} \DecValTok{150}\NormalTok{)}
\NormalTok{vario.resid }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(head }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lon }\SpecialCharTok{+}\NormalTok{ lat, aquifer\_sf, }\AttributeTok{cutoff =} \DecValTok{150}\NormalTok{)    }
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\CommentTok{\# plot(vario.est) \# no compatible con mfrow}
\FunctionTok{with}\NormalTok{(vario.est,  }\FunctionTok{plot}\NormalTok{(dist, gamma, }\AttributeTok{xlab =} \StringTok{"distance"}\NormalTok{, }\AttributeTok{ylab =}  \StringTok{"semivariance"}\NormalTok{))}
\CommentTok{\# plot(vario.resid)}
\FunctionTok{with}\NormalTok{(vario.resid,  }\FunctionTok{plot}\NormalTok{(dist, gamma, }\AttributeTok{xlab =} \StringTok{"distance"}\NormalTok{, }\AttributeTok{ylab =}  \StringTok{"semivariance"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.9\linewidth]{03-modelado_files/figure-latex/aquifer-var-trend-1} 

}

\caption{Semivariograma empírico obtenido asumiendo media constante (izquierda) y a partir de los residuos de un ajuste lineal de la tendencia (derecha), empleando los datos del acuífero Wolfcamp.}\label{fig:aquifer-var-trend}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

El ajuste por WLS se puede realizar también con la función \texttt{fit.variogram()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{nugget =} \ConstantTok{NA}\NormalTok{) }\CommentTok{\# Valores iniciales por defecto}
\CommentTok{\# modelo \textless{}{-} vgm(psill = 3, model = "Sph", range = 75, nugget = 0) }
\NormalTok{fit.resid }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(vario.resid, modelo, }\AttributeTok{fit.method =} \DecValTok{2}\NormalTok{)}
\NormalTok{fit.resid}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model    psill    range
## 1   Nug 1.095133  0.00000
## 2   Sph 3.044034 63.39438
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Cuidado con plot.variogramModel() si se pretende añadir elementos}
\CommentTok{\# plot(fit.resid, cutoff = 150, ylim = c(0, 4.5))}
\CommentTok{\# with(vario.resid,  points(dist, gamma))}
\FunctionTok{with}\NormalTok{(vario.resid, }\FunctionTok{plot}\NormalTok{(dist, gamma, }\AttributeTok{xlab =} \StringTok{"distance"}\NormalTok{, }\AttributeTok{ylab =}  \StringTok{"semivariance"}\NormalTok{, }
                       \AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{150}\NormalTok{), }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{)))}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{variogramLine}\NormalTok{(fit.resid, }\AttributeTok{maxdist =} \DecValTok{150}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.7\linewidth]{03-modelado_files/figure-latex/aquifer-var-fit-1} 

}

\caption{Ajuste de un modelo esférico de semivariograma a las estimaciones empíricas obtenidas a partir de los residuos de un ajuste lineal de la tendencia, empleando los datos del acuífero Wolfcamp.}\label{fig:aquifer-var-fit}
\end{figure}

Sin embargo, para poder estimar la tendencia de forma eficiente sería necesario conocer la dependencia (i.e.~conocer \(\gamma(\cdot)\)), que dependería a su vez de la estimación de la tendencia.
Para solventar este problema circular, Neuman y Jacobson (1984) propusieron una aproximación iterativa, empezar con el estimador OLS de \(\boldsymbol{\theta}\), estimar el variograma a partir de los residuos, ajustar un modelo de variograma válido, calcular el estimador GLS basado en el modelo ajustado y así sucesivamente hasta convergencia.
En la práctica este procedimiento suele converger en pocas iteraciones (normalmente menos de 5).
Sin embargo, en el paquete \texttt{gstat} solo se realiza una iteración (se reestimará la tendencia empleando GLS al calcular las predicciones kriging).

En el caso de variogramas no acotados, el proceso \(\varepsilon(\cdot)\) no sería estacionario de segundo orden, no está disponible la matriz \(\boldsymbol{\Sigma}\) y en principio sería imposible emplear GLS para estimar la tendencia.
Sin embargo, normalmente se suele trabajar en un dominio acotado \(D\) y podemos encontrar una constante positiva \(A\) tal que \(C^{\ast }(\mathbf{h})= A-\gamma(\mathbf{h})\geq 0,\forall \mathbf{h}\in D\) (y por tanto esta función es un covariograma válido en ese dominio).
La función \(C^{\ast }(\mathbf{h})\) se suele denominar \emph{pseudo-covariograma} (o covarianza localmente equivalente; ver e.g.~Chilès y Delfiner, 1999, Sección 4.6.2).
Si utilizamos \(C^{\ast }(\mathbf{h})\) en lugar del covariograma en la estimación de la media (o en las ecuaciones del predictor del KU), la constante \emph{A} se cancela y obtenemos los mismos resultados (sin embargo las varianzas si que dependen de esta constante).

Adicionalmente, habría que tener en cuenta también que la variabilidad de los residuos no es la de los errores teóricos (algo que normalmente se ignora).
Para ilustrar este problema supongamos que el proceso de error \(\varepsilon(\cdot)\) es estacionario de segundo orden con covariograma conocido \(C(\cdot)\) de forma que podemos calcular el estimador lineal óptimo de \(\boldsymbol{\beta}\):
\[\hat{\boldsymbol{\beta}}_{gls} =(\mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{X})^{-1} \mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{Z} = \mathbf{P}_{gls}\mathbf{Z},\]
siendo \(\mathbf{P}_{gls}\) la matriz de proyección.
Empleando este estimador obtenemos el vector de residuos:
\[\mathbf{r} =\mathbf{Z}-\mathbf{X}\hat{\boldsymbol{\beta}}_{gls} =\left( \mathbf{I}_{n} - \mathbf{P}_{gls} \right)\mathbf{Z},\]
cuya matriz de varianzas-covarianzas resulta ser:
\[\begin{aligned}
Var(\mathbf{r}) &=(\mathbf{I}_{n} -\mathbf{P}_{gls})\boldsymbol{\Sigma}(\mathbf{I}_{n}
-\mathbf{P}_{gls})^\top  \\
& = \boldsymbol{\Sigma} - \mathbf{X}(\mathbf{X}^\top\boldsymbol{\Sigma}^{-1} \mathbf{X})^{-1}
\mathbf{X}^\top.
\end{aligned}\]
De donde se deduce que si utilizamos directamente los residuos, incluso procediendo de la forma más eficiente, se introduce un sesgo en la estimación de la dependencia espacial.
Explícitamente, si denotamos por \(\hat{\mu}(\mathbf{s})\) la estimación GLS de la tendencia, puede verse que:
\[\begin{aligned}
C_{\mathbf{r}}(\mathbf{s}_{i} ,\mathbf{s}_{j}) &= Cov\left(Z(\mathbf{s}_{i})-\hat{\mu}(\mathbf{s}_{i}), Z(\mathbf{s}_{j} ) - \hat{\mu}(\mathbf{s}_{j})\right) \\
&= C(\mathbf{s}_{i} -\mathbf{s}_{j}) - Cov(\hat{\mu}(\mathbf{s}_{i} ), \hat{\mu}(\mathbf{s}_{j})),
\end{aligned}\]
y expresado en función del semivariograma:
\[\gamma_{\mathbf{r}}(\mathbf{s}_{i} ,\mathbf{s}_{j}) = \gamma
(\mathbf{s}_{i} -\mathbf{s}_{j})-\frac{1}{2} Var(\hat{\mu}
(\mathbf{s}_{i})-\hat{\mu}(\mathbf{s}_{j})).\]

Por tanto al utilizar alguno de los estimadores mostrados anteriormente con los residuos estimados obtenemos estimaciones sesgadas del semivariograma teórico.
Matheron (1971, pp.~152-155) ya notó que, por lo general, el sesgo del estimador del semivariograma es pequeño en los saltos próximos al origen, pero más sustancial en saltos grandes\footnote{Para un caso particular, Cressie (1993, pp.~166-167) observó que los residuos basados en el estimador GLS dan lugar a un estimador del variograma con sesgo negativo y cuadrático en h.}.
Parece ser que este problema provocó una desilusión con el kriging universal y la iniciativa hacia el kriging con funciones intrínsecamente estacionarias (ver e.g.~Matheron, 1973; Cressie, 1993, Sección 5.4; o Chilès y Delfiner, 1999, cap. 4).

En cuanto a las consecuencias de que el estimador del variograma no sea insesgado en el kriging universal, hay que tener en cuenta que:

\begin{itemize}
\tightlist
\item
  Al ajustar un modelo de variograma por mínimos cuadrados ponderados o generalizados (Sección \ref{ls-fit}), automáticamente los saltos pequeños reciben mayor peso en el ajuste.
\item
  Además si la predicción espacial se lleva a cabo con un criterio de vecindad, el variograma sólo es evaluado en saltos pequeños, donde se tiene una buena estimación y un buen ajuste.
\item
  También hay que tener en cuenta el resultado de Stein (1988), i.e.~para una predicción eficiente generalmente sólo es necesario capturar la conducta del variograma cerca del origen
\end{itemize}

Por lo anterior, el desencanto con el kriging universal ha sido prematuro, el efecto del sesgo del estimador del variograma sobre el predictor del kriging universal es pequeño.
Sin embargo la varianza del kriging universal se ve más afectada y es menor de lo que debería ser (para más detalles ver Cressie, 1993, pp.~296-299).
Adicionalmente se han propuesto alternativas a los métodos de ajuste basados en mínimos cuadrados que tienen en cuenta el sesgo en la estimación del variograma (e.g.~Beckers y Bogaert, 1998; Fernandez-Casal y Francisco-Fernandez, 2014, función \href{https://rubenfcasal.github.io/npsp/reference/np.svar.html}{\texttt{npsp::np.svariso.corr()}}).

Otra alternativa sería asumir normalidad y estimar ambos componentes de forma conjunta empleando alguno de los métodos basados en máxima verosimilitud descritos en la siguiente sección (que también tienen problemas de sesgo).

\hypertarget{ml-fit}{%
\subsection{Estimación por máxima verosimilitud}\label{ml-fit}}

La estimación por máxima verosimilitud (\emph{maximum likelihood}, ML) es un método muy conocido en inferencia estadística paramétrica, aunque su uso en geoestadística ha sido relativamente reciente (a partir de mediados de los 80).
Además la estimación ML tiene una conexión directa con la estimación Bayesiana (e.g.~Handcock y Wallis, 1994) y el empleo de estas herramientas en estadística espacial ha experimentado un notable aumento en los últimos años (e.g.~\href{https://spacetimewithr.org/}{Wikle et al., 2019}; \href{https://www.paulamoraga.com/book-geospatial/}{Moraga, 2020}).

Si suponemos que la distribución de los datos es normal:
\[\mathbf{Z}\sim \mathcal{N}(\mathbf{X}\boldsymbol{\beta},\boldsymbol{\Sigma}),\]
donde \(\boldsymbol{\Sigma}=\boldsymbol{\Sigma}(\boldsymbol{\theta})\) (utilizando la notación de secciones anteriores), se puede deducir fácilmente la expresión de la función de verosimilitud y obtener las estimaciones de los parámetros buscando los valores que la maximizan.

En este caso, la función de densidad de los datos es:
\[f(\mathbf{z})=(2\pi )^{-\frac{n}{2} } \left| \boldsymbol{\Sigma} \right|^{-\frac{1}{2} }
\exp \left\{ -\dfrac{1}{2}(\mathbf{z}-\mathbf{X}\boldsymbol{\beta})^\top \boldsymbol{\Sigma}^{-1}(\mathbf{z}-\mathbf{X}\boldsymbol{\beta})\right\}.\]
Además en la mayoría de los casos podemos reparametrizar el covariograma\footnote{Por ejemplo en el caso de los semivariogramas mostrados en la Sección \ref{modelos-parametricos}, si \(c_0\) es el efecto nugget y \(c_1\) el umbral parcial, en lugar de éstos parámetros se considerarían la varianza (umbral) \(\sigma^2 =c_0 +c_1\) y la proporción de nugget en el umbral total \(c_0^{\ast} =c_0 /(c_0 +c_1)\) (lo que equivale a suponer en las expresiones del covariograma que \(c_1 = 1 - c_0\) y \(0 \leq c_0 \leq 1\)).} de forma que:
\[\boldsymbol{\Sigma}=\sigma^2 \mathbf{V}(\boldsymbol{\theta}),\]
siendo \(\sigma^2\) la varianza desconocida (o umbral total), y se obtiene que la expresión del logaritmo negativo de la función de verosimilitud (\emph{negative log likelihood}, NLL) es:
\[\begin{aligned}
\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\beta},\sigma^2 \left| \mathbf{Z} \right.) & = \dfrac{n}{2} \ln (2\pi) + \dfrac{n}{2} \ln(\sigma^2) + \dfrac{1}{2} \ln \left| \mathbf{V}(\boldsymbol{\theta}) \right|  \\
& + \ \dfrac{1}{2\sigma^2 }(\mathbf{Z}-\mathbf{X}\boldsymbol{\beta})^\top \mathbf{V}(\boldsymbol{\theta})^{-1}(\mathbf{Z}-\mathbf{X}\boldsymbol{\beta}),
\end{aligned}\]
donde \(\left| \mathbf{V}(\boldsymbol{\theta})\right|\) denota el determinante de la matriz \(\mathbf{V}(\boldsymbol{\theta})\).
Las estimaciones de los parámetros \((\boldsymbol{\theta}, \boldsymbol{\beta}, \sigma^2)\) se obtendrán minimizando el NLL.
Un resultado bien conocido es que el mínimo se obtiene, independientemente de \(\boldsymbol{\theta}\), para:
\begin{equation} 
  \begin{aligned}
  \hat{\boldsymbol{\beta}} & =(\mathbf{X}^\top\mathbf{V}(\boldsymbol{\theta})^{-1} \mathbf{X})^{-1} \mathbf{X}^\top\mathbf{V}(\boldsymbol{\theta})^{-1} \mathbf{Z}, \\
  \hat{\sigma }^2 & =\dfrac{1}{n}(\mathbf{Z}-\mathbf{X}\hat{\boldsymbol{\beta}})^\top
  \mathbf{V}(\boldsymbol{\theta})^{-1}(\mathbf{Z}-\mathbf{X}\hat{\boldsymbol{\beta}}).
  \end{aligned}
  \label{eq:estimadores-ml}
\end{equation}
Por tanto la función a minimizar respecto a \(\boldsymbol{\theta}\) es:
\[\mathcal{L}(\boldsymbol{\theta}\left| \mathbf{Z}\right. )=\mathcal{L}(\hat{\boldsymbol{\beta}} ,\boldsymbol{\theta},\hat{\sigma }^2 \left|
\mathbf{Z}\right. ) = \dfrac{n}{2} \ln (2\pi ) + \dfrac{n}{2} \ln (\hat{\sigma
}^2) + \dfrac{1}{2} \ln \left| \mathbf{V}(\boldsymbol{\theta})\right| +\dfrac{n}{2}.\]
Para ello es necesario utilizar algoritmos de minimización no lineal multidimensional.
Además está el problema de la posible multimodalidad de esta función (ver e.g.~Mardia y Watkins, 1989), por tanto habría que asegurarse de que el algoritmo elegido no converge a un mínimo local.
Si \(\hat{\boldsymbol{\theta}}\) es la estimación de \(\boldsymbol{\theta}\) obtenida al resolver este problema, sustituyendo en \eqref{eq:estimadores-ml} se obtienen las estimaciones del resto de parámetros\footnote{El comportamiento asintótico (bajo dominio creciente) de estos estimadores ha sido estudiado por Mardia y Marshal (1984), dando condiciones (no muy fáciles de chequear en la práctica) para su consistencia y normalidad asintótica (ver también Cressie, 1993, Sección 7.3.1).}.

Uno de los principales problemas de la estimación ML es que los estimadores de \(\sigma^2\) y \(\boldsymbol{\theta}\) pueden tener un sesgo considerable (especialmente cuando la tendencia no es constante), algo que es bastante conocido en la estimación de la varianza con datos independientes.
Este problema se puede resolver (por lo menos en parte) utilizando una variante de este método.

El método de máxima verosimilitud restringida (\emph{restricted maximum likelihood}, REML) se basa en la idea de filtrar los datos de forma que la distribución conjunta no dependa de \(\boldsymbol{\beta}\).
Se trata de maximizar la verosimilitud de \(m=n-p-1\) contrastes de error linealmente independientes:
\[\mathbf{Y}=\boldsymbol{\Lambda}\mathbf{Z},\]
siendo \(\boldsymbol{\Lambda}\) una matriz \(m\times n\) de rango \(m\) y tal que \(\boldsymbol{\Lambda}\mathbf{X}=\mathbf{0}\) (i.e.~\(E(\mathbf{Y}) = \mathbf{0}\)).
Estas combinaciones lineales también se denominan habitualmente \emph{incrementos generalizados} y, asumiendo normalidad, su distribución no depende de \(\boldsymbol{\beta}\):
\[\mathbf{Y}\sim \mathcal{N}(\mathbf{0},\boldsymbol{\Lambda}\boldsymbol{\Sigma}\boldsymbol{\Lambda}^\top).\]
De forma análoga al caso anterior podríamos obtener la correspondiente función de verosimilitud. Además, Harville (1974) demostró que las verosimilitudes de distintos incrementos generalizados son iguales salvo una constante y que se pueden obtener expresiones simplificadas
seleccionando la matriz \(\boldsymbol{\Lambda}\) de forma que \(\boldsymbol{\Lambda}^\top \boldsymbol{\Lambda}=\mathbf{I}_{n} -\mathbf{X}(\mathbf{X^\top}\mathbf{X})^{-1} \mathbf{X}^\top\) y \(\boldsymbol{\Lambda}\boldsymbol{\Lambda}^\top =\mathbf{I}_{m}\), obteniéndose la siguiente expresión para el NLL:

\[\begin{aligned}
\mathcal{L}(\boldsymbol{\theta}\left| \mathbf{Y}\right. ) 
& = \dfrac{m}{2} \ln (2\pi ) + \dfrac{m}{2} \ln (\hat{\sigma}_{Y}^2) -\dfrac{1}{2} \left| \mathbf{X}^\top\mathbf{X}\right|  \\
& + \ \dfrac{1}{2} \left| \mathbf{X}^\top\mathbf{V}(\boldsymbol{\theta})^{-1}
\mathbf{X}\right| +\dfrac{1}{2} \ln \left| \mathbf{V}(\boldsymbol{\theta})\right|
+\dfrac{m}{2} ,\end{aligned}\]
siendo:
\[\hat{\sigma }_{Y}^2 =\dfrac{1}{m}(\mathbf{Z}-\mathbf{X}\hat{\boldsymbol{\beta}}
)^\top \mathbf{V}(\boldsymbol{\theta})^{-1}(\mathbf{Z}-\mathbf{X}\hat{\boldsymbol{\beta}}).\]

En general se da por hecho que la estimación REML mejora, a veces significativamente, los resultados obtenidos con la estimación ML (sobre todo si \(p\) es grande comparado con \(n\)).
En numerosos estudios de simulación (e.g.~Zimmerman y Zimmerman, 1991; Fernández-Casal et al., 2003b) se ha observado que el sesgo en las estimaciones de los parámetros del variograma es en general menor.

En \texttt{gstat} el ajuste mediante REML se podría realizar empleando la función:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fit.variogram.reml}\NormalTok{(formula, locations, data, model, }\AttributeTok{degree =} \DecValTok{0}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

Sin embargo, aparentemente \textbf{\emph{el método no está bien implementado}} (emplea \texttt{formula} para un ajuste OLS y después, en el código C interno, considera una tendencia polinómica en las coordenadas determinada por \texttt{degree}), actualmente solo admite datos tipo \texttt{Spatial*} del paquete \texttt{sp} y además es habitual que aparezcan problemas computacionales, por lo que no se recomendaría su uso.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{psill =} \DecValTok{3}\NormalTok{, }\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{range =} \DecValTok{75}\NormalTok{, }\AttributeTok{nugget =} \DecValTok{0}\NormalTok{)}
\FunctionTok{fit.variogram.reml}\NormalTok{(head }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =} \FunctionTok{as}\NormalTok{(aquifer\_sf, }\StringTok{"Spatial"}\NormalTok{), }\AttributeTok{model =}\NormalTok{ model, }\AttributeTok{degree =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model      psill range
## 1   Nug -0.7976219     0
## 2   Sph 12.5397527    75
\end{verbatim}

Como aparece en la ayuda de esta función, es preferible usar el paquete \texttt{geoR} (ver Sección \ref{geor-ajuste} del apéndice; también se podría emplear el paquete \texttt{nlme}), empleando la función \texttt{geoR::likfit()} para el ajuste y posteriormente \texttt{as.vgm.variomodel()} para convertir el modelo ajustado a un objeto de \texttt{gstat}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{geor.models }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{Exp =} \StringTok{"exponential"}\NormalTok{, }\AttributeTok{Sph =} \StringTok{"spherical"}\NormalTok{, }\AttributeTok{Cir =} \StringTok{"circular"}\NormalTok{, }
             \AttributeTok{Gau =} \StringTok{"gaussian"}\NormalTok{, }\AttributeTok{Mat =} \StringTok{"matern"}\NormalTok{, }\AttributeTok{Pow =} \StringTok{"power"}\NormalTok{, }\AttributeTok{Nug =} \StringTok{"nugget"}\NormalTok{, }
             \AttributeTok{Lin =} \StringTok{"linear"}\NormalTok{)}
\NormalTok{pars.ini }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{psill =} \DecValTok{3}\NormalTok{, }\AttributeTok{range =} \DecValTok{75}\NormalTok{, }\AttributeTok{nugget =} \DecValTok{0}\NormalTok{, }\AttributeTok{kappa =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}}\NormalTok{ geoR}\SpecialCharTok{::}\FunctionTok{likfit}\NormalTok{(}\AttributeTok{coords =} \FunctionTok{st\_coordinates}\NormalTok{(aquifer\_sf), }\AttributeTok{data =}\NormalTok{ aquifer\_sf}\SpecialCharTok{$}\NormalTok{head,}
             \AttributeTok{lik.method =} \StringTok{"REML"}\NormalTok{, }\AttributeTok{trend =} \StringTok{"1st"}\NormalTok{, }\AttributeTok{cov.model =}\NormalTok{ geor.models[}\StringTok{"Sph"}\NormalTok{], }
             \AttributeTok{ini.cov.pars =}\NormalTok{ pars.ini[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{], }\AttributeTok{nugget =}\NormalTok{ pars.ini[}\DecValTok{3}\NormalTok{], }\AttributeTok{kappa =}\NormalTok{ pars.ini[}\DecValTok{4}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## kappa not used for the spherical correlation function
## ---------------------------------------------------------------
## likfit: likelihood maximisation using the function optim.
## likfit: Use control() to pass additional
##          arguments for the maximisation function.
##         For further details see documentation for optim.
## likfit: It is highly advisable to run this function several
##         times with different initial values for the parameters.
## likfit: WARNING: This step can be time demanding!
## ---------------------------------------------------------------
## likfit: end of numerical maximisation.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(res)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Summary of the parameter estimation
## -----------------------------------
## Estimation method: restricted maximum likelihood 
## 
## Parameters of the mean component (trend):
##   beta0   beta1   beta2 
## 26.7704 -0.0701 -0.0634 
## 
## Parameters of the spatial component:
##    correlation function: spherical
##       (estimated) variance parameter sigmasq (partial sill) =  4.545
##       (estimated) cor. fct. parameter phi (range parameter)  =  79.16
##    anisotropy parameters:
##       (fixed) anisotropy angle = 0  ( 0 degrees )
##       (fixed) anisotropy ratio = 1
## 
## Parameter of the error component:
##       (estimated) nugget =  1.191
## 
## Transformation parameter:
##       (fixed) Box-Cox parameter = 1 (no transformation)
## 
## Practical Range with cor=0.05 for asymptotic range: 79.16084
## 
## Maximised Likelihood:
##    log.L n.params      AIC      BIC 
## "-160.4"      "6"  "332.7"  "347.4" 
## 
## non spatial model:
##    log.L n.params      AIC      BIC 
## "-174.5"      "4"  "357.1"  "366.8" 
## 
## Call:
## geoR::likfit(coords = st_coordinates(aquifer_sf), data = aquifer_sf$head, 
##     trend = "1st", ini.cov.pars = pars.ini[1:2], nugget = pars.ini[3], 
##     kappa = pars.ini[4], cov.model = geor.models["Sph"], lik.method = "REML")
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{as.vgm.variomodel}\NormalTok{(res)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model    psill    range
## 1   Nug 1.191129  0.00000
## 2   Sph 4.544502 79.16084
\end{verbatim}

\hypertarget{comentarios-sobre-los-distintos-muxe9todos}{%
\section{Comentarios sobre los distintos métodos}\label{comentarios-sobre-los-distintos-muxe9todos}}

Podemos afirmar que los métodos de estimación basados en mínimos cuadrados son los utilizados con mayor frecuencia en geoestadística.
Por el contrario la estimación por máxima verosimilitud ha sido objeto de debate, con numerosos comentarios en la literatura a favor (e.g.~Pardo-Igúzquiza, 1998) y en contra (e.g.~Ripley, 1988) de este tipo de métodos.

Una ventaja de los métodos de máxima verosimilitud es que permiten estimar de forma conjunta \(\boldsymbol{\beta}\) y \(\boldsymbol{\theta}\) directamente de los datos (y no es necesario calcular estimaciones piloto del variograma).
Los problemas numéricos relacionados con este tipo de estimación se pueden resolver en la práctica utilizando por ejemplo algoritmos genéticos;
aunque el tiempo de computación aumenta notablemente cuando el número de datos es grande (algo que también ocurre con el método GLS).
Sin embargo, uno de los principales inconvenientes normalmente achacados a estos métodos es que la hipótesis de normalidad es difícil (o más bien imposible) de chequear en la práctica a partir de una única realización parcial del proceso.
Otro problema que también se debe tener en cuenta al utilizar estos métodos es su falta de robustez cuando hay valores atípicos (outliers) en los datos.

No obstante es de esperar que las estimaciones obtenidas con los métodos de máxima verosimilitud sean más eficientes cuando la distribución de los datos se aproxima a la normalidad y el modelo paramétrico está especificado correctamente (especialmente con la estimación REML); aunque no está claro si esta mejora es realmente significativa comparada con otros métodos más sencillos como el de WLS.
De hecho, bajo la hipótesis de normalidad, Zimmerman y Zimmerman (1991) observaron, al comparar mediante simulación las estimaciones obtenidas utilizando
distintos métodos (entre ellos ML, REML, OLS, WLS y GLS), que el método de WLS era a veces el mejor procedimiento y nunca resultaba malo (considerando el sesgo, el error en media cuadrática y la cobertura del intervalo de predicción al 95\%).
Además, los métodos de mínimos cuadrados sólo utilizan la estructura asintótica de segundo orden del estimador piloto (no es necesario hacer suposiciones sobre la distribución completa de los datos), por lo que resultan ser más robustos que los de máxima verosimilitud cuando no se conoce por completo la distribución de \(Z\) (e.g.~Carroll y Ruppert, 1982) y son adecuados incluso cuando la distribución de los datos no es normal (aunque en ese caso pueden no ser los óptimos).
Los comentarios anteriores, además de su fácil implementación, justifican que el método WLS sea el preferible para muchos autores.

Por otra parte, si se asume un modelo paramétrico habrá que asegurarse en la práctica de que esa suposición es adecuada.
Diblasi y Bowman (2001) propusieron un método basado en la estimación no paramétrica para contrastar si el variograma teórico de un proceso estacionario es constante (i.e.~si no hay dependencia espacial; ver Figura \ref{fig:sm-variogram}).
Posteriormente Maglione y Diblasi (2004) propusieron contrastes de hipótesis para verificar si un determinado modelo paramétrico semivariograma es apropiado (ver también Bowman y Crujeiras, 2013).
Para evitar posibles problemas relacionados con la mala especificación del modelo de variograma se puede pensar en su estimación de forma no paramétrica
(Capítulo XX; ver paquete \href{https://rubenfcasal.github.io/post/geoestadistica-no-parametrica-con-el-paquete-npsp}{\texttt{npsp}}).
En este caso los métodos de mínimos cuadrados serán claramente preferibles a los basados en máxima verosimilitud.

Para comparar el ajuste obtenido con distintos modelos se pueden considerar los correspondientes valores finales de la función objetivo utilizada; por ejemplo los valores WLS (o GLS) correspondientes a su ajuste al estimador piloto o los valores del NLL si se utiliza alguno de los métodos de máxima verosimilitud (en este caso también se pueden emplear criterios para la selección de modelos que tengan en cuenta el número de parámetros, como AIC -\emph{Aikaike Information Criterion}- o BIC -\emph{Bayesian Information Criterion}).
Sin embargo en muchas ocasiones el objetivo final es la predicción, por lo que se suele utilizar la técnica de validación cruzada descrita en la Sección \ref{validacion-cruzada}.

\hypertarget{kriging}{%
\chapter{Predicción Kriging}\label{kriging}}

En este capítulo se comentan brevemente los métodos más conocidos de predicción espacial denominados métodos kriging\footnote{Podríamos definir los métodos kriging como algoritmos de predicción de mínimo error en media cuadrática que tienen en cuenta la estructura de segundo orden del proceso} (ver Sección \ref{geoestadistica} para un resumen del origen de esta terminología), centrándonos únicamente en el caso de predicción lineal puntual univariante (el caso multivariante se trata en el Capítulo \ref{multivar}).
Una revisión más completa de estos métodos se tiene por ejemplo en Cressie (1993, Capítulo 3 y secciones 5.1, 5.4 y 5.9.1) o Chilès y Delfiner (2012, capítulos 3, 4 y 6).

\hypertarget{introduccion}{%
\section{Introducción}\label{introduccion}}

Si denotamos por \(\mathbf{Z}=\left( Z(\mathbf{s}_{1}), \ldots, z(\mathbf{s}_{n} )\right)^\top\) valores observados del proceso, los distintos métodos kriging proporcionan un predictor \(p(\mathbf{Z},\mathbf{s}_{0})\) de \(Z(\mathbf{s}_{0})\) verificando que:

\begin{itemize}
\item
  es lineal:
  \[p(\mathbf{Z},\mathbf{s}_{0}) = \lambda_{0} + \sum\limits_{i=1}^{n}\lambda_{i} Z(\mathbf{s}_{i}),\]
\item
  es uniformemente insesgado, para cualquier \(\mu(\cdot)\):
  \[E(p(\mathbf{Z},\mathbf{s}_{0}))=\mu(\mathbf{s}_{0}),\]
\item
  y minimiza el error en media cuadrática de predicción (\emph{mean squared prediction error}, MSPE):
  \[E\left( \left( p(\mathbf{Z},\mathbf{s}_{0})-Z(\mathbf{s}_{0})\right)^2 \right).\]
\end{itemize}

En este capítulo, al hablar de predicción óptima, nos referiremos a que se verifican estas dos últimas condiciones.

Dependiendo de las suposiciones acerca de la función de tendencia \(\mu(\cdot)\), se distingue principalmente entre tres métodos kriging:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Kriging simple} (KS): se supone que la media es conocida (algunos autores suponen también que es constante o incluso cero).
  Además se asume que el covariograma existe y es conocido.
\item
  \emph{Kriging ordinario} (KO): se supone que la media es constante (i.e.~\(E(Z(\mathbf{s}))=\mu ,\forall \mathbf{s}\in D\)) y desconocida.
  Además se asume que por lo menos existe el variograma y es conocido.
\item
  \emph{Kriging universal} (KU; también denominado kriging con modelo de tendencia): se supone que la media es desconocida y no constante, pero
  que es una combinación lineal (desconocida) de \(p+1\) funciones (o variables explicativas) conocidas \(\left\{ X_{j} (\cdot):j=0, \ldots,p\right\}\):
  \[\mu(\mathbf{s})=\sum\limits_{j=0}^{p}X_{j} (\mathbf{s})\beta_{j}\]
  donde \(\boldsymbol{\beta}=(\beta_{0}, \ldots, \beta_{p} )^\top \in \mathbb{R}^{p+1}\) es un vector desconocido.
  Se asume también que por lo menos existe el variograma y es conocido\footnote{Siempre que una de las funciones explicativas sea idénticamente 1, e.g.~\(X_{0} (\cdot)\equiv 1\), en caso contrario las ecuaciones kriging sólo pueden expresarse en función del covariograma (Sección \ref{ku-covariograma}).}.
\end{enumerate}

Por simplicidad el kriging ordinario se tratará en este capítulo como un caso particular del kriging universal (aunque en la práctica se suele pensar en el KO como un método distinto al KU, principalmente por los inconvenientes que presenta este último; ver Sección \ref{trend-fit}).
Adicionalmente en la Sección \ref{kriging-residual} se tratará una extensión del KU denominada \emph{kriging residual} o \emph{kriging con tendencia externa}.

La suposición de que el variograma (o el covariograma) sólo dependa del salto es conveniente para facilitar el modelado de la dependencia espacial, pero para la predicción espacial no es necesaria esta consideración.
Por tanto en las expresiones de las ecuaciones de los distintos métodos kriging se utilizará la notación más general no estacionaria:
\[C(\mathbf{s}_{1}, \mathbf{s}_{2}) = Cov(Z(\mathbf{s}_{1}), Z(\mathbf{s}_{2})),\]
\[2\gamma(\mathbf{s}_{1}, \mathbf{s}_{2}) = Var(Z(\mathbf{s}_{1}) - Z(\mathbf{s}_{2})),\]
en lugar de suponer que son funciones de \(\mathbf{s}_{1}-\mathbf{s}_{2}\).

\hypertarget{ksimple}{%
\section{Kriging con media conocida: kriging simple}\label{ksimple}}

Supongamos que el proceso \(Z(\cdot)\) admite una descomposición de la forma:
\[Z(\mathbf{s})=\mu(\mathbf{s})+\varepsilon(\mathbf{s}),\]
siendo \(\mu(\cdot)\) la función de tendencia conocida y \(\varepsilon(\cdot)\) un proceso espacial de media cero con covariograma conocido \(C(\mathbf{s}_{1}, \mathbf{s}_{2}) =Cov(\varepsilon(\mathbf{s}_{1}), \varepsilon(\mathbf{s}_{2}))\) (no necesariamente estacionario, aunque en la práctica se suele suponer que \(\varepsilon(\cdot)\) es un proceso estacionario de segundo orden).
El predictor lineal óptimo minimiza el MSPE, que puede expresarse como:
\[\begin{aligned}
E\left[ \left( p(\mathbf{Z},\mathbf{s}_{0}) - Z(\mathbf{s}_{0})\right)^2 \right]  
& = Var\left( p(\mathbf{Z},\mathbf{s}_{0}) - Z(\mathbf{s}_{0})\right) 
+ \left[ E\left( p(\mathbf{Z},\mathbf{s}_{0}) - Z(\mathbf{s}_{0})\right) \right]^{2}  \\
& = Var\left( Z(\mathbf{s}_{0})-\sum\limits_{i=1}^{n}\lambda_{i}
Z(\mathbf{s}_{i}) \right) +\left( \mu(\mathbf{s}_{0}
)-\sum\limits_{i=1}^{n}\lambda_{i} \mu(\mathbf{s}_{i}) -\lambda_{0}
\right)^{2},
\end{aligned}\]
de donde se deduce que:
\[\lambda_{0} =\mu(\mathbf{s}_{0})-\sum\limits_{i=1}^{n}\lambda_{i} \mu(\mathbf{s}_{i}),\]
(por tanto el sesgo es nulo).
Entonces el predictor es de la forma:
\[p(\mathbf{Z}, \mathbf{s}_{0}) = \mu(\mathbf{s}_{0}) + \sum\limits_{i=1}^{n}\lambda_{i} (Z(\mathbf{s}_{i}) -\mu(\mathbf{s}_{i})),\]
(por tanto se puede pensar que se trata de la estimación lineal homogénea de un proceso de media cero) y el MSPE es igual a:
\[\begin{aligned}
E\left[ \left( p(\mathbf{Z},\mathbf{s}_{0})-Z(\mathbf{s}_{0})\right)^2 \right]  & = E\left[ \left( \sum\limits_{i=1}^{n}\lambda_{i} \varepsilon(\mathbf{s}_{i}) -\varepsilon(\mathbf{s}_{0})\right)^2 \right]  \\
& = \sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}\lambda_{i} \lambda_{j}
C(\mathbf{s}_{i},\mathbf{s}_{j} ) -2 \sum\limits_{i=1}^{n}\lambda_{i}
C(\mathbf{s}_{i},\mathbf{s}_{0}) +C(\mathbf{s}_{0},\mathbf{s}_{0}).\end{aligned}\]
Para minimizar esta función se igualan a cero las derivadas parciales respecto a los pesos, obteniéndose las ecuaciones del kriging simple:
\[\sum\limits_{j=1}^{n}\lambda_{j} C(\mathbf{s}_{i},\mathbf{s}_{j} )
- C(\mathbf{s}_{i},\mathbf{s}_{0})=0, \ \
i=1, \ldots, n,\]
que pueden expresarse en forma matricial como:
\[\boldsymbol{\Sigma}\boldsymbol{\lambda}=\mathbf{c},\]
siendo \(\boldsymbol{\lambda} = \left(\lambda_{1}, \ldots, \lambda_{n}\right)^\top\), \(\mathbf{c}=\left( C(\mathbf{s}_{1},\mathbf{s}_{0}), \ldots,C(\mathbf{s}_{n}, \mathbf{s}_{0})\right)^\top\) y \(\boldsymbol{\Sigma}\) la matriz \(n\times n\) de varianzas-covarianzas de los datos (i.e.~\(\boldsymbol{\Sigma}_{ij} =C(\mathbf{s}_{i},\mathbf{s}_{j} )\)).
Combinando las expresiones para \(\lambda_{0}\) y \(\boldsymbol{\lambda}\), se obtiene el predictor del kriging simple:
\[p_{KS}(\mathbf{Z}, \mathbf{s}_{0}) = \mu(\mathbf{s}_{0}) + \mathbf{c^\top }\boldsymbol{\Sigma}^{-1} (\mathbf{Z}-\boldsymbol{\mu}),\]
donde \(\boldsymbol{\mu}=\left( \mu(\mathbf{s}_{1}), \ldots,\mu(\mathbf{s}_{n} )\right)^\top\), y el correspondiente valor mínimo del MSPE, también denominado \emph{varianza kriging}:
\[\sigma_{KS}^{2} (\mathbf{s}_{0})=C(\mathbf{s}_{0},\mathbf{s}_{0}
)-\mathbf{c^\top }\boldsymbol{\Sigma}^{-1} \mathbf{c}.\]
Una de las principales utilidades de la varianza kriging es la construcción de intervalos de confianza (normalmente basados en la hipótesis de normalidad).

Para que exista una única solución del sistema la matriz \(\boldsymbol{\Sigma}\) debe ser no singular.
Una condición suficiente para que esto ocurra es que el covariograma \(C(\cdot ,\cdot)\) sea una función definida positiva (hay que tener cuidado con la anisotropía zonal, ver Sección \ref{anisotropia}) y las posiciones de los datos sean distintas.
En la práctica suele interesar la predicción en múltiples posiciones.
Teniendo en cuenta que la matriz del sistema no depende de la posición
de predicción\footnote{Además, tanto los pesos kriging como la varianza kriging no dependen de los datos observados, solamente de las posiciones y del covariograma (lo que por ejemplo, entre otras cosas, facilita el diseño de la configuración espacial de muestreo).}, el procedimiento recomendado sería calcular la factorización Cholesky de la matriz \(\boldsymbol{\Sigma}\) y posteriormente emplear esta factorización para resolver el sistema en cada posición de predicción \(\mathbf{s}_{0}\).

\hypertarget{kuniversal}{%
\section{Kriging con media desconocida: kriging universal y kriging residual}\label{kuniversal}}

Como ya se comentó, el kriging universal se basa en el siguiente modelo:
\[Z(\mathbf{s}) = \sum\limits_{j=0}^{p}X_{j}(\mathbf{s})\beta_{j} + \varepsilon(\mathbf{s}),\]
donde \(\boldsymbol{\beta}=(\beta_{0}, \ldots, \beta_{p})^\top \in \mathbb{R}^{p+1}\) es un vector desconocido, \(\left\{ X_{j}(\cdot):j=0, \ldots,p\right\}\) son funciones conocidas y \(\varepsilon(\cdot)\) un proceso espacial de media cero con variograma conocido \(2\gamma(\mathbf{s}_{1},\mathbf{s}_{2}) = Var(\varepsilon(\mathbf{s}_{1})-\varepsilon(\mathbf{s}_{2}))\) (aunque en la práctica se suele suponer estacionario).
Supondremos también que \(X_{0} (\cdot)\equiv 1\), de esta forma además en el caso particular de \(p=0\), se corresponderá con el modelo del kriging ordinario (ver Sección \ref{introduccion}) muy utilizado en la práctica.
Utilizando una notación matricial podemos escribir:
\[\mathbf{Z}=\mathbf{X}\boldsymbol{\beta}+\boldsymbol{\varepsilon},\]
siendo \(\boldsymbol{\varepsilon}=\left( \varepsilon(\mathbf{s}_{1}), \ldots, \varepsilon(\mathbf{s}_{n} )\right)^\top\) y \(\mathbf{X}\) una matriz \(n\times (p+1)\) con \(\mathbf{X}_{ij} =X_{j-1} (\mathbf{s}_{i})\), y:
\[Z(\mathbf{s}_{0})=\mathbf{x}_0^\top\boldsymbol{\beta}+\varepsilon(\mathbf{s}_{0}),\]
con \(\mathbf{x}_0=\left(X_{0}(\mathbf{s}_{0}), \ldots, X_{p}(\mathbf{s}_{0})\right)^\top\).

En este caso, como un predictor lineal verifica que:
\[E\left( \sum\limits_{i=1}^{n}\lambda_{i} Z(\mathbf{s}_{i}) +\lambda_{0} \right) = \boldsymbol{\lambda}^\top \mathbf{X}\boldsymbol{\beta}+\lambda_{0},\]\\
siendo \(\boldsymbol{\lambda}=\left( \lambda_{1}, \ldots,\lambda_{n} \right)^\top\), una condición necesaria y suficiente para que el predictor sea uniformemente insesgado, i.e.~\(E(p(\mathbf{Z},\mathbf{s}_{0}))=E(Z(\mathbf{s}_{0}))=\mathbf{x}_0^\top\boldsymbol{\beta}\), \(\forall \boldsymbol{\beta}\in \mathbb{R}^{p+1}\), es que \(\lambda_{0} =0\) y:
\begin{equation}
  \boldsymbol{\lambda}^\top \mathbf{X} = \mathbf{x}_0^\top.
  \label{eq:resticciones-ku}
\end{equation}
Además como \(X_{0} (\cdot)\equiv 1\), una de estas restricciones es:
\begin{equation}
  \sum\limits_{i=1}^{n}\lambda_{i} = 1,
  \label{eq:resticcion-ko}
\end{equation}
que es la única condición que deben verificar los pesos en el caso del kriging ordinario.

Por tanto el predictor del kriging universal será de la forma:
\[p(\mathbf{Z},\mathbf{s}_{0})=\sum\limits_{i=1}^{n}\lambda_{i} Z(\mathbf{s}_{i}),\]
verificando \eqref{eq:resticciones-ku} y tal que minimiza el MSPE.
Entonces se trata de minimizar:
\begin{equation}
  E\left( Z(\mathbf{s}_{0})-\sum\limits_{i=1}^{n}\lambda_{i} Z(\mathbf{s}_{i}) \right)^{2} - 2\sum\limits_{j=0}^{p}m_{j} \left( \sum\limits_{i=1}^{n} \lambda_{i} X_{j} (\mathbf{s}_{i})- X_{j}(\mathbf{s}_{0}) \right)
  \label{eq:objetivo-ku}
\end{equation}
respecto a \(\left\{ \lambda_{i} :i=1, \ldots,n\right\}\) y \(\left\{ m_{j} :j=0, \ldots,p\right\}\), multiplicadores de Lagrange que garantizan \eqref{eq:resticciones-ku}.
Teniendo en cuenta que el predictor es insesgado y que los pesos verifican \eqref{eq:resticcion-ko}, entonces:
\[\begin{aligned}
\left( \sum\limits_{i=1}^{n}\lambda_{i} Z(\mathbf{s}_{i}) - Z(\mathbf{s}_{0})\right)^2  
& = \left( \sum\limits_{i=1}^{n}\lambda_{i} \varepsilon(\mathbf{s}_{i}) - \varepsilon(\mathbf{s}_{0})\right)^2  \\
& = -\dfrac{1}{2} \sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}\lambda_{i}\lambda_{j} \left( \varepsilon(\mathbf{s}_{i}) - \varepsilon(\mathbf{s}_{j} )\right)^{2}  + \sum\limits_{i=1}^{n}\lambda_{i} \left( \varepsilon(\mathbf{s}_{i}) - \varepsilon(\mathbf{s}_{0}) \right)^{2},
\end{aligned}\]
y podemos escribir \eqref{eq:objetivo-ku} como:
\[-\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}\lambda_{i} \lambda_{j}
\gamma(\mathbf{s}_{i},\mathbf{s}_{j} ) +2 \sum\limits_{i=1}^{n}\lambda
_{i} \gamma(\mathbf{s}_{i},\mathbf{s}_{0}) -2\sum\limits_{j=0}^{p}m_{j}
\left( \sum\limits_{i=1}^{n}\lambda_{i} X_{j} (\mathbf{s}_{i})-X_{j}
(\mathbf{s}_{0}) \right)\] Derivando respecto a
\(\left\{ \lambda_{i} :i=1, \ldots,n\right\}\) y
\(\left\{ m_{j} :j=0, \ldots,p\right\}\) e igualando a cero se obtienen las
\(n+p+1\) ecuaciones del kriging universal que, expresadas en forma
matricial, resultan ser:
\[\boldsymbol{\Gamma}_{U} \boldsymbol{\lambda}_{U} =\boldsymbol{\gamma}_{U},\]
con:
\[\boldsymbol{\Gamma}_{U} = \left( \begin{array}{lc}
\boldsymbol{\Gamma} & \mathbf{X} \\
\mathbf{X^\top } & \mathbf{0}
\end{array} \right) ,\ 
\boldsymbol{\lambda}_{U} = \left( \begin{array}{c}
\boldsymbol{\lambda} \\
\mathbf{m}
\end{array} \right) ,\ 
\boldsymbol{\gamma}_{U} =\left( \begin{array}{c}
\boldsymbol{\gamma} \\
\mathbf{x}_0
\end{array} \right),\]
donde \(\boldsymbol{\gamma}=\left( \gamma(\mathbf{s}_{1},\mathbf{s}_{0}), \ldots, \gamma(\mathbf{s}_{n} ,\mathbf{s}_{0})\right)^\top\), \(\mathbf{m}=\left(m_{0}, \ldots,m_{p} \right)^\top\) y \(\boldsymbol{\Gamma}\) es una matriz \(n\times n\) con \(\boldsymbol{\Gamma}_{ij} = \gamma(\mathbf{s}_{i}, \mathbf{s}_{j})\).
Además el MSPE mínimo, o varianza kriging:
\[\sigma_{KU}^{2} (\mathbf{s}_{0})=2\sum\limits_{i=1}^{n}\lambda_{i} 
\gamma(\mathbf{s}_{0},\mathbf{s}_{i}
)-\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}\lambda_{i}  \lambda_{j}
\gamma(\mathbf{s}_{i},\mathbf{s}_{j} )\]
se puede obtener como:
\[\begin{aligned}
\sigma_{KU}^{2} (\mathbf{s}_{0})
& =\sum\limits_{i=1}^{n}\lambda_{i} \gamma(\mathbf{s}_{0},\mathbf{s}_{i})+\sum\limits_{j=0}^{p}m_{j} X_{j}
(\mathbf{s}_{0}) \\
& =\boldsymbol{\lambda}_{U}^\top \boldsymbol{\gamma}_{U}.
\end{aligned}\]
En el caso particular del kriging ordinario (\(p=0\)), la expresión de la varianza kriging resulta ser:
\[\sigma_{KO}^{2} (\mathbf{s}_{0})=\sum\limits_{i=1}^{n}\lambda_{i} 
\gamma(\mathbf{s}_{0},\mathbf{s}_{i})+m_{0}.\]

\hypertarget{ku-covariograma}{%
\subsection{Ecuaciones en función del covariograma}\label{ku-covariograma}}

Cuando existe el covariograma \(C(\mathbf{s}_{1},\mathbf{s}_{2}) = Cov(\varepsilon(\mathbf{s}_{1}), \varepsilon(\mathbf{s}_{2}))\) del proceso \(\varepsilon(\cdot)\) y es conocido (una suposición más fuerte), podemos expresar las ecuaciones del kriging universal (o del KO) en función de \(C(\cdot,\cdot)\).
Además, si ninguna de las funciones explicativas es idénticamente 1, las ecuaciones del kriging universal sólo pueden expresarse en función del covariograma.

El proceso sería análogo al caso anterior, el sistema del kriging universal equivalente es:
\[\boldsymbol{\Sigma}_{U} \boldsymbol{\lambda}_{U} = \mathbf{c}_{U},\]
donde:
\[\boldsymbol{\Sigma}_{U} =\left( 
\begin{array}{lc}
\boldsymbol{\Sigma} & \mathbf{X} \\
\mathbf{X^\top } & \mathbf{0}
\end{array}
\right) ,\ 
\boldsymbol{\lambda}_{U} =\left( \begin{array}{c}
\boldsymbol{\lambda} \\
\mathbf{m}
\end{array} \right) ,\ 
\mathbf{c}_{U} =\left( \begin{array}{c}
\mathbf{c} \\
\mathbf{x}_0
\end{array} \right),\]
y la varianza kriging es:
\[\begin{aligned}
\sigma_{KU}^{2} (\mathbf{s}_{0}) 
& = C(\mathbf{s}_{0},\mathbf{s}_{0}) - \sum\limits_{i=1}^{n}\lambda_{i}  C(\mathbf{s}_{0},\mathbf{s}_{i}) + \sum\limits_{j=0}^{p}m_{j} X_{j}(\mathbf{s}_{0}) \\
& = C(\mathbf{s}_{0}, \mathbf{s}_{0}) - \boldsymbol{\lambda}_{U} \mathbf{c}_{U}.
\end{aligned}\]

Muchos de los algoritmos utilizados para la solución de los sistema kriging están diseñados y optimizados para covariogramas (e.g.~Chilès y Delfiner, 2012, p.~170).
En el caso de variogramas no acotados se podrían emplear pseudo-covarianzas (ver Sección \ref{trend-fit}).

\hypertarget{kriging-residual}{%
\subsection{Kriging residual}\label{kriging-residual}}

Otra forma, que puede ser más interesante, de obtener las ecuaciones del KU es a partir del predictor del kriging simple.
Suponiendo que \(\boldsymbol{\beta}\) es conocido en el modelo del KU, el predictor del kriging simple es:
\[\begin{aligned}
p_{KS} (\mathbf{Z},\mathbf{s}_{0})
& = \mathbf{x}_0^{\top}\boldsymbol{\beta} + \mathbf{c}^{\top} \boldsymbol{\Sigma}^{-1} \left( \mathbf{Z} - \mathbf{X}\boldsymbol{\beta} \right) \\
& =\mathbf{c^\top }\boldsymbol{\Sigma}^{-1}
\mathbf{Z}+(\mathbf{x}_0-\mathbf{X^\top }\boldsymbol{\Sigma}^{-1} \mathbf{c})^\top \boldsymbol{\beta}.
\end{aligned}\]

Cuando \(\boldsymbol{\beta}\) no es conocido es lógico pensar en utilizar en su lugar su estimador lineal óptimo
\[\hat{\boldsymbol{\beta}}_{gls} =(\mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{X})^{-1} \mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{Z},\]
obteniéndose el predictor:
\[p^{\ast}(\mathbf{Z},\mathbf{s}_{0}) = \mathbf{c^\top }\boldsymbol{\Sigma}^{-1}\mathbf{Z} + (\mathbf{x}_0-\mathbf{X}^\top\boldsymbol{\Sigma}^{-1} \mathbf{c})^\top \hat{\boldsymbol{\beta}}_{gls}.\]
Puede verse (Goldberger, 1962) que este predictor, lineal e insesgado, es óptimo (en el sentido de que minimiza el MSPE sobre todos los predictores lineales e insesgados) y por tanto coincide con el predictor del kriging universal.
Además, teniendo en cuenta que el error \(\left( p_{KS} (\mathbf{Z},\mathbf{s}_{0})-Z(\mathbf{s}_{0})\right)\) tiene covarianza nula con cualquier combinación lineal de \(\mathbf{Z}\) (ver e.g.~Chilès y Delfiner, 2012, p.~161), esta relación también se extiende a la varianza kriging:
\[\sigma_{KU}^{2} (\mathbf{s}_{0})=\sigma_{KS}^{2} (\mathbf{s}_{0}
)+(\mathbf{x}_0-\mathbf{X^\top }\boldsymbol{\Sigma}^{-1} \mathbf{c})^\top \left(
\mathbf{X^\top }\boldsymbol{\Sigma}^{-1} \mathbf{X}\right)^{-1}
(\mathbf{x}_0-\mathbf{X^\top }\boldsymbol{\Sigma}^{-1} \mathbf{c}),\]
donde el segundo termino cuantifica la precisión en la estimación de la media.
Estas expresiones son conocidas como la relación de aditividad entre el KS y el KU.

Los resultados anteriores permiten pensar en la predicción lineal con media desconocida como un proceso de dos etapas: en la primera estimar la media desconocida, y en la segunda realizar la predicción lineal óptima con media supuestamente conocida.
En el caso de una tendencia lineal obtenemos el predictor de KU, mientras que en el caso general se obtiene el denominado predictor del \emph{kriging residual} (o \emph{kriging con tendencia externa}).

\hypertarget{kriging-gstat}{%
\section{\texorpdfstring{Kriging con el paquete \textbf{gstat}}{Kriging con el paquete gstat}}\label{kriging-gstat}}

Los métodos kriging (KS, KO y KU) están implementados en la función \texttt{krige()} del paquete \texttt{gstat}.
Normalmente la sintaxis empleada es:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{krige}\NormalTok{(formula, locations, newdata, model, ..., beta)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \texttt{formula}: fórmula que define la tendencia como un modelo lineal de la respuesta en función de las variables explicativas (para KO será de la forma \texttt{z\ \textasciitilde{}\ 1}).
\item
  \texttt{locations}: objeto \texttt{sf} o \texttt{Spatial*} que contiene las observaciones espaciales (incluyendo las variables explicativas).
\item
  \texttt{newdata}: objeto \texttt{sf}, \texttt{stars} o \texttt{Spatial*}, que contiene las posiciones de predicción (incluyendo las variables explicativas).
\item
  \texttt{model}: modelo de semivariograma (generado con la función \texttt{vgm()} o \texttt{fit.variogram()}).
\item
  \texttt{beta}: vector con los coeficientes de tendencia (incluida la intersección) si se supone conocida (se empleará para KS, en lugar de las estimaciones GLS empleadas en KO y KU).
\end{itemize}

Esta función, además de kriging univariante puntual con vecindario global, también implementa kriging por bloques, cokriging (predicción multivariante), predicción local y simulación condicional.
Para predicción (o simulación) local se pueden establecer los siguientes parámetros adicionales (ver Sección \ref{eleccion-vecindario}):

\begin{itemize}
\tightlist
\item
  \texttt{maxdist}: solo se utilizarán las observaciones a una distancia de la posición de predicción menor de este valor.
\item
  \texttt{nmax}, \texttt{nmin} (opcionales): número máximo y mínimo de observaciones más cercanas. Si el número de observaciones más cercanas dentro de la distancia \texttt{maxdist} es menor que \texttt{nmin}, se generará un valor faltante.
\item
  \texttt{omax} (opcional): número máximo de observaciones por octante (3D) o cuadrante (2D).
\end{itemize}

Los parámetros (opcionales) para simulación condicional (ver e.g.~Fernández-Casal y Cao, 2020, \href{https://rubenfcasal.github.io/simbook/simulaci\%C3\%B3n-condicional-e-incondicional.html}{Sección 7.5}) son:

\begin{itemize}
\tightlist
\item
  \texttt{nsim}: número de generaciones. Si se establece un valor distinto de cero, se emplea simulación condicional en lugar de predicción kriging.
\item
  \texttt{indicators}: valor lógico que determina el método de simulación. Por defecto (\texttt{FALSE}) emplea simulación condicional gaussiana, en caso contrario (\texttt{TRUE}) simula una variable indicadora.
\end{itemize}

Como ejemplo consideraremos los datos del acuífero Wolfcamp con el modelo del kriging universal ajustado en la Sección \ref{trend-fit} (en \href{s100.html}{s100} se tiene un ejemplo adicional empleando KO).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"datos/aquifer.RData"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(sf)}
\NormalTok{aquifer}\SpecialCharTok{$}\NormalTok{head }\OtherTok{\textless{}{-}}\NormalTok{ aquifer}\SpecialCharTok{$}\NormalTok{head}\SpecialCharTok{/}\DecValTok{100} \CommentTok{\# en cientos de pies...}
\NormalTok{aquifer\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_as\_sf}\NormalTok{(aquifer, }\AttributeTok{coords =} \FunctionTok{c}\NormalTok{(}\StringTok{"lon"}\NormalTok{, }\StringTok{"lat"}\NormalTok{), }\AttributeTok{remove =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{agr =} \StringTok{"constant"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(gstat)}
\NormalTok{vario }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(head }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lon }\SpecialCharTok{+}\NormalTok{ lat, aquifer\_sf, }\AttributeTok{cutoff =} \DecValTok{150}\NormalTok{)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(vario, }\FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{nugget =} \ConstantTok{NA}\NormalTok{), }\AttributeTok{fit.method =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Como se mostró en el Ejemplo \ref{exm:aquifer2}, para generar la rejilla de predicción podemos utilizar la función \texttt{st\_as\_stars()} del paquete \texttt{stars} considerando un buffer de radio 40 en torno a las posiciones espaciales:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{buffer }\OtherTok{\textless{}{-}}\NormalTok{ aquifer\_sf }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{st\_geometry}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{st\_buffer}\NormalTok{(}\DecValTok{40}\NormalTok{)}
\FunctionTok{library}\NormalTok{(stars)}
\NormalTok{grid }\OtherTok{\textless{}{-}}\NormalTok{ buffer }\SpecialCharTok{\%\textgreater{}\%}  \FunctionTok{st\_as\_stars}\NormalTok{(}\AttributeTok{nx =} \DecValTok{50}\NormalTok{, }\AttributeTok{ny =} \DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Como suponemos un modelo (no constante) para la tendencia, es necesario añadir los valores de las variables explicativas a la rejilla de predicción:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coord }\OtherTok{\textless{}{-}} \FunctionTok{st\_coordinates}\NormalTok{(grid)}
\NormalTok{grid}\SpecialCharTok{$}\NormalTok{lon }\OtherTok{\textless{}{-}}\NormalTok{ coord}\SpecialCharTok{$}\NormalTok{x}
\NormalTok{grid}\SpecialCharTok{$}\NormalTok{lat }\OtherTok{\textless{}{-}}\NormalTok{ coord}\SpecialCharTok{$}\NormalTok{y}
\end{Highlighting}
\end{Shaded}

Además, en este caso recortamos la rejilla para filtrar predicciones alejadas de las observaciones:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid }\OtherTok{\textless{}{-}}\NormalTok{ grid }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{st\_crop}\NormalTok{(buffer)}
\end{Highlighting}
\end{Shaded}

Obtenemos las predicciones mediante kriging universal (Sección \ref{kuniversal}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ head }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lon }\SpecialCharTok{+}\NormalTok{ lat, }\AttributeTok{locations =}\NormalTok{ aquifer\_sf, }\AttributeTok{model =}\NormalTok{ fit,}
              \AttributeTok{newdata =}\NormalTok{ grid)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [using universal kriging]
\end{verbatim}

Aparentemente hay un \textbf{\emph{ERROR en krige()}} y cambia las coordenadas del objeto \texttt{stars}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{st\_coordinates}\NormalTok{(grid))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        x                 y         
##  Min.   :-181.86   Min.   :-28.03  
##  1st Qu.:-100.73   1st Qu.: 33.25  
##  Median : -16.22   Median : 97.09  
##  Mean   : -16.22   Mean   : 97.09  
##  3rd Qu.:  68.29   3rd Qu.:160.93  
##  Max.   : 149.42   Max.   :222.21
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{st\_coordinates}\NormalTok{(pred))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        x                 y         
##  Min.   :-181.86   Min.   : 53.83  
##  1st Qu.:-100.73   1st Qu.:115.11  
##  Median : -16.22   Median :178.95  
##  Mean   : -16.22   Mean   :178.95  
##  3rd Qu.:  68.29   3rd Qu.:242.79  
##  Max.   : 149.42   Max.   :304.08
\end{verbatim}

Para evitar este problema podemos añadir los resultado al objeto \texttt{grid} y emplearlo en lugar de \texttt{pred}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid}\SpecialCharTok{$}\NormalTok{var1.pred }\OtherTok{\textless{}{-}}\NormalTok{ pred}\SpecialCharTok{$}\NormalTok{var1.pred}
\NormalTok{grid}\SpecialCharTok{$}\NormalTok{var1.var }\OtherTok{\textless{}{-}}\NormalTok{ pred}\SpecialCharTok{$}\NormalTok{var1.var}
\end{Highlighting}
\end{Shaded}

Podemos representar las predicciones y las varianzas kriging empleando \texttt{plot.stars()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(grid[}\StringTok{"var1.pred"}\NormalTok{], }\AttributeTok{breaks =} \StringTok{"equal"}\NormalTok{, }\AttributeTok{col =} \FunctionTok{sf.colors}\NormalTok{(}\DecValTok{64}\NormalTok{), }\AttributeTok{key.pos =} \DecValTok{4}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Predicciones kriging"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{04-kriging_files/figure-latex/unnamed-chunk-10-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(grid[}\StringTok{"var1.var"}\NormalTok{], }\AttributeTok{breaks =} \StringTok{"equal"}\NormalTok{, }\AttributeTok{col =} \FunctionTok{sf.colors}\NormalTok{(}\DecValTok{64}\NormalTok{), }\AttributeTok{key.pos =} \DecValTok{4}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Varianzas kriging"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{04-kriging_files/figure-latex/unnamed-chunk-10-2} \end{center}

También podríamos emplear el paquete \texttt{ggplot2}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(gridExtra)}
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{geom\_stars}\NormalTok{(}\AttributeTok{data =}\NormalTok{ grid, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ var1.pred, }\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
    \FunctionTok{scale\_fill\_viridis\_c}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{data =}\NormalTok{ aquifer\_sf) }\SpecialCharTok{+}
    \FunctionTok{coord\_sf}\NormalTok{(}\AttributeTok{lims\_method =} \StringTok{"geometry\_bbox"}\NormalTok{)}
\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{geom\_stars}\NormalTok{(}\AttributeTok{data =}\NormalTok{ grid, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ var1.var, }\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
    \FunctionTok{scale\_fill\_viridis\_c}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{data =}\NormalTok{ aquifer\_sf) }\SpecialCharTok{+}
    \FunctionTok{coord\_sf}\NormalTok{(}\AttributeTok{lims\_method =} \StringTok{"geometry\_bbox"}\NormalTok{)}
\FunctionTok{grid.arrange}\NormalTok{(p1, p2, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=1\linewidth]{04-kriging_files/figure-latex/unnamed-chunk-11-1} \end{center}

\hypertarget{consideraciones-kriging}{%
\section{Consideraciones acerca de los métodos kriging}\label{consideraciones-kriging}}

Los métodos kriging descritos anteriormente permiten obtener el mejor predictor lineal insesgado (BLUP, \emph{best linear unbiased predictor}).
Como es bien sabido, en el caso de normalidad el predictor óptimo (tomando como función de pérdidas el error cuadrático) es lineal y va a coincidir con los predictores kriging.
Pero si el proceso no es normal no tiene porque serlo, lo que ha motivado el desarrollo de métodos kriging no lineales (ver e.g.~Rivoirard, 1994) y del kriging trans-normal (ver Sección \ref{kriging-trans-normal}).

En estos métodos se supone que el variograma (covariograma) es conocido, sin embargo en la práctica en realidad el variograma es estimado (kriging estimado).
Puede verse (Yakowitz y Szidarovszky, 1985) que, bajo condiciones muy generales, el predictor kriging con variograma estimado converge al valor correcto si la densidad de datos tiende a infinito, incluso cuando la estimación del variograma no es muy buena.
Además, Stein (1988) probó que para una predicción asintóticamente (de relleno) eficiente lo que se necesita generalmente es capturar la conducta del variograma cerca del origen.
Por tanto, en cuanto a las predicciones, el factor más importante es que la aproximación al variograma
verdadero cerca del origen no sea muy mala.

Al contrario que en el caso del predictor, la estimación del
variograma afecta directamente a la varianza kriging y en general no es un estimador consistente del error en media cuadrática del predictor con variograma estimado.
En general, por ejemplo si el proceso es normal, es de esperar que subestime la verdadera varianza de predicción y por tanto debería incrementarse para que tenga en cuenta el efecto de la estimación del variograma.
Para más detalles sobre este problema, ver por ejemplo Cressie (1993, Sección 5.3), Christensen (1991, Sección 6.5), Stein (1999, Sección 6.8) o Chilès y Delfiner (2012, Sección 3.4.3).
En la Sección \ref{validacion-cruzada} se sugiere una posible corrección de la varianza kriging a partir del método de validación cruzada.

\hypertarget{kriging-interpolador}{%
\subsection{Kriging como interpolador}\label{kriging-interpolador}}

Las ecuaciones kriging tienen en cuenta varios aspectos del problema de interpolación\footnote{Para un tratamiento más detallado ver por ejemplo Chilès y Delfiner (2012), secciones 3.3.2 y 3.4.2.}:

\begin{itemize}
\tightlist
\item
  La configuración espacial de los datos, a través de las matrices \(\boldsymbol{\Sigma}\) (o \(\boldsymbol{\Gamma}\)), donde el covariograma (o el variograma) actúa como una ``distancia estadística'' entre las observaciones y de forma que se tiene en cuenta la información redundante presente en los datos.
\item
  La situación de la posición de predicción respecto a los datos, a través
  de \(\mathbf{c}\) (o \(\boldsymbol{\gamma}\)).
\item
  La presencia de una función determinística de tendencia.
\end{itemize}

Adicionalmente también tienen en cuenta propiedades estadísticas del proceso \(Z(\cdot)\), a través del variograma o el covariograma (que como se comentó en la Sección \ref{procesos-estacionarios}, entre otras cosas, determina las propiedades de continuidad del proceso).
Esta es la principal diferencia con otros métodos de interpolación que no tienen en cuenta la estructura de segundo orden del proceso.

Una propiedad importante de los predictores kriging es que son interpoladores exactos (suponiendo que no hay error de medida\footnote{En caso contrario interesaría predecir el proceso libre de ruido y habría que modificar ligeramente las ecuaciones kriging. Para más detalles, ver por ejemplo Cressie (1993, pp.~128-130) o Chilès y Delfiner (2012, Sección 3.7.1)}), en el sentido de que \(p(\mathbf{Z},\mathbf{s}_{0})=Z(\mathbf{s}_{0})\) cuando \(\mathbf{s}_{0}=\mathbf{s}_{i}\) (la solución de los sistemas es \(\lambda_{i} =1\) y \(\lambda_{j} =0\), \(\forall j\neq i\)), y naturalmente en ese caso la estimación de la varianza es 0.
Además, por lo general no son continuos en las posiciones de los datos, para que lo sean el efecto nugget debe ser nulo.

Otra característica de la interpolación kriging (y que no aparece en otros métodos como los que asignan pesos inversamente proporcionales a la distancia) es el denominado \emph{efecto pantalla}.
En general se observa (ver comentarios en la siguiente sección) que la influencia de un valor es menor si está oculto detrás de otro valor (e.g.~Journel y Huijbregts, 1978, p.~346).
Esto produce, por ejemplo en el caso del KO (incluso con un variograma isotrópico), que puntos situados a la misma distancia de la posición de predicción puedan tener distintos pesos y que los datos cercanos no apantallados reciban los mayores pesos, reduciéndose considerablemente (llegando a ser negativos) los pesos de los datos que quedan ocultos\footnote{En la literatura se muestran numerosos ejemplos sobre el comportamiento de los pesos kriging en distintos escenarios; una colección bastante completa se tiene en Wakernagel (1998, Capítulo 13).}.

La aparición de pesos negativos (o mayores que 1) en el KO como consecuencia del efecto pantalla, puede provocar (incluso suponiendo media constante) que el predictor kriging no esté necesariamente comprendido entre el valor mínimo y máximo de los datos.
Esto que en principio puede ser una propiedad muy interesante puede conducir a resultados extraños en ciertas ocasiones, como por ejemplo dar lugar a predicciones negativas en casos en los que la variable considerada es necesariamente positiva.
Para solucionar estos problemas se han propuesto numerosas alternativas, entre ellas la inclusión de restricciones adicionales sobre los pesos de forma que sean positivos (e.g.~Chilès y Delfiner, 2012, Sección 3.9.1) (lo cual puede dar lugar a un incremento considerable del MSPE de predicción) o sobre el predictor (ver p.e. Goovaerts, 1997, Sección 7.4.2).
Otra alternativa que puede ser preferible es la transformación del proceso \(Z(\cdot)\) a otra escala (de forma que se aproxime a la normalidad), realizar la predicción kriging del proceso transformado y volver a la escala original (pero asegurándose de que al hacer la transformación inversa el resultado tenga las propiedades de optimalidad deseadas); más detalles sobre este procedimiento se tienen en la Sección \ref{kriging-trans-normal}.

\hypertarget{efecto-variog-kriging}{%
\subsection{Efecto del variograma (covariograma) en el kriging}\label{efecto-variog-kriging}}

El variograma (o el covariograma) tiene un efecto determinante en la predicción espacial.
Como ejemplo, a continuación se incluyen algunas observaciones acerca de la influencia en el kriging de las tres principales características de un variograma estacionario (normalmente tratadas como parámetros) definidas en la Sección \ref{procesos-estacionarios}.

\textbf{Rango}

Supongamos que la posición de predicción \(\mathbf{s}_{0}\) está a una
distancia mayor que el rango de las posiciones de los datos \(\left\{ \mathbf{s}_{1}, \ldots,\mathbf{s}_{n} \right\}\) (i.e.~la posición de predicción está fuera de la zona de influencia de los datos), entonces \(\mathbf{c}=\mathbf{0}\) en las ecuaciones kriging, obteniéndose que:
\[p_{KS} (\mathbf{Z},\mathbf{s}_{0})=\mu(\mathbf{s}_{0}),\ \ p_{KU} (\mathbf{Z},\mathbf{s}_{0})=\mathbf{x}_0^\top\hat{\boldsymbol{\beta}}_{gls},\]
por lo tanto la predicción kriging se reduce a la media\footnote{Puede verse fácilmente que la ecuaciones del kriging universal con \(\mathbf{c}=\mathbf{0}\), son las obtenidas en el denominado método kriging de estimación de la tendencia (e.g.~Wackernagel, 1998, pp.~212-213; Chilès y Delfiner, 2012, Sección 3.4.5).} (estimada en el caso del KU).

\textbf{Nugget y umbral}

Resulta claro que las estimaciones obtenidas de la varianza de los predictores kriging dependen en gran medida de estos parámetros.
Es importante destacar que la escala del variograma (o del covariograma) no influye en las predicciones obtenidas, solamente en la varianza kriging.
Si se multiplica el variograma (o el covariograma) por una constante, las ecuaciones de los predictores kriging quedan invariantes y consecuentemente los pesos kriging no cambian, aunque la varianza kriging resulta multiplicada por esa constante.
Para estudiar su influencia en la predicción resulta de utilidad la proporción del efecto nugget en el umbral total \(c_{0} /\sigma^{2}\) (que como ya se comentó al final de la Sección \ref{procesos-estacionarios}, proporciona mucha información acerca del grado de dependencia espacial presente en los datos).
Por ejemplo, en el caso en que toda la variabilidad es efecto nugget (i.e.~el proceso \(Z(\cdot)\) es ruido blanco) entonces \(\boldsymbol{\Sigma}=\sigma^{2} \mathbf{I}_{n}\) y \(\mathbf{c}=\mathbf{0}\) (suponiendo que \(\mathbf{s}_{0}\neq \mathbf{s}_{i}, \forall i\)), y los predictores kriging se reducen a la estimación OLS de la tendencia:
\[p_{KU} (\mathbf{Z},\mathbf{s}_{0}) = \mathbf{x}_0^\top(\mathbf{X }^\top\mathbf{X})^{-1} \mathbf{X}^\top\mathbf{Z} = \mathbf{x }_0^\top\hat{\boldsymbol{\beta}}_{ols}.\]
En el caso del KO se obtiene la media muestral:
\[p_{KO} (\mathbf{Z},\mathbf{s}_{0})=\bar{Z} =\dfrac{1}{n}
\sum\nolimits_{i=1}^{n}Z(\mathbf{s}_{i}),\]
predictor bien conocido que asigna igual peso a todos los datos (por tanto el efecto pantalla es nulo).
Además, teniendo en cuenta los resultados de la Sección \ref{kriging-residual}, como \(\sigma_{KS}^{2} (\mathbf{s}_{0})=\sigma^{2}\) (caso más desfavorable), entonces:
\[\sigma_{KO}^{2} (\mathbf{s}_{0})=\sigma_{}^{2} +\dfrac{\sigma_{}^{2}
}{n},\]
es decir, la varianza del KO para el caso de procesos incorrelados es igual a la varianza del proceso más la varianza de la media muestral.
En general (al menos en KS y KO), se puede ver que al aumentar el porcentaje de efecto nugget en el umbral total disminuye el efecto pantalla y aumenta la varianza kriging (ver e.g.~Isaaks y Srivastava, 1989, pp.~305-306).
Hay que tener en cuenta que cuando la media no es constante (e.g.~KU), puede ocurrir incluso lo contrario del efecto pantalla, y observaciones alejadas pueden tener una gran influencia en la estimación (como es bien conocido en la estimación de la tendencia).

Teniendo en cuenta los comentarios anteriores, podemos afirmar que todos los parámetros (características) del variograma influyen en el kriging (aunque quizás el rango es el que tiene un menor efecto, ya que pequeñas variaciones en este parámetro producen resultados casi idénticos).
Estas observaciones no contradicen el resultado de que asintóticamente lo importante es capturar el comportamiento del variograma cerca del origen (Stein, 1988).
Es difícil determinar cuando los datos están suficientemente cerca como para tener sólo en cuenta el efecto nugget y la pendiente del variograma cerca del origen.

\hypertarget{eleccion-vecindario}{%
\subsection{Elección del vecindario}\label{eleccion-vecindario}}

Una práctica habitual en geoestadística, en lugar de considerar todas las observaciones disponibles, es incluir en las ecuaciones kriging únicamente los \(n(\mathbf{s}_{0})\) datos más ``próximos'' a la posición de predicción \(\mathbf{s}_{0}\) .
Esto puede justificarse por varias razones:

\begin{itemize}
\tightlist
\item
  Utilizar todos los datos puede dar lugar a un sistema de difícil solución debido a problemas numéricos. Por ejemplo, entre otros, el tiempo de computación (aproximadamente proporcional a \(n(\mathbf{s}_{0})^{3}\)) aumenta drásticamente al aumentar el numero de datos.
\item
  Las estimaciones del variograma son normalmente eficientes (o incluso el propio modelo geoestadístico válido) únicamente en pequeñas distancias.
\item
  El uso de vecindarios locales permite la relajación de las hipótesis del modelo (como la estacionariedad intrínseca en el caso del KO) o su simplificación (por ejemplo, en el caso del KU se puede suponer que locamente la estructura de la tendencia es más simple o incluso constante y utilizar en su lugar KO local).
\item
  En muchos casos los datos cercanos apantallan a los más alejados
  reduciendo su influencia (aunque no siempre de forma significativa; ver
  observaciones siguientes).
\end{itemize}

La selección ``optima'' de un vecindario local resulta no obstante un problema algo complejo. Por ejemplo, se acostumbra a pensar que el rango del variograma permite determinar por sí solo un criterio de vecindad, como incluir en las ecuaciones sólo los datos que estén dentro del rango de \(\mathbf{s}_{0}\), sin embargo esto puede no ser adecuado en muchos casos (aunque en la práctica el valor de este parámetro puede ser de gran utilidad como referencia inicial).
Teniendo en cuentas las observaciones realizadas en secciones anteriores, cuando aumenta la proporción de efecto nugget disminuye el efecto pantalla, el predictor kriging se reduce a la media y observaciones a más distancia que el rango de la posición de predicción contribuyen (a veces de forma significativa) a la estimación de la tendencia.
Hay que tener en cuenta que los pesos kriging dependen de la configuración espacial de todas las observaciones y observaciones fuera del rango pueden tener influencia en la predicción a través de su correlación con observaciones dentro del rango (esto es conocido en la literatura como efecto \emph{relay}, que podríamos traducir por efecto transmisión).

Se han propuesto algunos criterios para la selección de un vecindario óptimo (e.g.~Cressie, 1993, pp.~176-177), que son de utilidad cuando los datos están regularmente espaciados y el vecindario se puede fijar de antemano.
Por ejemplo, se pueden ir incluyendo observaciones en el vecindario hasta que no se produzca una disminución ``significativa'' en la estimación de la varianza kriging.

En la práctica, la densidad de datos y su configuración espacial en torno a las posiciones de predicción pueden ser muy irregulares.
Teniendo en cuenta esto se han desarrollado distintos algoritmos, algunos bastante sofisticados, para la selección de vecindarios (ver e.g.~Isaaks y Srivastava, 1989, Capítulo 14; Deutsch y Journel, 1992, secciones II.4 y IV.6).
Para la selección de los datos típicamente se fija un radio máximo de búsqueda y únicamente se consideran los datos dentro de una circunferencia (esfera) centrada en la posición de predicción.
En el caso de anisotropía (Sección 2.2.2), se considera una elipse (elipsoide) con el radio mayor orientado en la dirección de máxima variación.
Además suele interesar disponer de observaciones en todas direcciones, por lo que se divide la zona de búsqueda en sectores angulares (por ejemplo cuadrantes en el caso bidimensional o octantes en el caso tridimensional) y se selecciona un número mínimo de datos en todos o en la mayoría de esos sectores (esto evita también que clusters de datos tengan una excesiva influencia sobre predicciones en su entorno).
Si se sospecha de la presencia de una tendencia en los datos (KU), puede ser deseable la inclusión de observaciones más alejadas de la posición de predicción para poder estimarla de forma más eficiente.

Utilizando un algoritmo de búsqueda que tenga en cuenta todas o alguna de las consideraciones anteriores, típicamente se selecciona un número pequeño de datos como vecindario (e.g.~entre 10 y 20 observaciones) para cada posición de predicción.
Sin embargo esto puede causar que las superficies de predicción presenten discontinuidades (especialmente cuando los datos están regularmente espaciados y se utiliza búsqueda por octantes).
Una aproximación distinta sería la selección un único vecindario más grande (e.g.~de 20 a 40 observaciones) para pequeños conjuntos de posiciones de predicción, de esta forma en condiciones normales los vecindarios correspondientes a conjuntos de predicción próximos se solapan y es de esperar que no aparezcan discontinuidades.
Además el incremento en tiempo de computación debido a la inclusión de un número mayor de observaciones se compensa por el hecho de que sólo es necesario factorizar una vez la matriz sistema kriging para obtener las predicciones en el conjunto considerado\footnote{Por ejemplo, si se pretenden obtener predicciones en una rejilla bidimensional, el tiempo de computación considerando un vecindario distinto con 16 observaciones para cada nodo resulta similar a considerar un vecindario con 25 (o incluso más) observaciones para grupos de 4 nodos (dos por fila y columna).}.

Otra forma de proceder que puede ser de interés en la práctica, es usar el semivariograma como distancia en lugar de la tradicional distancia euclidea; de esta forma los datos son seleccionados preferentemente en la dirección de máxima continuidad (y se evita tener que considerar elipsoides en el caso de anisotropía).
Adicionalmente, cuando el número de datos es grande y sus posiciones irregulares, es recomendable utilizar alguna técnica de búsqueda, como el denominado \emph{kd-tree} (e.g.~ver paquete \href{https://CRAN.R-project.org/package=FNN}{\texttt{FNN}}), de forma que se puedan determinar eficientemente las observaciones más próximas a la posición de predicción \(\mathbf{s}_{0}\) (en lugar de comprobar todas las posiciones).

Independientemente del algoritmo de búsqueda que se vaya a utilizar, puede ser recomendable realizar antes algunas pruebas utilizando por ejemplo la técnica de validación cruzada descrita a continuación.

\hypertarget{validacion-cruzada}{%
\section{Validación cruzada del modelo ajustado}\label{validacion-cruzada}}

El método de validación cruzada es la técnica normalmente utilizada en geoestadística para diagnosticar si un modelo (de tendencia y variograma) describe adecuadamente la variabilidad espacial de los datos (ver e.g.~Cressie, 1993, Sección 2.6.4).
Si se asume que la tendencia es constante, permitiría verificar si el modelo de variograma describe adecuadamente la dependencia espacial de los datos.
Aunque también es utilizada para otros fines (ver e.g.~Isaaks y Srivastava, 1989, Capítulo 15), entre ellos: comparar distintas hipótesis sobre el modelo geoestadístico (tipo de modelo, vecindarios, etc.), detectar observaciones atípicas o incluso para la estimación de los parámetros del variograma.
La idea básica es eliminar una parte de los datos y utilizar el resto de los datos para predecir los datos eliminados, entonces el error de predicción puede deducirse del valor que se predice menos el observado; repitiendo esto sobre varios conjuntos de datos se tiene una idea sobre la variabilidad del error de predicción.
En su versión más simple, validación cruzada dejando uno fuera (\emph{Leave-one-out cross-validation}, LOOCV), para cada observación de la muestra se obtiene una predicción empleando el resto de observaciones (para más detalles, ver e.g.~Fernández-Casal et al., 2021, \href{https://rubenfcasal.github.io/aprendizaje_estadistico/const-eval.html\#cv}{Sección 1.3.3}).
En el caso de datos geoestadísticos no sólo interesa analizar las predicciones, en general son también de interés las estimaciones del error cuadrático de predicción (varianza kriging).

Supongamos que \(\hat{Z}_{-j}(\mathbf{s}_{j})\) es un predictor de \(Z(\mathbf{s}_{j})\) obtenido, utilizando alguno de los métodos de predicción espacial, a partir de \(\left\{ Z(\mathbf{s}_{i}):i\neq j\right\}\) y el variograma ajustado \(2\gamma(\cdot ,\hat{\boldsymbol{\theta}})\) (calculado utilizando todos los datos), y que \(\sigma_{-j}^2 (\mathbf{s}_{j})\) es el correspondiente error en media cuadrática de predicción.
Hay varias formas de medir la aproximación de las predicciones a los verdaderos valores, por ejemplo:

\begin{itemize}
\item
  La media de los errores tipificados (\emph{dimensionless mean error})
  \[\text{DME} =\dfrac{1}{n} \sum\limits_{j=1}^{n}\left( \hat{Z}_{-j}(\mathbf{s}_{j})-Z(\mathbf{s}_{j})\right) /\sigma_{-j}(\mathbf{s}_{j})\]
  debería ser próxima a cero. Este no es un criterio muy adecuado (sobre todo en el caso del KO) ya que los predictores kriging son insesgados independientemente del modelo de variograma utilizado (ver e.g.~Yakowitz y Szidarovski, 1985).
\item
  El error cuadrático medio adimensional (\emph{dimensionless mean squared error}):
  \[\text{DMSE} =\sqrt{\dfrac{1}{n} \sum\limits_{j=1}^{n}\left( \left( \hat{Z}_{-j}(\mathbf{s}_{j})-Z(\mathbf{s}_{j})\right) /\sigma_{-j}(\mathbf{s}_{j})\right)^2  }\]
  debería ser próximo a uno.
  El valor de este estadístico puede interpretarse como una medida de la concordancia entre las varianzas kriging y las varianzas observadas.
  Teniendo en cuenta que si reescalamos el variograma multiplicándolo por una constante, las predicciones con el variograma reescalado son idénticas y las varianzas kriging serán las mismas multiplicadas por esa constante.
  Podemos pensar en ``corregir'' las varianzas kriging obtenidas con un modelo de variograma estimado de forma que el DMSE sea igual a 1, multiplicándolas por \(\text{DMSE}^2\).
\item
  El error cuadrático medio (\emph{mean squared error}):
  \[\text{MSE} =\dfrac{1}{n} \sum\limits_{j=1}^{n}\left( \hat{Z}_{-j}(\mathbf{s}_{j})-Z(\mathbf{s}_{j})\right)^2\] debería ser pequeño.
  El principal problema de este estadístico es que asigna igual peso a todos los datos y no tiene en cuenta las posiciones espaciales.
  Por lo general los errores son mayores en los puntos más alejados del resto de los datos (observaciones exteriores) y pueden tener un efecto dominante en la media global.
  Se podría pensar en calcular una media ponderada con pesos inversamente proporcionales a la varianza kriging o a alguna medida de la distancia de una posición al resto de los datos.
\item
  Diversos criterios gráficos pueden ser también de interés como herramientas de diagnóstico, como un gráfico de tallo-hojas de los residuos tipificados o gráficos de normalidad.
\end{itemize}

Después de la validación cruzada del variograma, si esta resultó ser satisfactoria, se puede confiar en que la predicción basada en el modelo ajustado es aproximadamente óptima y que las estimaciones del error en media cuadrática de predicción son bastante buenas (i.e.~el modelo ajustado no es muy incorrecto).

Uno de los principales problemas de esta técnica es el elevado coste computacional (Cressie, 1993, p.~104), sin embargo, se han desarrollado métodos(normalmente ignorados) que permiten realizar la validación cruzada de un modelo de variograma de forma rápida y sencilla (ver Fernández-Casal, 2003c, Sección 4.4).
Alternativamente se podría emplear validación cruzada en \emph{k} grupos (\emph{k-fold cross-validation}), considerando típicamente 10 o 5 grupos\footnote{LOOCV sería un caso particular considerando un número de grupos igual al número de observaciones. La partición en k-fold CV se suele realizar al azar. Hay que tener en cuenta la aleatoriedad al emplear k-fold CV, algo que no ocurre con LOOCV.}.

La validación cruzada en \texttt{gstat} está implementada en la función \texttt{krige.cv()}.
La sintaxis de esta función es casi idéntica a la de la función \texttt{krige()} (Sección \ref{kriging-gstat}, salvo que incluye un argumento \texttt{nfold} en lugar de \texttt{newdata}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{krige.cv}\NormalTok{(formula, locations, model, }\AttributeTok{nfold =} \FunctionTok{nrow}\NormalTok{(data), ...)}
\end{Highlighting}
\end{Shaded}

El resultado (un \texttt{data.frame} o un objeto del mismo tipo que \texttt{locations}), además de las predicciones y varianzas kriging de validación cruzada (en las posiciones de observación), contiene los componentes \texttt{observed} (valor observado), \texttt{residual} (residuos), \texttt{zscore} (residuos divididos por el error estándar kriging) y \texttt{fold} (grupo de validación cruzada).

Como ejemplo continuaremos con los datos del acuífero Wolfcamp (en \href{s100.html}{s100} se tiene un ejemplo adicional empleando KO).
Como ya se comentó, la función \texttt{krige.cv()} emplea LOOCV por defecto y puede requerir de mucho tiempo de computación (no implementa eficientemente esta técnica):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{system.time}\NormalTok{(cv }\OtherTok{\textless{}{-}} \FunctionTok{krige.cv}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ head }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lon }\SpecialCharTok{+}\NormalTok{ lat, }\AttributeTok{locations =}\NormalTok{ aquifer\_sf,}
                           \AttributeTok{model =}\NormalTok{ fit))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    user  system elapsed 
##    0.79    0.09    0.90
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(cv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Classes 'sf' and 'data.frame':   85 obs. of  7 variables:
##  $ var1.pred: num  15 23.5 22.9 24.6 17 ...
##  $ var1.var : num  3.08 2.85 2.32 2.81 2.05 ...
##  $ observed : num  14.6 25.5 21.6 24.6 17.6 ...
##  $ residual : num  -0.3357 1.9962 -1.3101 -0.0792 0.5478 ...
##  $ zscore   : num  -0.1914 1.1821 -0.8608 -0.0472 0.3829 ...
##  $ fold     : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ geometry :sfc_POINT of length 85; first list element:  'XY' num  42.8 127.6
##  - attr(*, "sf_column")= chr "geometry"
##  - attr(*, "agr")= Factor w/ 3 levels "constant","aggregate",..: NA NA NA NA NA NA
##   ..- attr(*, "names")= chr [1:6] "var1.pred" "var1.var" "observed" "residual" ...
\end{verbatim}

Si el número de observaciones es grande puede ser preferible emplear k-fold CV (y como la partición en grupos es aleatoria se recomendaría fijar previamente la semilla de aleatorización):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\FunctionTok{system.time}\NormalTok{(cv }\OtherTok{\textless{}{-}} \FunctionTok{krige.cv}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ head }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lon }\SpecialCharTok{+}\NormalTok{ lat, }\AttributeTok{locations =}\NormalTok{ aquifer\_sf,}
                           \AttributeTok{model =}\NormalTok{ fit, }\AttributeTok{nfold =} \DecValTok{10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    user  system elapsed 
##    0.11    0.00    0.11
\end{verbatim}

Como ya se comentó, podemos considerar distintos estadísticos, por ejemplo los implementados en la siguiente función (los tres últimos tienen en cuenta la estimación de la varianza kriging):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary\_cv }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cv.data, }\AttributeTok{na.rm =} \ConstantTok{FALSE}\NormalTok{,}
                       \AttributeTok{tol =} \FunctionTok{sqrt}\NormalTok{(.Machine}\SpecialCharTok{$}\NormalTok{double.eps)) \{}
\NormalTok{  err }\OtherTok{\textless{}{-}}\NormalTok{ cv.data}\SpecialCharTok{$}\NormalTok{residual      }\CommentTok{\# Errores}
\NormalTok{  obs }\OtherTok{\textless{}{-}}\NormalTok{ cv.data}\SpecialCharTok{$}\NormalTok{observed}
\NormalTok{  z }\OtherTok{\textless{}{-}}\NormalTok{ cv.data}\SpecialCharTok{$}\NormalTok{zscore}
\NormalTok{  w }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{/}\FunctionTok{pmax}\NormalTok{(cv.data}\SpecialCharTok{$}\NormalTok{var1.var, tol) }\CommentTok{\# Ponderación según varianza kriging}
  \ControlFlowTok{if}\NormalTok{(na.rm) \{}
\NormalTok{    is.a }\OtherTok{\textless{}{-}} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(err)}
\NormalTok{    err }\OtherTok{\textless{}{-}}\NormalTok{ err[is.a]}
\NormalTok{    obs }\OtherTok{\textless{}{-}}\NormalTok{ obs[is.a]}
\NormalTok{    z }\OtherTok{\textless{}{-}}\NormalTok{ z[is.a]}
\NormalTok{    w }\OtherTok{\textless{}{-}}\NormalTok{ w[is.a]}
\NormalTok{  \}}
\NormalTok{  perr }\OtherTok{\textless{}{-}} \DecValTok{100}\SpecialCharTok{*}\NormalTok{err}\SpecialCharTok{/}\FunctionTok{pmax}\NormalTok{(obs, tol)  }\CommentTok{\# Errores porcentuales}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
    \CommentTok{\# Medidas de error tradicionales}
    \AttributeTok{me =} \FunctionTok{mean}\NormalTok{(err),           }\CommentTok{\# Error medio}
    \AttributeTok{rmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)), }\CommentTok{\# Raíz del error cuadrático medio}
    \AttributeTok{mae =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(err)),     }\CommentTok{\# Error absoluto medio}
    \AttributeTok{mpe =} \FunctionTok{mean}\NormalTok{(perr),         }\CommentTok{\# Error porcentual medio}
    \AttributeTok{mape =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(perr)),   }\CommentTok{\# Error porcentual absoluto medio}
    \AttributeTok{r.squared =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{((obs }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(obs))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{), }\CommentTok{\# Pseudo R{-}cuadrado}
    \CommentTok{\# Medidas de error que tienen en cuenta la varianza kriging}
    \AttributeTok{dme =} \FunctionTok{mean}\NormalTok{(z),            }\CommentTok{\# Error estandarizado medio}
    \AttributeTok{dmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(z}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)),    }\CommentTok{\# Error cuadrático medio adimensional}
    \AttributeTok{rwmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{weighted.mean}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, w)) }\CommentTok{\# Raíz del ECM ponderado}
\NormalTok{  ))}
\NormalTok{\}}

\FunctionTok{summary\_cv}\NormalTok{(cv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           me         rmse          mae          mpe         mape    r.squared 
##  0.058039856  1.788446500  1.407874022 -0.615720059  7.852363328  0.913398424 
##          dme         dmse        rwmse 
##  0.001337332  1.118978878  1.665958815
\end{verbatim}

Estas medidas podrían emplearse para seleccionar modelos (de tendencia y variograma), y también para ayudar a establecer los parámetros del vecindario para kriging local.

Para detectar datos atípicos, o problemas con el modelo, podemos generar distintos gráficos.
Por ejemplo, gráficos de dispersión de valores observados o residuos estándarizados frente a predicciones:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{old\_par }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(observed }\SpecialCharTok{\textasciitilde{}}\NormalTok{ var1.pred, }\AttributeTok{data =}\NormalTok{ cv, }\AttributeTok{xlab =} \StringTok{"Predicción"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Observado"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{a =} \DecValTok{0}\NormalTok{, }\AttributeTok{b =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(zscore }\SpecialCharTok{\textasciitilde{}}\NormalTok{ var1.pred, }\AttributeTok{data =}\NormalTok{ cv, }\AttributeTok{xlab =} \StringTok{"Predicción"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Residuo estandarizado"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{), }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=1\linewidth]{04-kriging_files/figure-latex/unnamed-chunk-16-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(old\_par)}
\end{Highlighting}
\end{Shaded}

Gráficos con la distribución espacial de los residuos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(cv[}\StringTok{"residual"}\NormalTok{], }\AttributeTok{pch =} \DecValTok{20}\NormalTok{, }\AttributeTok{cex =} \DecValTok{2}\NormalTok{, }\AttributeTok{breaks =} \StringTok{"quantile"}\NormalTok{, }\AttributeTok{nbreaks =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{04-kriging_files/figure-latex/unnamed-chunk-17-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(cv[}\StringTok{"zscore"}\NormalTok{], }\AttributeTok{pch =} \DecValTok{20}\NormalTok{, }\AttributeTok{cex =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{04-kriging_files/figure-latex/unnamed-chunk-17-2} \end{center}

Además de los gráficos estándar para analizar la distribución de los residuos estándarizados o detectar atípicos:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Histograma}
\NormalTok{old\_par }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\FunctionTok{hist}\NormalTok{(cv}\SpecialCharTok{$}\NormalTok{zscore, }\AttributeTok{freq =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{density}\NormalTok{(cv}\SpecialCharTok{$}\NormalTok{zscore), }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{)}
\CommentTok{\# Gráfico de normalidad}
\FunctionTok{qqnorm}\NormalTok{(cv}\SpecialCharTok{$}\NormalTok{zscore)}
\FunctionTok{qqline}\NormalTok{(cv}\SpecialCharTok{$}\NormalTok{zscore, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{)}
\CommentTok{\# Boxplot}
\NormalTok{car}\SpecialCharTok{::}\FunctionTok{Boxplot}\NormalTok{(cv}\SpecialCharTok{$}\NormalTok{zscore, }\AttributeTok{ylab =} \StringTok{"Residuos estandarizados"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=1\linewidth]{04-kriging_files/figure-latex/unnamed-chunk-18-1} \end{center}

\begin{verbatim}
## [1] 78
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(old\_par)}
\end{Highlighting}
\end{Shaded}

\hypertarget{otros-muxe9todos-kriging}{%
\section{Otros métodos kriging}\label{otros-muxe9todos-kriging}}

\hypertarget{block-kriging}{%
\subsection{Block kriging}\label{block-kriging}}

Aunque en los métodos kriging descritos anteriormente se asumía que el soporte era puntual, serían igualmente válidos para el caso de distintos soportes.
Simplemente habría que sustituir las semivarianzas (o covarianzas) puntuales por las del proceso agregado \(Var\left( Z(B_1)-Z(B_2)\right)\) (ver Sección \ref{procesos-agregados}).

La función \texttt{krige()} del paquete \texttt{gtsat} empleará este método de forma automática cuando la geometría del argumento \texttt{newdata} sean polígonos (incluyendo datos raster).

\hypertarget{kriging-trans-normal}{%
\subsection{Kriging trans-normal}\label{kriging-trans-normal}}

Como se comentó en la Sección \ref{consideraciones-kriging}, en el caso de normalidad el predictor óptimo \(E\left( \left. Z(\mathbf{s}_{0})\right| \mathbf{Z}\right)\) de \(Z(\mathbf{s}_{0})\) es lineal y coincide con los predictores kriging.
Pero si el proceso no es normal este predictor puede ser altamente no lineal, en esos casos la transformación del proceso \(Z(\cdot)\) a otra escala puede producir que se aproxime a la normalidad.
De esta forma se puede pensar en realizar la predicción lineal en la escala transformada (donde también puede ser más eficiente realizar el modelado) y posteriormente hacer la transformación inversa (pero asegurándose de que el resultado tenga las propiedades de optimalidad deseadas).
En esta Sección simplemente se muestran algunos resultados sobre este método, para un tratamiento más detallado ver por ejemplo Cressie (1993, Sección 3.2.2) o Chilès y Delfiner (2012, Sección 3.4.10).

Una de las transformaciones más utilizadas en geoestadística es la transformación logarítmica, asumiendo que el proceso \(Z(\cdot)\) sigue una distribución lognormal.
Un proceso aleatorio lognormal es un proceso \(\left\{ Z(\mathbf{s}):\mathbf{s}\in D\right\}\) (que toma valores positivos) tal que:
\[Y(\mathbf{s})=\log \left( Z(\mathbf{s})\right) ;\ \ \mathbf{s}\in D,\]
es un proceso normal.

El \emph{kriging simple lognormal} (KSL) se basa en la suposición adicional de que el proceso \(Y(\cdot)\) verifica las hipótesis del kriging simple (media y covariograma conocidos).
En ese caso, utilizando el método del KS, a partir de \(\mathbf{Y}=(Y(\mathbf{s}_{1}), \ldots,Y(\mathbf{s}_{n} ))^\top\) podemos obtener el predictor \(p_{KS} (\mathbf{Y},\mathbf{s}_{0})\) de \(Y(\mathbf{s}_{0})\) y la correspondiente varianza kriging \(\sigma_{KS}^{2} (\mathbf{s}_{0})\).
Si transformamos de nuevo este valor a la escala de \(Z(\cdot)\), obtenemos \(\exp (p_{KS} (\mathbf{Y},\mathbf{s}_{0}))\) que no es un predictor insesgado de \(Z(\mathbf{s}_{0})\) (es un predictor insesgado en mediana).
El predictor óptimo de \(Z(\mathbf{s}_{0})\) resulta ser:
\[p_{KSL} (\mathbf{Z},\mathbf{s}_{0}) = \exp \left( p_{KS}(\mathbf{Y},\mathbf{s}_{0}) + \frac{1}{2} \sigma_{KS}^{2}(\mathbf{s}_{0}) \right),\]
y la correspondiente varianza kriging:
\[\sigma_{KSL}^{2} (\mathbf{s}_{0})=p_{KS} (\mathbf{Y},\mathbf{s}_{0}
)^{2} \left( \exp (\sigma_{KS}^{2} (\mathbf{s}_{0}))-1\right).\]

En el caso de media no conocida, i.e.~suponiendo que el proceso \(Y(\cdot)\) verifica las hipótesis del KU (kriging universal lognormal, KUL), se complica aún más el problema.
No basta con sustituir la media teórica en por su predictor óptimo ya que se obtendría un predictor sesgado.
Si se hace una corrección para obtener un predictor insesgado de \(Z(\mathbf{s}_{0})\), el resultado sería:
\[p_{KUL} (\mathbf{Z},\mathbf{s}_{0}) = \exp \left( p_{KU}(\mathbf{Y},\mathbf{s}_{0}) + \frac{1}{2} \sigma_{KU}^{2}(\mathbf{s}_{0}) - \mathbf{m^\top }\mathbf{x}_0\right),\]
utilizando la notación de la Sección \ref{kuniversal} (y suponiendo también que una de las funciones explicativas es idénticamente 1).
Hay que destacar que el predictor no es un predictor óptimo en el sentido de que minimice el MSPE (este predictor minimiza \(E\left( \log p(\mathbf{Z},\mathbf{s}_{0})-Y(\mathbf{s}_{0})\right)^2\), sujeto a las correspondientes restricciones de insesgadez y forma del predictor).

La varianza kriging tiene una expresión considerablemente más complicada que en el caso de media conocida (ver Cressie, 1993, p.~136; para el caso de media constante).
Sin embargo, si el objetivo es la construcción de intervalos de confianza, se pueden transformar directamente de la escala \(Y(\cdot)\).
Por ejemplo:
\[\left( \exp \left( p_{K} (\mathbf{Y},\mathbf{s}_{0}) - 1.96\sigma_{K}^{2}(\mathbf{s}_{0}) \right), \exp \left( p_{K} (\mathbf{Y},\mathbf{s}_{0}) + 1.96\sigma_{K}^{2} (\mathbf{s}_{0})\right) \right),\]
es un intervalo de confianza al 95\% para \(Z(\mathbf{s}_{0})\).

La aproximación anterior puede generalizarse para una transformación
cualquiera:
\[Z(\mathbf{s})=\phi \left( Y(\mathbf{s})\right) ;\;\;\mathbf{s}\in D,\]
siendo \(Y(\cdot)\) un proceso normal y \(\phi (\cdot)\) una función medible dos veces diferenciable.
En general no se dispone de expresiones exactas como en el caso del kriging lognormal, aunque a partir de un predictor kriging \(p_{K} (\mathbf{Y},\mathbf{s}_{0})\) de \(Y(\mathbf{s}_{0})\) se pueden obtener un predictor aproximadamente insesgado de \(Z(\mathbf{s}_{0})\) teniendo en cuenta que:
\[\begin{aligned}
\phi (Y(\mathbf{s}_{0})) & \simeq \phi (p_{K}(\mathbf{Y},\mathbf{s}_{0}))+(Y(\mathbf{s}_{0})-p_{K}(\mathbf{Y},\mathbf{s}_{0}))\phi^\prime (p_{K}(\mathbf{Y},\mathbf{s}_{0})) \\
 & +\frac{1}{2} (Y(\mathbf{s}_{0})-p_{K}(\mathbf{Y},\mathbf{s}_{0}))^{2} \phi^{\prime\prime} (p_{K}(\mathbf{Y},\mathbf{s}_{0})),
\end{aligned}\]
si el error kriging \(p_{K} (\mathbf{Y},\mathbf{s}_{0})-Y(\mathbf{s}_{0})\) es pequeño.
A partir de esto, si \(\sigma_{K}^{2} (\mathbf{s}_{0})\) es la correspondiente varianza kriging, se obtiene el predictor (aproximadamente insesgado) del \emph{kriging trans-normal} (KT):
\[p_{KT} (\mathbf{Z},\mathbf{s}_{0}) = \phi \left( p_{K}(\mathbf{Y},\mathbf{s}_{0})\right) + \frac{1}{2} \sigma_{K}^{2}(\mathbf{s}_{0}) \phi^{\prime\prime} \left( p_{K}(\mathbf{Y},\mathbf{s}_{0}) \right),\]
que en el caso del KS se aproxima al predictor óptimo \(E\left( \left. Z(\mathbf{s}_{0})\right| \mathbf{Z}\right)\) de \(Z(\mathbf{s}_{0})\).
Como aproximación de la varianza kriging de este predictor se puede utilizar:
\[\sigma_{KT}^{2}(\mathbf{s}_{0}) = \sigma_{K}^{2}(\mathbf{s}_{0}) \phi^{\prime} (p_{K}(\mathbf{Y},\mathbf{s}_{0})).\]

\hypertarget{multivar}{%
\chapter{Procesos espaciales multivariantes}\label{multivar}}

\textbf{\emph{En preparación\ldots{}}}

Si \(\left\{ Z_{j}(\mathbf{s}):j=1, \ldots, k;\mathbf{s}\in D\right\}\)
son \(k\) procesos espaciales univariantes (y que se suponen en principio interdependientes), el vector
\[\mathbf{Z}(\mathbf{s})=(Z_{1}(\mathbf{s}), \ldots, Z_{k}(\mathbf{s}))^\top\]
lo denominaremos proceso espacial multivariante (también se denomina proceso espacial vectorial, campo vectorial espacial o vector regionalizado).

\hypertarget{esp-temp}{%
\chapter{Procesos espacio-temporales}\label{esp-temp}}

\textbf{\emph{En preparación\ldots{}}}

Como ya se comentó en el Capítulo 1 se puede pensar en un procesos espacio-temporal como un caso particular de un proceso espacial en el que una de las componentes es el tiempo.
Sin embargo, para enfatizar el carácter temporal, se utilizará una notación de la forma:
\[\left\{ Z(\mathbf{s},t):(\mathbf{s},t)\in D\times T\right\}\]
donde \(D\times T\subset \mathbb{R} ^{d} \times \mathbb{R}^{+,0}\), para
referirse a un proceso espacio-temporal.

En algunos casos los procesos espacio-temporales son modelados también
como procesos espaciales multivariantes (e.g.~Egbert y Lettenmaier,
1986; Kyriakidis y Journel, 1999).

Por ejemplo, se puede considerar una representación de la forma:

\[Z(\mathbf{s},t)=\mathbf{Z}(\mathbf{s})=(Z_{1} (\mathbf{s}), \ldots,Z_{k} (
\mathbf{s}))^\top,\]
donde
\[Z_{i} (\mathbf{s})=Z(\mathbf{s},t_{i} ),\  i=1, \ldots,k.\]
O también:
\[Z(\mathbf{s},t) = \mathbf{Z}(t) =  \left(Z_{1}(t), \ldots, Z_{n}(t) \right)^\top,\]
siendo
\[Z_{j} (t)=Z(\mathbf{s}_{j} ,t),\  j=1, \ldots,n.\]
Uno de los principales problemas al utilizar estas aproximaciones es que, utilizando los modelos geoestadísticos tradicionales, no es posible la
predicción en todas las posiciones espacio-temporales sin algún tipo de
modelado adicional. Por ejemplo, utilizando la representación y los métodos geoestadísticos de predicción espacial multivariante, se pueden obtener en principio superficies de predicción solamente en los k instantes temporales \(t_{i} ,\  i=1, \ldots, k\),
y no es posible la interpolación temporal sin modelado adicional (ver Sección 5.3.5).

\hypertarget{appendix-apendices}{%
\appendix}


\hypertarget{intro-sp}{%
\chapter{\texorpdfstring{Introducción al paquete \textbf{sp}}{Introducción al paquete sp}}\label{intro-sp}}

El paquete \href{https://CRAN.R-project.org/package=sp}{\texttt{sp}} {[}Classes and methods for spatial data; \protect\hyperlink{ref-Pebesma2005}{E. J. Pebesma y Bivand} (\protect\hyperlink{ref-Pebesma2005}{2005}){]} implementa objetos y métodos para datos espaciales.
En este apéndice se incluyen algunos ejemplos que pueden servir como introducción a las herramientas implementadas en este paquete.
Para más detalles ver \protect\hyperlink{ref-Bivand2013}{Bivand et~al.} (\protect\hyperlink{ref-Bivand2013}{2013}), consular las viñetas \href{https://cran.r-project.org/web/packages/sp/vignettes/intro_sp.pdf}{sp: classes and methods for spatial data} y \href{https://edzer.github.io/sp}{Plotting maps with sp} o la \href{https://www.maths.lancs.ac.uk/~rowlings/Teaching/UseR2012/cheatsheet.html}{chuleta}.

\hypertarget{tipos-de-objetos}{%
\section{Tipos de objetos}\label{tipos-de-objetos}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Librería sp:classes and methods for spatial data}
\FunctionTok{library}\NormalTok{(sp) }\CommentTok{\# install.packages(\textquotesingle{}sp\textquotesingle{})}

\CommentTok{\# Tipos de objetos}
\FunctionTok{getClass}\NormalTok{(}\StringTok{"Spatial"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Class "Spatial" [package "sp"]
## 
## Slots:
##                               
## Name:         bbox proj4string
## Class:      matrix         CRS
## 
## Known Subclasses: 
## Class "SpatialPoints", directly
## Class "SpatialMultiPoints", directly
## Class "SpatialGrid", directly
## Class "SpatialLines", directly
## Class "SpatialPolygons", directly
## Class "SpatialPointsDataFrame", by class "SpatialPoints", distance 2
## Class "SpatialPixels", by class "SpatialPoints", distance 2
## Class "SpatialMultiPointsDataFrame", by class "SpatialMultiPoints", distance 2
## Class "SpatialGridDataFrame", by class "SpatialGrid", distance 2
## Class "SpatialLinesDataFrame", by class "SpatialLines", distance 2
## Class "SpatialPixelsDataFrame", by class "SpatialPoints", distance 3
## Class "SpatialPolygonsDataFrame", by class "SpatialPolygons", distance 2
\end{verbatim}

\begin{itemize}
\item
  Clases del tipo S4 (definicion formal con componentes
  denominadas slots)
\item
  Tipo base: \texttt{Spatial}

  \begin{itemize}
  \item
    \texttt{bbox} (bounding box): matriz con los límites mínimo y máximo de
    las coordenadas (principalmente para representación gráfica;
    normalmente se genera automáticamente).
  \item
    \texttt{proj4string}: cadena de texto que define el sistema de
    coordenadas de referencia (realmente objeto tipo \emph{CRS,}
    coordinate reference system) en formato
    \href{http://trac.osgeo.org/proj}{PROJ.4}.

    \begin{itemize}
    \item
      \texttt{CRS(as.character(NA))} para indicar no disponible/faltante
    \item
      \texttt{CRS(+proj=longlat)} para coordenadas geográficas
    \item
      \texttt{CRS(+proj=longlat\ +ellps=WGS84)} estándar GPS (World
      Geodetic System of 1984)
    \end{itemize}
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xbbox }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{( }\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{ncol=}\DecValTok{2}\NormalTok{)}
\FunctionTok{colnames}\NormalTok{(xbbox) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"min"}\NormalTok{, }\StringTok{"max"}\NormalTok{) }\CommentTok{\# Normalmente la bbox se genera automáticamente al crear el objeto}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{Spatial}\NormalTok{(xbbox, }\AttributeTok{proj4string =} \FunctionTok{CRS}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(}\ConstantTok{NA}\NormalTok{)))}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## class       : Spatial 
## features    : 1 
## extent      : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)
## crs         : NA
\end{verbatim}

Los objetos son del tipo S4.
Los componentes se denominan slots.
Se acceden con la función \texttt{slot()} o el operador \texttt{@}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{slot}\NormalTok{(x,}\StringTok{\textquotesingle{}bbox\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      min max
## [1,]   0   1
## [2,]   0   1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x}\SpecialCharTok{@}\NormalTok{bbox }\DocumentationTok{\#\#\# en s4 se pone @ en vez de $.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      min max
## [1,]   0   1
## [2,]   0   1
\end{verbatim}

El paquete sp dispone también de funciones para acceder/establecer
los componentes:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bbox}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      min max
## [1,]   0   1
## [2,]   0   1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{proj4string}\NormalTok{(x) }\OtherTok{\textless{}{-}} \FunctionTok{CRS}\NormalTok{(}\StringTok{"+proj=longlat +ellps=WGS84"}\NormalTok{) }\CommentTok{\# Importante}
\end{Highlighting}
\end{Shaded}

\hypertarget{spatialpoints-y-spatialpointsdataframe}{%
\subsection{SpatialPoints y SpatialPointsDataFrame}\label{spatialpoints-y-spatialpointsdataframe}}

\begin{itemize}
\item
  Tipo \texttt{SpatialPoints}

  \begin{itemize}
  \item
    Slots: \texttt{coords,\ bbox,\ proj4string}
  \item
    Objeto de datos básico para procesos puntuales.
  \end{itemize}
\item
  Tipo \texttt{SpatialPointsDataFrame}

  \begin{itemize}
  \item
    Slots: \texttt{data,\ coords.nrs,\ coords,\ bbox,\ proj4string}
  \item
    Objeto de datos básico para procesos geoestadísticos (y procesos
    puntuales marcados).
  \end{itemize}
\end{itemize}

\hypertarget{ejemplo-spatialpoints}{%
\subsubsection{Ejemplo SpatialPoints}\label{ejemplo-spatialpoints}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"datos/caballa.galicia.RData"}\NormalTok{)}
\FunctionTok{str}\NormalTok{(caballa.galicia)  }\CommentTok{\# data.frame(attr(caballa.galicia, "variable.labels"))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    676 obs. of  12 variables:
##  $ id       : Factor w/ 31 levels "A1","A2","B1",..: 17 17 19 19 19 21 21 23 23 23 ...
##  $ x        : num  -9.4 -9.44 -9.44 -9.4 -9.47 ...
##  $ y        : num  43 43 43 43 42.8 ...
##  $ fecha    : num  1.32e+10 1.32e+10 1.32e+10 1.32e+10 1.32e+10 ...
##  $ semana   : num  7 7 7 7 7 7 8 8 8 8 ...
##  $ mes      : num  2 2 2 2 2 2 2 2 2 2 ...
##  $ ano      : num  2001 2001 2001 2001 2001 ...
##  $ cpue     : num  18 240 240 18 118 ...
##  $ chl_a    : num  NA NA 7.08 7.08 7.08 ...
##  $ sust_amar: num  NA NA 0.356 0.356 0.356 ...
##  $ sst      : num  14.2 14.2 16 16 16 16.1 16 15.9 15.9 15.9 ...
##  $ lcpue    : num  2.89 5.48 5.48 2.89 4.77 ...
##  - attr(*, "variable.labels")= Named chr [1:12] "Cuadricula " "" "" "" ...
##   ..- attr(*, "names")= chr [1:12] "id" "x" "y" "fecha" ...
##  - attr(*, "codepage")= int 1252
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(y}\SpecialCharTok{\textasciitilde{}}\NormalTok{x, }\AttributeTok{data =}\NormalTok{ caballa.galicia)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-6-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spt }\OtherTok{\textless{}{-}} \FunctionTok{SpatialPoints}\NormalTok{(caballa.galicia[,}\FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{,}\StringTok{"y"}\NormalTok{)], }\AttributeTok{proj4string =} \FunctionTok{CRS}\NormalTok{(}\StringTok{"+proj=longlat +ellps=WGS84"}\NormalTok{))}
\FunctionTok{summary}\NormalTok{(spt)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Object of class SpatialPoints
## Coordinates:
##        min       max
## x -9.56538 -8.030065
## y 41.86240 44.010800
## Is projected: FALSE 
## proj4string : [+proj=longlat +ellps=WGS84 +no_defs]
## Number of points: 676
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(spt)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Formal class 'SpatialPoints' [package "sp"] with 3 slots
##   ..@ coords     : num [1:676, 1:2] -9.4 -9.44 -9.44 -9.4 -9.47 ...
##   .. ..- attr(*, "dimnames")=List of 2
##   .. .. ..$ : chr [1:676] "1" "2" "3" "4" ...
##   .. .. ..$ : chr [1:2] "x" "y"
##   ..@ bbox       : num [1:2, 1:2] -9.57 41.86 -8.03 44.01
##   .. ..- attr(*, "dimnames")=List of 2
##   .. .. ..$ : chr [1:2] "x" "y"
##   .. .. ..$ : chr [1:2] "min" "max"
##   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
##   .. .. ..@ projargs: chr "+proj=longlat +ellps=WGS84 +no_defs"
##   .. .. ..$ comment: chr "GEOGCRS[\"unknown\",\n    DATUM[\"Unknown based on WGS84 ellipsoid\",\n        ELLIPSOID[\"WGS 84\",6378137,298"| __truncated__
\end{verbatim}

Hay muchos métodos (funciones genéricas) implementados para objetos \texttt{sp}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot(spt)}
\FunctionTok{plot}\NormalTok{(spt, }\AttributeTok{axes=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-7-1} \end{center}

\hypertarget{ejemplo-spatialpointsdataframe}{%
\subsubsection{Ejemplo SpatialPointsDataFrame}\label{ejemplo-spatialpointsdataframe}}

Importante (para preparar datos):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdf1 }\OtherTok{\textless{}{-}} \FunctionTok{SpatialPointsDataFrame}\NormalTok{(caballa.galicia[,}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)], caballa.galicia[,}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)], }\AttributeTok{proj4string =} \FunctionTok{CRS}\NormalTok{(}\StringTok{"+proj=longlat +ellps=WGS84"}\NormalTok{))}
\FunctionTok{str}\NormalTok{(sdf1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
##   ..@ data       :'data.frame':  676 obs. of  10 variables:
##   .. ..$ id       : Factor w/ 31 levels "A1","A2","B1",..: 17 17 19 19 19 21 21 23 23 23 ...
##   .. ..$ fecha    : num [1:676] 1.32e+10 1.32e+10 1.32e+10 1.32e+10 1.32e+10 ...
##   .. ..$ semana   : num [1:676] 7 7 7 7 7 7 8 8 8 8 ...
##   .. ..$ mes      : num [1:676] 2 2 2 2 2 2 2 2 2 2 ...
##   .. ..$ ano      : num [1:676] 2001 2001 2001 2001 2001 ...
##   .. ..$ cpue     : num [1:676] 18 240 240 18 118 ...
##   .. ..$ chl_a    : num [1:676] NA NA 7.08 7.08 7.08 ...
##   .. ..$ sust_amar: num [1:676] NA NA 0.356 0.356 0.356 ...
##   .. ..$ sst      : num [1:676] 14.2 14.2 16 16 16 16.1 16 15.9 15.9 15.9 ...
##   .. ..$ lcpue    : num [1:676] 2.89 5.48 5.48 2.89 4.77 ...
##   ..@ coords.nrs : num(0) 
##   ..@ coords     : num [1:676, 1:2] -9.4 -9.44 -9.44 -9.4 -9.47 ...
##   .. ..- attr(*, "dimnames")=List of 2
##   .. .. ..$ : chr [1:676] "1" "2" "3" "4" ...
##   .. .. ..$ : chr [1:2] "x" "y"
##   ..@ bbox       : num [1:2, 1:2] -9.57 41.86 -8.03 44.01
##   .. ..- attr(*, "dimnames")=List of 2
##   .. .. ..$ : chr [1:2] "x" "y"
##   .. .. ..$ : chr [1:2] "min" "max"
##   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
##   .. .. ..@ projargs: chr "+proj=longlat +ellps=WGS84 +no_defs"
##   .. .. ..$ comment: chr "GEOGCRS[\"unknown\",\n    DATUM[\"Unknown based on WGS84 ellipsoid\",\n        ELLIPSOID[\"WGS 84\",6378137,298"| __truncated__
\end{verbatim}

Una alernativa normalmente preferible es modificar directamente
el \texttt{data.frame}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdf }\OtherTok{\textless{}{-}}\NormalTok{ caballa.galicia}
\FunctionTok{coordinates}\NormalTok{(sdf) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{) }\CommentTok{\# Recomendación}
\FunctionTok{proj4string}\NormalTok{(sdf) }\OtherTok{\textless{}{-}} \FunctionTok{CRS}\NormalTok{(}\StringTok{"+proj=longlat +ellps=WGS84"}\NormalTok{)  }\CommentTok{\# También sdf@proj4string \textless{}{-} CRS("+proj=longlat +ellps=WGS84")}
\FunctionTok{str}\NormalTok{(sdf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
##   ..@ data       :'data.frame':  676 obs. of  10 variables:
##   .. ..$ id       : Factor w/ 31 levels "A1","A2","B1",..: 17 17 19 19 19 21 21 23 23 23 ...
##   .. ..$ fecha    : num [1:676] 1.32e+10 1.32e+10 1.32e+10 1.32e+10 1.32e+10 ...
##   .. ..$ semana   : num [1:676] 7 7 7 7 7 7 8 8 8 8 ...
##   .. ..$ mes      : num [1:676] 2 2 2 2 2 2 2 2 2 2 ...
##   .. ..$ ano      : num [1:676] 2001 2001 2001 2001 2001 ...
##   .. ..$ cpue     : num [1:676] 18 240 240 18 118 ...
##   .. ..$ chl_a    : num [1:676] NA NA 7.08 7.08 7.08 ...
##   .. ..$ sust_amar: num [1:676] NA NA 0.356 0.356 0.356 ...
##   .. ..$ sst      : num [1:676] 14.2 14.2 16 16 16 16.1 16 15.9 15.9 15.9 ...
##   .. ..$ lcpue    : num [1:676] 2.89 5.48 5.48 2.89 4.77 ...
##   ..@ coords.nrs : int [1:2] 2 3
##   ..@ coords     : num [1:676, 1:2] -9.4 -9.44 -9.44 -9.4 -9.47 ...
##   .. ..- attr(*, "dimnames")=List of 2
##   .. .. ..$ : chr [1:676] "1" "2" "3" "4" ...
##   .. .. ..$ : chr [1:2] "x" "y"
##   ..@ bbox       : num [1:2, 1:2] -9.57 41.86 -8.03 44.01
##   .. ..- attr(*, "dimnames")=List of 2
##   .. .. ..$ : chr [1:2] "x" "y"
##   .. .. ..$ : chr [1:2] "min" "max"
##   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
##   .. .. ..@ projargs: chr "+proj=longlat +ellps=WGS84 +no_defs"
##   .. .. ..$ comment: chr "GEOGCRS[\"unknown\",\n    DATUM[\"Unknown based on WGS84 ellipsoid\",\n        ELLIPSOID[\"WGS 84\",6378137,298"| __truncated__
\end{verbatim}

Operaciones como en un \texttt{data.frame}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(sdf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "id"        "fecha"     "semana"    "mes"       "ano"       "cpue"     
##  [7] "chl_a"     "sust_amar" "sst"       "lcpue"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdf}\SpecialCharTok{$}\NormalTok{id  }\CommentTok{\# Equivalente a sdf@data$id }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1] E2 E2 F2 F2 F2 G2 G2 H1 H1 H1 I1 I1 I2 I2 J1 J1 J1 J1 J2 J2 J2 D1 E1 F1 F1
##  [26] G1 G2 H2 I2 I2 J1 J2 D1 E2 E2 F2 F1 F1 F1 F2 G1 G1 G2 G2 H2 I1 I1 I2 I2 I2
##  [51] J1 J1 J2 E2 F1 F1 G1 G2 H1 H2 H2 I1 I1 I1 I1 I2 I2 I2 F1 F2 F2 G2 I1 I1 I1
##  [76] I1 I2 I2 I2 I2 J1 J1 E2 F2 F2 F2 F2 G2 G2 H3 I3 I3 I3 J3 J3 J3 F2 G2 H2 F2
## [101] G2 G2 H2 I1 I1 I2 I2 J2 B2 B3 C2 C3 C3 E2 F2 F2 G2 H3 I3 B3 B3 C3 C3 C3 C4
## [126] C4 C4 I2 I2 I3 J2 J2 H2 H2 H2 I2 I2 I2 E2 F2 F2 G2 B2 B3 B3 C3 C3 C3 C4 C4
## [151] E1 F1 F1 F1 F2 G1 G1 G2 E1 F1 F2 G2 G2 H2 I2 I2 I2 J2 J2 A1 B2 B3 B3 B3 B4
## [176] B4 C3 I2 I2 J2 J2 I2 J2 I2 J2 I3 J2 J3 A1 A2 A2 B3 B4 B4 B5 C2 C3 C3 C4 D2
## [201] D3 F1 F2 C2 C2 C3 C3 C3 C4 C4 D4 H2 H2 H3 I3 B2 B3 C2 C2 C3 C3 C3 C3 C4 B2
## [226] B3 C2 C3 C3 C3 C3 C4 C4 C4 B2 C2 C2 C3 C3 C3 C3 C4 C4 C4 H2 H2 I1 I2 I2 I1
## [251] I2 I2 I2 I2 I3 J1 J2 J2 J2 J3 B2 B3 B3 B3 B3 C3 C3 C3 C3 C4 C4 C4 I2 I2 I3
## [276] I3 J2 J2 J3 J3 B2 C3 C3 C4 C4 B2 B2 B3 B3 B3 C3 C3 C3 C4 C4 B2 B2 B3 C3 C3
## [301] C3 C3 C4 D4 B2 B2 B3 C2 C2 C3 C3 C3 C3 C4 I2 J2 J2 J2 B2 B3 C2 C2 C3 C3 C4
## [326] I3 J2 J2 J3 B3 B3 B3 B4 B4 C3 C4 C4 B2 B3 C3 C3 C3 C4 C4 B3 C3 C3 C4 C4 C4
## [351] B3 B3 B3 B4 B4 C4 G2 H1 H2 H2 B3 B3 B4 C4 C4 H2 H2 I2 I2 H2 I2 J2 B3 B3 B4
## [376] C3 C4 C4 D4 B3 C3 C3 C4 C4 C4 D4 D4 H2 I2 I2 J1 J2 D1 D2 D2 D2 D2 H2 I2 E2
## [401] F2 F2 F2 E2 E2 F2 F2 E2 F2 F2 F2 G2 B2 B2 B3 B3 B3 C3 C3 C3 C4 C1 C2 C3 C3
## [426] C4 D1 D2 D4 C1 C2 C2 C3 C3 C4 I2 I2 J1 J1 J2 J2 I3 H2 H3 I2 I2 I2 I2 I2 I3
## [451] J1 J1 J1 J2 J2 J2 J2 H3 H3 I2 I3 I3 I3 I3 I3 J2 J2 J3 H3 H3 H3 I2 I2 I2 I3
## [476] I3 I3 J2 J2 G3 G3 H2 H2 H2 H2 H2 H3 G3 H2 H2 H2 E1 F1 E1 F1 E1 F1 G2 H1 H2
## [501] H2 H3 I3 C2 D1 D1 D1 D2 D2 D2 E2 E2 E2 F2 B1 B2 C2 C2 C3 D1 D1 D1 D2 E2 E2
## [526] H2 I2 I2 I2 J1 J1 J1 J2 J2 H3 H3 I3 I3 I3 I3 J3 J3 H1 I1 H3 H3 I2 I2 I3 I3
## [551] I3 I3 J2 J2 I2 I3 J2 H3 H3 I3 I3 I3 I3 J3 J3 H3 I3 I3 I3 J3 J3 H3 H3 I2 I3
## [576] I3 I3 I3 J3 J3 H3 H3 I2 I3 I3 I3 J2 J2 J3 F1 F2 G2 G2 H1 H2 H2 F1 G1 G2 I1
## [601] I2 I2 I2 J1 J1 J2 J2 J2 I2 I2 I2 I2 J2 J2 J2 J2 D1 D2 E2 E2 E2 F2 F2 G2 D1
## [626] D1 D1 D1 D2 D2 E1 E2 E2 F1 G1 G2 G2 F1 G1 G1 G1 G2 G2 G1 G2 H3 I2 I3 I3 J2
## [651] J2 J3 J3 H3 I3 I3 I3 I3 I3 J2 J3 J3 J3 J3 H3 I2 I3 I3 I3 I3 I3 I3 J3 J3 J3
## [676] J3
## 31 Levels: A1 A2 B1 B2 B3 B4 B5 C1 C2 C3 C4 D1 D2 D3 D4 E1 E2 F1 F2 G1 ... J3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(sdf, }\AttributeTok{axes =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(sdf[sdf}\SpecialCharTok{$}\NormalTok{id }\SpecialCharTok{==} \StringTok{"J3"}\NormalTok{, ], }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-10-1} \end{center}

Importante (para análisis descriptivo):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(sdf[,}\FunctionTok{c}\NormalTok{(}\StringTok{"cpue"}\NormalTok{,}\StringTok{"lcpue"}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Object of class SpatialPointsDataFrame
## Coordinates:
##        min       max
## x -9.56538 -8.030065
## y 41.86240 44.010800
## Is projected: FALSE 
## proj4string : [+proj=longlat +ellps=WGS84 +no_defs]
## Number of points: 676
## Data attributes:
##       cpue              lcpue        
##  Min.   :  0.1435   Min.   :-1.9411  
##  1st Qu.:  1.9559   1st Qu.: 0.6708  
##  Median :  5.8537   Median : 1.7671  
##  Mean   : 30.9208   Mean   : 1.9087  
##  3rd Qu.: 19.5349   3rd Qu.: 2.9722  
##  Max.   :870.0000   Max.   : 6.7685
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(sdf}\SpecialCharTok{$}\NormalTok{cpue)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-11-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(sdf}\SpecialCharTok{$}\NormalTok{lcpue)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-11-2} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{spplot}\NormalTok{(sdf, }\StringTok{"lcpue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-11-3} \end{center}

\hypertarget{spatiallines-y-spatialpolygons}{%
\subsection{SpatialLines y SpatialPolygons}\label{spatiallines-y-spatialpolygons}}

\begin{itemize}
\item
  Tipo \texttt{SpatialLines}

  \begin{itemize}
  \item
    Basados en \texttt{Line}: \texttt{coords}
  \item
    Se combinan objetos \texttt{Line} en listas: \texttt{lines,\ bbox,\ proj4string}
  \item
    De utilidad principalmente para representaciones gráficas (y
    para generar polígonos).
  \end{itemize}
\item
  Tipo \texttt{SpatialPolygons}

  \begin{itemize}
  \item
    Basados en \texttt{Polygon}:
    \texttt{labpt,\ area,\ hole,\ ringDir,\ coords}(extiende \texttt{Line} de forma
    que la primera y la última línea es la misma)\texttt{.}
  \item
    Se combinan objetos \texttt{Polygon} en listas:
    \texttt{polygons,\ plotOrder,\ bbox,\ proj4string.}
  \item
    De utilidad principalmente para representaciones gráficas (y
    \texttt{overlay}).
  \end{itemize}
\item
  Se extienden también a \texttt{Spatial*DataFrame} (slot \texttt{data})

  \begin{itemize}
  \tightlist
  \item
    \texttt{SpatialPolygonsDataFrame}: util para procesos reticulares.
  \end{itemize}
\end{itemize}

\hypertarget{ejemplo-spatiallines}{%
\subsubsection{Ejemplo SpatialLines}\label{ejemplo-spatiallines}}

El fichero \emph{costa.galicia.txt} contiene la costa de Galicia en formato Mapgen.
Descargada del (difunto) \href{http://www.ngdc.noaa.gov/mgg/shorelines/shorelines.html}{Coastline Extractor}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(maptools) }\CommentTok{\# Utilidades para convertir datos entre diferentes formatos espaciales}

\NormalTok{costa.galicia }\OtherTok{\textless{}{-}} \FunctionTok{MapGen2SL}\NormalTok{(}\StringTok{"datos/costa.galicia.txt"}\NormalTok{, }\FunctionTok{CRS}\NormalTok{(}\StringTok{"+proj=longlat +ellps=WGS84"}\NormalTok{))}

\FunctionTok{summary}\NormalTok{(costa.galicia)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Object of class SpatialLines
## Coordinates:
##         min       max
## x -9.305495 -6.500147
## y 41.500846 43.791944
## Is projected: FALSE 
## proj4string : [+proj=longlat +ellps=WGS84 +no_defs]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(sdf, }\AttributeTok{axes=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(costa.galicia, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-12-1} \end{center}

\hypertarget{ejemplo-spatialpolygonsdataframe}{%
\subsubsection{Ejemplo SpatialPolygonsDataFrame}\label{ejemplo-spatialpolygonsdataframe}}

Los objetos de este tipo se suelen crear a partir de objetos \texttt{SpatialLines},
pero hay que asegurarse de que definen adecuadamente un polígono.

Objetos de este tipo se pueden descargar de
\href{http://www.gadm.org}{GADM database of Global Administrative Areas}.
Contienen límites administrativos a disintos niveles, e.g.:

\begin{itemize}
\item
  \texttt{ESP\_adm0.rds} límites España e islas
\item
  \texttt{ESP\_adm1.rds} límites Autonomías
\item
  \texttt{ESP\_adm2.rds} límites Provincias
\item
  \texttt{ESP\_adm3.rds} límites Comarcas
\item
  \texttt{ESP\_adm4.rds} límites Ayuntamientos
\end{itemize}

NOTA: Se podrían descargar directamente desde R, e.g.:

\begin{verbatim}
  con <- url('http://gadm.org/data/rda/ESP_adm1.rds')
  gadm <- readRDS(con)
  close(con)
\end{verbatim}

Carga de un objeto gadm:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gadm }\OtherTok{\textless{}{-}} \FunctionTok{readRDS}\NormalTok{(}\StringTok{"datos/ESP\_adm1.rds"}\NormalTok{) }
\FunctionTok{summary}\NormalTok{(gadm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Object of class SpatialPolygonsDataFrame
## Coordinates:
##         min       max
## x -18.16153  4.328195
## y  27.63736 43.791527
## Is projected: FALSE 
## proj4string :
## [+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0]
## Data attributes:
##     OBJECTID          ID_0         ISO               NAME_0         
##  Min.   : 1.00   Min.   :215   Length:18          Length:18         
##  1st Qu.: 5.25   1st Qu.:215   Class :character   Class :character  
##  Median : 9.50   Median :215   Mode  :character   Mode  :character  
##  Mean   : 9.50   Mean   :215                                        
##  3rd Qu.:13.75   3rd Qu.:215                                        
##  Max.   :18.00   Max.   :215                                        
##                                                                     
##       ID_1          NAME_1             HASC_1              CCN_1    
##  Min.   : 1.00   Length:18          Length:18          Min.   : NA  
##  1st Qu.: 5.25   Class :character   Class :character   1st Qu.: NA  
##  Median : 9.50   Mode  :character   Mode  :character   Median : NA  
##  Mean   : 9.50                                         Mean   :NaN  
##  3rd Qu.:13.75                                         3rd Qu.: NA  
##  Max.   :18.00                                         Max.   : NA  
##                                                        NA's   :18   
##     CCA_1              TYPE_1           ENGTYPE_1          NL_NAME_1        
##  Length:18          Length:18          Length:18          Length:18         
##  Class :character   Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
##                                                                             
##                                                                             
##                                                                             
##                                                                             
##   VARNAME_1        
##  Length:18         
##  Class :character  
##  Mode  :character  
##                    
##                    
##                    
## 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(gadm)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-13-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Cuidado objeto muy grande: str(gadm)}
\CommentTok{\# Mejor emplear str(gadm, 3)}
\end{Highlighting}
\end{Shaded}

Extraer autonomía de Galicia:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(gadm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "OBJECTID"  "ID_0"      "ISO"       "NAME_0"    "ID_1"      "NAME_1"   
##  [7] "HASC_1"    "CCN_1"     "CCA_1"     "TYPE_1"    "ENGTYPE_1" "NL_NAME_1"
## [13] "VARNAME_1"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{galicia }\OtherTok{\textless{}{-}}\NormalTok{ gadm[gadm}\SpecialCharTok{$}\NormalTok{NAME\_1 }\SpecialCharTok{==} \StringTok{"Galicia"}\NormalTok{, ]}
\FunctionTok{plot}\NormalTok{(galicia)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-14-1} \end{center}

Es preferible emplear este tipo de objetos a \texttt{SpatialLines}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(sdf, }\AttributeTok{axes=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(galicia, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-15-1} \end{center}

\hypertarget{spatialgrid-y-spatialpixels}{%
\subsection{SpatialGrid y SpatialPixels}\label{spatialgrid-y-spatialpixels}}

Es habitual trabajar con datos espaciales en formato
rejilla (grid) (e.g.~predicciones en geoestadística):

\begin{itemize}
\item
  Rejilla (posiciones) definida por un objeto \texttt{GridTopology}:
  \texttt{cellcentre.offset,\ cellsize,\ cells.dim}
\item
  Tipos \texttt{SpatialGrid} y \texttt{SpatialPixels}:
  \texttt{grid,\ grid.index,\ coords,\ bbox,\ proj4string}
\item
  Se extienden también a \texttt{Spatial*DataFrame} (slot \texttt{data})
\item
  Los objetos \texttt{SpatialGrid} se corresponden con la rejilla completa:
\item
  Los objetos \texttt{SpatialPixels} se corresponden con una rejilla
  incompleta

  \begin{itemize}
  \item
    \texttt{coords}contiene todas las coordenadas (objetos equivalentes a
    \texttt{SpatialPoints})
  \item
    \texttt{grid.index}indices de la rejilla
  \end{itemize}
\end{itemize}

\hypertarget{ejemplo-spatialgrid}{%
\subsubsection{Ejemplo SpatialGrid}\label{ejemplo-spatialgrid}}

Importante si se utiliza el paquete \texttt{gstat}\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xrange }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{7.5}\NormalTok{)}
\NormalTok{yrange }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{42.25}\NormalTok{, }\DecValTok{44}\NormalTok{)}
\NormalTok{nx }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{ny }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{hx }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(xrange)}\SpecialCharTok{/}\NormalTok{(nx}\DecValTok{{-}1}\NormalTok{)}
\NormalTok{hy }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(yrange)}\SpecialCharTok{/}\NormalTok{(ny}\DecValTok{{-}1}\NormalTok{)}

\NormalTok{gridtop }\OtherTok{\textless{}{-}} \FunctionTok{GridTopology}\NormalTok{(}\AttributeTok{cellcentre.offset =} \FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(xrange), }\FunctionTok{min}\NormalTok{(yrange)),}
                        \AttributeTok{cellsize =} \FunctionTok{c}\NormalTok{(hx, hy), }\AttributeTok{cells.dim =} \FunctionTok{c}\NormalTok{(nx, ny))}
\NormalTok{spgrid }\OtherTok{\textless{}{-}}  \FunctionTok{SpatialGrid}\NormalTok{(gridtop, }\AttributeTok{proj4string =} \FunctionTok{proj4string}\NormalTok{(gadm))}

\FunctionTok{str}\NormalTok{(spgrid)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Formal class 'SpatialGrid' [package "sp"] with 3 slots
##   ..@ grid       :Formal class 'GridTopology' [package "sp"] with 3 slots
##   .. .. ..@ cellcentre.offset: num [1:2] -10 42.2
##   .. .. ..@ cellsize         : num [1:2] 0.0253 0.0177
##   .. .. ..@ cells.dim        : int [1:2] 100 100
##   ..@ bbox       : num [1:2, 1:2] -10.01 42.24 -7.49 44.01
##   .. ..- attr(*, "dimnames")=List of 2
##   .. .. ..$ : NULL
##   .. .. ..$ : chr [1:2] "min" "max"
##   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
##   .. .. ..@ projargs: chr "+proj=longlat +datum=WGS84 +no_defs"
##   .. .. ..$ comment: chr "GEOGCRS[\"unknown\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.25722"| __truncated__
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(spgrid, }\AttributeTok{axes =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(galicia, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-16-1} \end{center}

\hypertarget{ejemplo-spatialpixels}{%
\subsubsection{Ejemplo SpatialPixels}\label{ejemplo-spatialpixels}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# over: combinación de objetos espaciales}
\NormalTok{index }\OtherTok{\textless{}{-}} \FunctionTok{over}\NormalTok{(spgrid, }\FunctionTok{as}\NormalTok{(galicia, }\StringTok{"SpatialPolygons"}\NormalTok{))}
\NormalTok{sppix }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(spgrid, }\StringTok{"SpatialPixels"}\NormalTok{)[}\FunctionTok{is.na}\NormalTok{(index), ]}

\FunctionTok{str}\NormalTok{(sppix)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Formal class 'SpatialPixels' [package "sp"] with 5 slots
##   ..@ grid       :Formal class 'GridTopology' [package "sp"] with 3 slots
##   .. .. ..@ cellcentre.offset: num [1:2] -10 42.2
##   .. .. ..@ cellsize         : num [1:2] 0.0253 0.0177
##   .. .. ..@ cells.dim        : int [1:2] 100 100
##   ..@ grid.index : int [1:5631] 1 2 3 4 5 6 7 8 9 10 ...
##   ..@ coords     : num [1:5631, 1:2] -10 -9.97 -9.95 -9.92 -9.9 ...
##   .. ..- attr(*, "dimnames")=List of 2
##   .. .. ..$ : NULL
##   .. .. ..$ : chr [1:2] "s1" "s2"
##   ..@ bbox       : num [1:2, 1:2] -10.01 42.24 -7.49 44.01
##   .. ..- attr(*, "dimnames")=List of 2
##   .. .. ..$ : chr [1:2] "s1" "s2"
##   .. .. ..$ : chr [1:2] "min" "max"
##   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
##   .. .. ..@ projargs: chr "+proj=longlat +datum=WGS84 +no_defs"
##   .. .. ..$ comment: chr "GEOGCRS[\"unknown\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.25722"| __truncated__
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(sppix, }\AttributeTok{axes =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(galicia, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-17-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# NOTA: puede ser preferible asignar NA\textquotesingle{}s a variables en SpatialGridDataFrame...}
\FunctionTok{object.size}\NormalTok{(spgrid)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 4040 bytes
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{object.size}\NormalTok{(sppix)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 117680 bytes
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Otras funciones:}
\CommentTok{\# as(sppix, "SpatialGrid") recostruye la rejilla completa}
\CommentTok{\# gridded(ObjetoSpatialPoints) \textless{}{-} TRUE  convierte el objeto SpatialPoints en SpatialPixels}
\end{Highlighting}
\end{Shaded}

\hypertarget{muxe9todos-y-procedimientos-clases-sp}{%
\section{Métodos y procedimientos clases sp}\label{muxe9todos-y-procedimientos-clases-sp}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.13}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.87}}@{}}
\toprule
Método & Descripción \\
\midrule
\endhead
\texttt{{[}} & selecciona elementos espaciales (puntos, líneas, polígonos, filas/columnas de una rejilla) y/o variables. \\
\texttt{\$,\ {[}{[}} & obtiene, establece o agrega variables (columnas). \\
\texttt{coordinates} & obtiene o establece (creando objetos sp) coordenadas. \\
\texttt{as(obj,\ clase)} & convierte un objeto a una clase. \\
\texttt{over,\ overlay} & combina objetos espaciales. \\
\texttt{spsample} & muestrea puntos dentro de una región (rectangular, polígono, línea o rejilla). \\
\bottomrule
\end{longtable}

\hypertarget{importarexportartransformar}{%
\subsection{Importar/exportar/transformar}\label{importarexportartransformar}}

A través de R (paquetes que emplean sp) es fácil exportar datos a otras aplicaciones
(e.g.~\href{http://plotkml.r-forge.r-project.org}{Google Earth}).

Ejemplo importación:

Datos descargados en formato NetCDF (\href{http://www.opengeospatial.org/standards/netcdf}{Network Common Data Form})
de \href{http://www.esrl.noaa.gov/psd/data/gridded/data.noaa.oisst.v2.html}{NOAA Optimum Interpolated Sea Surface Temperature V2 (OISST)}
y procesados con \emph{\href{datos/NOAA_OISST_extraction_v2.R}{NOAA\_OISST\_extraction\_v2.R}}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"datos/sstsp.RData"}\NormalTok{) }\CommentTok{\# SST 15{-}04{-}2012 }
\NormalTok{jet.colors }\OtherTok{\textless{}{-}} \FunctionTok{colorRampPalette}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"\#00007F"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"\#007FFF"}\NormalTok{, }\StringTok{"cyan"}\NormalTok{, }\StringTok{"\#7FFF7F"}\NormalTok{, }\StringTok{"yellow"}\NormalTok{, }\StringTok{"\#FF7F00"}\NormalTok{, }\StringTok{"red"}\NormalTok{, }\StringTok{"\#7F0000"}\NormalTok{))}
\FunctionTok{image}\NormalTok{(sstsp, }\AttributeTok{col =} \FunctionTok{jet.colors}\NormalTok{(}\DecValTok{128}\NormalTok{), }\AttributeTok{axes =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{title}\NormalTok{(}\FunctionTok{attr}\NormalTok{(sstsp}\SpecialCharTok{@}\NormalTok{data, }\StringTok{"label"}\NormalTok{))}

\CommentTok{\# Ejemplo importar datos de otros paquetes:}
\FunctionTok{library}\NormalTok{(maps)}
\FunctionTok{library}\NormalTok{(maptools)}
\NormalTok{world }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(}\StringTok{"world"}\NormalTok{, }\AttributeTok{fill =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{plot =} \ConstantTok{FALSE}\NormalTok{)   }\CommentTok{\# Hay un mapa con mayor resolución en mapdata::worldHires}
\NormalTok{world\_pol }\OtherTok{\textless{}{-}} \FunctionTok{map2SpatialPolygons}\NormalTok{(world, world}\SpecialCharTok{$}\NormalTok{names, }\FunctionTok{CRS}\NormalTok{(}\StringTok{"+proj=longlat +ellps=WGS84"}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(world\_pol, }\AttributeTok{col =} \StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-18-1} \end{center}

\hypertarget{representaciones-gruxe1ficas}{%
\section{Representaciones gráficas}\label{representaciones-gruxe1ficas}}

\hypertarget{gruxe1ficos-estuxe1ndar}{%
\subsection{Gráficos estándar}\label{gruxe1ficos-estuxe1ndar}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(sdf, }\AttributeTok{axes =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{pch =} \DecValTok{1}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(galicia, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-19-1} \end{center}

Color en función de una variable categórica:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdf}\SpecialCharTok{$}\NormalTok{ano }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(sdf}\SpecialCharTok{$}\NormalTok{ano)   }\CommentTok{\# convertir año a factor}
\NormalTok{colores }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"yellow"}\NormalTok{, }\StringTok{"red"}\NormalTok{)}
\NormalTok{color }\OtherTok{\textless{}{-}}\NormalTok{ colores[}\FunctionTok{as.numeric}\NormalTok{(sdf}\SpecialCharTok{$}\NormalTok{ano)]}
\FunctionTok{plot}\NormalTok{(sdf, }\AttributeTok{axes =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{col =}\NormalTok{ color, }\AttributeTok{pch =} \DecValTok{19}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\AttributeTok{fill =}\NormalTok{ colores, }\AttributeTok{legend =} \FunctionTok{levels}\NormalTok{(sdf}\SpecialCharTok{$}\NormalTok{ano), }\AttributeTok{bty =} \StringTok{"n"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(galicia, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-20-1} \end{center}

Usando p.e. la función classIntervals del paquete classInt
se puede establecer los colores en función de una variable continua:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(classInt) }\CommentTok{\# install.packages(\textquotesingle{}classInt\textquotesingle{})}

\NormalTok{class.int }\OtherTok{\textless{}{-}} \FunctionTok{classIntervals}\NormalTok{(sdf}\SpecialCharTok{$}\NormalTok{lcpue, }\AttributeTok{n =} \DecValTok{5}\NormalTok{, }\AttributeTok{style =} \StringTok{"quantile"}\NormalTok{)}
\NormalTok{pal }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{)}
\CommentTok{\# plot(class.int, pal = pal)}

\NormalTok{class.col }\OtherTok{\textless{}{-}} \FunctionTok{findColours}\NormalTok{(class.int, }\AttributeTok{pal =}\NormalTok{ pal)}

\FunctionTok{plot}\NormalTok{(sdf, }\AttributeTok{col =}\NormalTok{ class.col, }\AttributeTok{pch =} \DecValTok{19}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\AttributeTok{fill =} \FunctionTok{attr}\NormalTok{(class.col, }\StringTok{"palette"}\NormalTok{), }
       \AttributeTok{legend =} \FunctionTok{names}\NormalTok{(}\FunctionTok{attr}\NormalTok{(class.col, }\StringTok{"table"}\NormalTok{)), }\AttributeTok{bty =} \StringTok{"n"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(galicia, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-21-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# methods(image) para rejillas}
\CommentTok{\# ver tambien splot, simage,... en library(npsp)}
\end{Highlighting}
\end{Shaded}

\hypertarget{gruxe1ficos-lattice-spplot}{%
\subsection{Gráficos lattice: spplot}\label{gruxe1ficos-lattice-spplot}}

\begin{itemize}
\item
  Ventajas: ``Ideales'' para las clases sp (para gráfico automáticos\ldots)
\item
  Inconveniente: los gráficos lattice requieren mayor tiempo de aprendizaje (dificultades para personalizarlos\ldots)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(lattice)}

\FunctionTok{spplot}\NormalTok{(sdf, }\StringTok{"lcpue"}\NormalTok{, }\AttributeTok{main =} \StringTok{"CPUE (escala logarítmica)"}\NormalTok{, }
       \AttributeTok{col.regions =} \FunctionTok{topo.colors}\NormalTok{(}\DecValTok{6}\NormalTok{), }\AttributeTok{cuts=}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-22-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bubble}\NormalTok{(sdf, }\StringTok{"cpue"}\NormalTok{, }\AttributeTok{main =} \StringTok{"CPUE"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-22-2} \end{center}

Añadir perfil de Galicia:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sp.layout }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{"sp.polygons"}\NormalTok{, galicia)   }\CommentTok{\# Para añadir elementos se utiliza el parámetro sp.layout}
\FunctionTok{spplot}\NormalTok{(sdf, }\StringTok{"lcpue"}\NormalTok{, }\AttributeTok{main =} \StringTok{"CPUE (escala logarítmica)"}\NormalTok{, }
       \AttributeTok{col.regions =} \FunctionTok{topo.colors}\NormalTok{(}\DecValTok{6}\NormalTok{), }\AttributeTok{cuts =} \DecValTok{5}\NormalTok{, }\AttributeTok{sp.layout =}\NormalTok{ sp.layout )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{11-sp_files/figure-latex/unnamed-chunk-23-1} \end{center}

Alternativamente gráficos ggplot (\href{https://ggplot2.tidyverse.org}{\texttt{ggplot2}}) con el paquete \href{https://paleolimbot.github.io/ggspatial}{\texttt{ggspatial}}\ldots{}

\hypertarget{intro-geoR}{%
\chapter{\texorpdfstring{Introducción al paquete \textbf{geoR}}{Introducción al paquete geoR}}\label{intro-geoR}}

El paquete \href{http://www.leg.ufpr.br/geoR}{\texttt{geoR}} proporciona herramientas para el análisis de datos
geoestadísticos en \texttt{R}
(alternativa al paquete \href{http://r-spatial.github.io/gstat}{\texttt{gstat}}).
A continuación se ilustran algunas de las capacidades de este paquete.

\hypertarget{inicio-de-una-sesiuxf3n-y-de-carga-de-datos}{%
\section{Inicio de una sesión y de carga de datos}\label{inicio-de-una-sesiuxf3n-y-de-carga-de-datos}}

Después de iniciar la sesión R, cargar \texttt{geoR} con el comando \texttt{library} (o
\texttt{require}). Si el paquete se carga correctamente aparece un mensaje.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(geoR)}
\end{Highlighting}
\end{Shaded}

\hypertarget{archivos-de-datos}{%
\subsection{Archivos de datos}\label{archivos-de-datos}}

Normalmente, los datos se almacenan como un objeto (una lista) de la
clase \texttt{geodata}. Un objeto de esta clase contiene obligatoriamente dos
elementos:

\begin{itemize}
\item
  \texttt{\$coords}: las coordenadas de las posiciones de los datos.
\item
  \texttt{\$data}: los valores observados de la variables.
\end{itemize}

Opcionalmente pueden tener otros elementos, como covariables
y coordenadas de las fronteras de la zona de estudio.

Hay algunos conjuntos de datos incluidos en el paquete de distribución.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data()                    \# lista todos los conjuntos de datos disponibles}
\CommentTok{\# data(package = "geoR")    \# lista los conjuntos de datos en el paquete geoR}

\FunctionTok{data}\NormalTok{(wolfcamp)              }\CommentTok{\# carga el archivo de datos wolfcamp}
\FunctionTok{summary}\NormalTok{(wolfcamp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Number of data points: 85 
## 
## Coordinates summary
##       Coord.X   Coord.Y
## min -233.7217 -145.7884
## max  181.5314  136.4061
## 
## Distance summary
##         min         max 
##   0.3669819 436.2067085 
## 
## Data summary
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
##  312.1095  471.8218  547.7156  610.2845  774.1778 1088.4209
\end{verbatim}

Se pueden importar directamente un archivo de datos en formato texto:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ncep }\OtherTok{\textless{}{-}} \FunctionTok{read.geodata}\NormalTok{(}\StringTok{\textquotesingle{}ncep.txt\textquotesingle{}}\NormalTok{, }\AttributeTok{header =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{coords.col =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{data.col =} \DecValTok{4}\NormalTok{)}
\CommentTok{\# plot(ncep)}
\CommentTok{\# summary(ncep)}
\end{Highlighting}
\end{Shaded}

También se puede convertir un \texttt{data.frame} a un objeto \texttt{geodata}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ncep.df }\OtherTok{\textless{}{-}} \FunctionTok{read.table}\NormalTok{(}\StringTok{\textquotesingle{}ncep.txt\textquotesingle{}}\NormalTok{, }\AttributeTok{header =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{names}\NormalTok{(ncep.df) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}t\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}z\textquotesingle{}}\NormalTok{)}
\CommentTok{\# str(ncep.df)}
\CommentTok{\# Nota: los datos son espacio{-}temporales, pero geoR sólo admite datos 2D}

\NormalTok{datgeo }\OtherTok{\textless{}{-}} \FunctionTok{as.geodata}\NormalTok{(ncep.df, }\AttributeTok{coords.col =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{data.col =} \DecValTok{4}\NormalTok{)}
\CommentTok{\# plot(datgeo)}
\CommentTok{\# summary(datgeo)}
\end{Highlighting}
\end{Shaded}

O objetos de datos espaciales (entre ellos los compatibles del paquete \texttt{sp}),
por ejemplo el siguiente código crea un objeto \texttt{SpatialPointsDataFrame}
y lo convierte a \texttt{geodata}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sp)}
\FunctionTok{load}\NormalTok{(}\StringTok{"caballa.galicia.RData"}\NormalTok{)}
\FunctionTok{coordinates}\NormalTok{(caballa.galicia) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{,}\StringTok{"y"}\NormalTok{)}
\FunctionTok{proj4string}\NormalTok{(caballa.galicia) }\OtherTok{\textless{}{-}} \FunctionTok{CRS}\NormalTok{(}\StringTok{"+proj=longlat +ellps=WGS84"}\NormalTok{)}

\NormalTok{datgeo }\OtherTok{\textless{}{-}} \FunctionTok{as.geodata}\NormalTok{(caballa.galicia[}\StringTok{"lcpue"}\NormalTok{])}
\CommentTok{\# Problemas con coordenadas duplicadas  (ver ?duplicated)}
\CommentTok{\# plot(datgeo)}
\CommentTok{\# summary(datgeo)     }
\end{Highlighting}
\end{Shaded}

En la documentación de las funciones \texttt{as.geodata} y \texttt{read.geodata}
hay más información sobre cómo importar/convertir datos.

\hypertarget{anuxe1lisis-descriptivo-de-datos-geoestaduxedsticos}{%
\section{Análisis descriptivo de datos geoestadísticos}\label{anuxe1lisis-descriptivo-de-datos-geoestaduxedsticos}}

Como se mostró anteriormente, el método \texttt{summary} proporciona un breve resumen
descriptivo de los datos (ver \texttt{?summary.geodata}).

La función \texttt{plot()} genera por defecto gráficos de los
valores en las posiciones espaciales (distinguiendo según cuartiles),
los datos frente a las coordenadas y un histograma de los datos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(wolfcamp)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{12-geor_files/figure-latex/plot-geo1-1} \end{center}

Los gráficos de dispersión de los datos frente a las coordenadas nos pueden ayudar
a determinar si hay una tendencia. También, en lugar del histograma,
nos puede interesar un gráfico de dispersión 3D

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(wolfcamp, }\AttributeTok{lowess =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{scatter3d =} \ConstantTok{TRUE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{12-geor_files/figure-latex/plot-geo2-1} \end{center}

Si se asume que hay una tendencia puede interesar eliminarla:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(wolfcamp, }\AttributeTok{trend=}\SpecialCharTok{\textasciitilde{}}\NormalTok{coords)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{12-geor_files/figure-latex/plot-geo3-1} \end{center}

El comando \texttt{points(geodata)} (función \texttt{points.geodata}) genera un gráfico con
las posiciones de los datos (y por defecto con el tamaño de los puntos proporcional
al valor):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{points}\NormalTok{(wolfcamp)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-7-1} \end{center}

Se pueden establecer los tamaños de los puntos, simbolos y colores a
partir de los valores de los datos. Por ejemplo, para los puntos, empleando el argumento:
\texttt{pt.divide\ =\ c("data.proportional",\ "rank.proportional",\ "quintiles",}
\texttt{"quartiles",\ "deciles",\ "equal")}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{points}\NormalTok{(wolfcamp, }\AttributeTok{col =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{pt.divide =} \StringTok{"equal"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-8-1} \end{center}

\hypertarget{modelado-de-la-dependencia}{%
\section{Modelado de la dependencia}\label{modelado-de-la-dependencia}}

En la primera parte de esta sección consideraremos un proceso espacial sin
tendencia:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(s100) }\CommentTok{\# Cargar datos estacionarios}
\FunctionTok{summary}\NormalTok{(s100)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Number of data points: 100 
## 
## Coordinates summary
##         Coord.X    Coord.Y
## min 0.005638006 0.01091027
## max 0.983920544 0.99124979
## 
## Distance summary
##         min         max 
## 0.007640962 1.278175109 
## 
## Data summary
##       Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
## -1.1676955  0.2729882  1.1045936  0.9307179  1.6101707  2.8678969 
## 
## Other elements in the geodata object
## [1] "cov.model" "nugget"    "cov.pars"  "kappa"     "lambda"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(s100)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{12-geor_files/figure-latex/plot-s100-1} \end{center}

En el último apartado se tratará el caso general.

\hypertarget{variogramas-empuxedricos}{%
\subsection{Variogramas empíricos}\label{variogramas-empuxedricos}}

Los variogramas empíricos se calculan utilizando la función \texttt{variog}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)) }
\FunctionTok{plot}\NormalTok{(}\FunctionTok{variog}\NormalTok{(s100))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{center}\includegraphics[width=0.9\linewidth]{12-geor_files/figure-latex/plot-variog1-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

La recomendación es considerar solo saltos hasta la mitad de la máxima
distancia (ver \texttt{Distance\ summary} en resultados del sumario).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario }\OtherTok{\textless{}{-}} \FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(vario)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "u"                "v"                "n"                "sd"              
##  [5] "bins.lim"         "ind.bin"          "var.mark"         "beta.ols"        
##  [9] "output.type"      "max.dist"         "estimator.type"   "n.data"          
## [13] "lambda"           "trend"            "pairs.min"        "nugget.tolerance"
## [17] "direction"        "tolerance"        "uvec"             "call"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# str(vario)}
\end{Highlighting}
\end{Shaded}

NOTA: La componente \texttt{u} contiene los saltos, \texttt{v} las estimaciones del
semivariograma (semivarianzas) y \texttt{n} el número de aportaciones.

Los resultados pueden ser nubes de puntos (semivarianzas), valores
discretizados (binned) o suavizados, dependiendo del parámetro:
\texttt{option\ =\ c("bin",\ "cloud",\ "smooth")}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calculo de los variogramas empíricos}
\NormalTok{vario.b }\OtherTok{\textless{}{-}} \FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{) }\CommentTok{\#discretizado}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario.c }\OtherTok{\textless{}{-}} \FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{max.dist=}\FloatTok{0.6}\NormalTok{, }\AttributeTok{op=}\StringTok{"cloud"}\NormalTok{)  }\CommentTok{\#nube}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario.bc }\OtherTok{\textless{}{-}} \FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{max.dist=}\FloatTok{0.6}\NormalTok{, }\AttributeTok{bin.cloud=}\ConstantTok{TRUE}\NormalTok{)  }\CommentTok{\#discretizado+nube}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario.s }\OtherTok{\textless{}{-}} \FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{max.dist=}\FloatTok{0.6}\NormalTok{, }\AttributeTok{op=}\StringTok{"sm"}\NormalTok{, }\AttributeTok{band=}\FloatTok{0.2}\NormalTok{)  }\CommentTok{\#suavizado}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Representación gráfica}
\NormalTok{oldpar}\OtherTok{\textless{}{-}}\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)) }\CommentTok{\# Preparar para 4 gráficos por ventana}
\FunctionTok{plot}\NormalTok{(vario.b, }\AttributeTok{main=}\StringTok{"Variograma empírico"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(vario.c, }\AttributeTok{main=}\StringTok{"Nube de puntos variograma"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(vario.bc, }\AttributeTok{bin.cloud=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{main=}\StringTok{"Graficos de cajas"}\NormalTok{)}
\FunctionTok{title}\NormalTok{(}\StringTok{"Gráficos de cajas"}\NormalTok{) }\CommentTok{\# Corregir fallo del comando anterior}
\FunctionTok{plot}\NormalTok{(vario.s, }\AttributeTok{main=}\StringTok{"Variograma suavizado"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{12-geor_files/figure-latex/plot-variog2-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar) }\CommentTok{\# Restaurar opciones de gráficos}
\end{Highlighting}
\end{Shaded}

Si hay valores atípicos (o la distribución de los datos es asimétrica)
puede ser preferible utilizar el estimador robusto. Se puede
calcular este estimador estableciendo \texttt{estimator.type\ =\ "modulus"}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{varior.b }\OtherTok{\textless{}{-}} \FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{estimator.type =} \StringTok{"modulus"}\NormalTok{, }\AttributeTok{max.dist=}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{varior.bc }\OtherTok{\textless{}{-}} \FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{estimator.type =} \StringTok{"modulus"}\NormalTok{, }\AttributeTok{max.dist=}\FloatTok{0.6}\NormalTok{, }\AttributeTok{bin.cloud=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oldpar}\OtherTok{\textless{}{-}}\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)) }\CommentTok{\#Preparar para 4 gráficos por ventana}
\FunctionTok{plot}\NormalTok{(vario.b, }\AttributeTok{main=}\StringTok{"Estimador clásico"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(varior.b, }\AttributeTok{main=}\StringTok{"Estimador robusto"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(vario.bc, }\AttributeTok{bin.cloud=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(varior.bc, }\AttributeTok{bin.cloud=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{12-geor_files/figure-latex/plot-variog3-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar) }\CommentTok{\#Restaurar opciones de gráficos}
\end{Highlighting}
\end{Shaded}

En el caso de anisotropía, también se pueden obtener variogramas direccionales con la función
\texttt{variog} mediante los argumentos \texttt{direction} y \texttt{tolerance}. Por ejemplo,
para calcular un variograma en la dirección de 60 grados (con la
tolerancia angular por defecto de 22.5 grados):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario}\FloatTok{.60} \OtherTok{\textless{}{-}} \FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{, }\AttributeTok{direction =}\NormalTok{ pi}\SpecialCharTok{/}\DecValTok{3}\NormalTok{) }\CommentTok{\#variograma en la dirección de 60 grados}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing variogram for direction = 60 degrees (1.047 radians)
##         tolerance angle = 22.5 degrees (0.393 radians)
\end{verbatim}

Para estudiar si hay anisotropía, se pueden cálcular de forma rápida variogramas
direccionales con la función \texttt{variog4}. Por defecto calcula cuatro variogramas
direccionales, correspondientes a los ángulos 0, 45, 90 y 135 grados:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario}\FloatTok{.4} \OtherTok{\textless{}{-}} \FunctionTok{variog4}\NormalTok{(s100, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing variogram for direction = 0 degrees (0 radians)
##         tolerance angle = 22.5 degrees (0.393 radians)
## variog: computing variogram for direction = 45 degrees (0.785 radians)
##         tolerance angle = 22.5 degrees (0.393 radians)
## variog: computing variogram for direction = 90 degrees (1.571 radians)
##         tolerance angle = 22.5 degrees (0.393 radians)
## variog: computing variogram for direction = 135 degrees (2.356 radians)
##         tolerance angle = 22.5 degrees (0.393 radians)
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(vario}\FloatTok{.60}\NormalTok{)}
\FunctionTok{title}\NormalTok{(}\AttributeTok{main =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"direccional, angulo = "}\NormalTok{, }\DecValTok{60} \SpecialCharTok{*}\NormalTok{ degree)))}
\FunctionTok{plot}\NormalTok{(vario}\FloatTok{.4}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{12-geor_files/figure-latex/plot-variog4-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

\hypertarget{geor-ajuste}{%
\subsection{Ajuste de un modelo de variograma}\label{geor-ajuste}}

Los estimadores empíricos no pueden ser empleados en la práctica (no
verifican necesariamente las propiedades de un variograma válido), por
lo que se suele recurrir en la práctica al ajuste de un modelo válido.
Con el paquete \texttt{geoR} podemos realizar el ajuste:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  ``A ojo'': representando diferentes modelos sobre un variograma
  empírico (usando la función \texttt{lines.variomodel} o la función
  \texttt{eyefit}).
\item
  Por mínimos cuadrados: ajustando por mínimos cuadrados
  ordinarios (OSL) o ponderados (WLS) al variograma empírico (usando
  la función \texttt{variofit}),
\item
  Por máxima verosimilitud: estimando por máxima verosimilitud (ML) o
  máxima verosimilitud restringida (REML) los parámetros a partir de
  los datos (utilizando la función \texttt{likfit}),
\item
  Métodos bayesianos (utilizando la función \texttt{krige.bayes}).
\end{enumerate}

Ejemplo de ajuste ``a ojo'':

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario.b }\OtherTok{\textless{}{-}} \FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{max.dist=}\FloatTok{0.6}\NormalTok{) }\CommentTok{\#discretizado}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario.s }\OtherTok{\textless{}{-}} \FunctionTok{variog}\NormalTok{(s100, }\AttributeTok{max.dist=}\FloatTok{0.6}\NormalTok{,}\AttributeTok{option =} \StringTok{"smooth"}\NormalTok{, }\AttributeTok{kernel =} \StringTok{"normal"}\NormalTok{, }\AttributeTok{band =} \FloatTok{0.2}\NormalTok{)  }\CommentTok{\#suavizado}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(vario.b)}
\FunctionTok{lines}\NormalTok{(vario.s, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}

\FunctionTok{lines.variomodel}\NormalTok{(}\AttributeTok{cov.model =} \StringTok{"exp"}\NormalTok{, }\AttributeTok{cov.pars =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\FloatTok{0.3}\NormalTok{), }\AttributeTok{nugget =} \DecValTok{0}\NormalTok{, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"empirico"}\NormalTok{, }\StringTok{"suavizado"}\NormalTok{, }\StringTok{"modelo exponencial"}\NormalTok{), }\AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{lwd =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-11-1} \end{center}

Otros ajustes:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(vario.b)}
\FunctionTok{lines.variomodel}\NormalTok{(}\AttributeTok{cov.model =} \StringTok{"exp"}\NormalTok{, }\AttributeTok{cov.pars =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.9}\NormalTok{,}\FloatTok{0.3}\NormalTok{), }\AttributeTok{nug =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{)}
\FunctionTok{lines.variomodel}\NormalTok{(}\AttributeTok{cov.model =} \StringTok{"mat"}\NormalTok{, }\AttributeTok{cov.pars =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.85}\NormalTok{,}\FloatTok{0.2}\NormalTok{), }\AttributeTok{nug =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{kappa =} \DecValTok{1}\NormalTok{, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{,}\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{lines.variomodel}\NormalTok{(}\AttributeTok{cov.model =} \StringTok{"sph"}\NormalTok{, }\AttributeTok{cov.pars =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.8}\NormalTok{,}\FloatTok{0.8}\NormalTok{), }\AttributeTok{nug =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-12-1} \end{center}

Nota: no hace falta escribir el nombre completo de los parámetros
(basta con que no dé lugar a confusión).

En las versiones recientes de \texttt{geoR} está disponible una función para
realizar el ajuste gráficamente de forma interactiva
(cuadro de diálogo en tcl/tk):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{eyefit}\NormalTok{(vario.b)}
\end{Highlighting}
\end{Shaded}

Cuando se utilizan las funciones \texttt{variofit} y \texttt{likfit} para la
estimación de parámetros, el efecto pepita (nugget) puede ser estimado o
establecido a un valor fijo. Lo mismo ocurre con los parámetros de
suavidad, anisotropía y transformación de los datos. También se dispone
de opciones para incluir una tendencia. Las tendencias pueden ser
polinomios en función de las coordenadas y/o funciones lineales de otras
covariables.

Ejemplos de estimación por mínimos cuadrados (llamadas a \texttt{variofit}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#   Modelo exponencial con par ini umbral 1 y escala 0.5 (1/3 rango = 1.5)}
\NormalTok{vario.ols }\OtherTok{\textless{}{-}} \FunctionTok{variofit}\NormalTok{(vario.b, }\AttributeTok{ini =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{), }\AttributeTok{weights =} \StringTok{"equal"}\NormalTok{)  }\CommentTok{\#ordinarios}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variofit: covariance model used is matern 
## variofit: weights used: equal 
## variofit: minimisation function used: optim
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario.wls }\OtherTok{\textless{}{-}} \FunctionTok{variofit}\NormalTok{(vario.b, }\AttributeTok{ini =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{), }\AttributeTok{weights =} \StringTok{"cressie"}\NormalTok{)  }\CommentTok{\#ponderados}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variofit: covariance model used is matern 
## variofit: weights used: cressie 
## variofit: minimisation function used: optim
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario.wls}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variofit: model parameters estimated by WLS (weighted least squares):
## covariance model is: matern with fixed kappa = 0.5 (exponential)
## parameter estimates:
##   tausq sigmasq     phi 
##  0.1955  2.0110  1.4811 
## Practical Range with cor=0.05 for asymptotic range: 4.437092
## 
## variofit: minimised weighted sum of squares = 31.5115
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(vario.wls)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $pmethod
## [1] "WLS (weighted least squares)"
## 
## $cov.model
## [1] "matern"
## 
## $spatial.component
##  sigmasq      phi 
## 2.010972 1.481138 
## 
## $spatial.component.extra
## kappa 
##   0.5 
## 
## $nugget.component
##     tausq 
## 0.1955322 
## 
## $fix.nugget
## [1] FALSE
## 
## $fix.kappa
## [1] TRUE
## 
## $practicalRange
## [1] 4.437092
## 
## $sum.of.squares
##   value 
## 31.5115 
## 
## $estimated.pars
##     tausq   sigmasq       phi 
## 0.1955322 2.0109718 1.4811376 
## 
## $weights
## [1] "cressie"
## 
## $call
## variofit(vario = vario.b, ini.cov.pars = c(1, 0.5), weights = "cressie")
## 
## attr(,"class")
## [1] "summary.variomodel"
\end{verbatim}

Ejemplo de estimación por máxima verosimilitud (llamada a \texttt{likfit}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario.ml }\OtherTok{\textless{}{-}} \FunctionTok{likfit}\NormalTok{(s100, }\AttributeTok{ini =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)) }\CommentTok{\#Modelo exponencial con par ini umbral y escala (1/3 rango)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ---------------------------------------------------------------
## likfit: likelihood maximisation using the function optim.
## likfit: Use control() to pass additional
##          arguments for the maximisation function.
##         For further details see documentation for optim.
## likfit: It is highly advisable to run this function several
##         times with different initial values for the parameters.
## likfit: WARNING: This step can be time demanding!
## ---------------------------------------------------------------
## likfit: end of numerical maximisation.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario.ml}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## likfit: estimated model parameters:
##     beta    tausq  sigmasq      phi 
## "0.7766" "0.0000" "0.7517" "0.1827" 
## Practical Range with cor=0.05 for asymptotic range: 0.547383
## 
## likfit: maximised log-likelihood = -83.57
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(vario.ml)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Summary of the parameter estimation
## -----------------------------------
## Estimation method: maximum likelihood 
## 
## Parameters of the mean component (trend):
##   beta 
## 0.7766 
## 
## Parameters of the spatial component:
##    correlation function: exponential
##       (estimated) variance parameter sigmasq (partial sill) =  0.7517
##       (estimated) cor. fct. parameter phi (range parameter)  =  0.1827
##    anisotropy parameters:
##       (fixed) anisotropy angle = 0  ( 0 degrees )
##       (fixed) anisotropy ratio = 1
## 
## Parameter of the error component:
##       (estimated) nugget =  0
## 
## Transformation parameter:
##       (fixed) Box-Cox parameter = 1 (no transformation)
## 
## Practical Range with cor=0.05 for asymptotic range: 0.547383
## 
## Maximised Likelihood:
##    log.L n.params      AIC      BIC 
## "-83.57"      "4"  "175.1"  "185.6" 
## 
## non spatial model:
##    log.L n.params      AIC      BIC 
## "-125.8"      "2"  "255.6"  "260.8" 
## 
## Call:
## likfit(geodata = s100, ini.cov.pars = c(1, 0.5))
\end{verbatim}

Ejemplo de estimación por máxima verosimilitud restringida (opción de
\texttt{likfit}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vario.reml }\OtherTok{\textless{}{-}} \FunctionTok{likfit}\NormalTok{(s100, }\AttributeTok{ini =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{), }\AttributeTok{lik.method =} \StringTok{"RML"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ---------------------------------------------------------------
## likfit: likelihood maximisation using the function optim.
## likfit: Use control() to pass additional
##          arguments for the maximisation function.
##         For further details see documentation for optim.
## likfit: It is highly advisable to run this function several
##         times with different initial values for the parameters.
## likfit: WARNING: This step can be time demanding!
## ---------------------------------------------------------------
## likfit: end of numerical maximisation.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(vario.reml)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Summary of the parameter estimation
## -----------------------------------
## Estimation method: restricted maximum likelihood 
## 
## Parameters of the mean component (trend):
##   beta 
## 0.7478 
## 
## Parameters of the spatial component:
##    correlation function: exponential
##       (estimated) variance parameter sigmasq (partial sill) =  0.8473
##       (estimated) cor. fct. parameter phi (range parameter)  =  0.2102
##    anisotropy parameters:
##       (fixed) anisotropy angle = 0  ( 0 degrees )
##       (fixed) anisotropy ratio = 1
## 
## Parameter of the error component:
##       (estimated) nugget =  0
## 
## Transformation parameter:
##       (fixed) Box-Cox parameter = 1 (no transformation)
## 
## Practical Range with cor=0.05 for asymptotic range: 0.6296295
## 
## Maximised Likelihood:
##    log.L n.params      AIC      BIC 
## "-81.53"      "4"  "171.1"  "181.5" 
## 
## non spatial model:
##    log.L n.params      AIC      BIC 
## "-125.1"      "2"  "254.1"  "259.3" 
## 
## Call:
## likfit(geodata = s100, ini.cov.pars = c(1, 0.5), lik.method = "RML")
\end{verbatim}

\textbf{NOTAS}:

\begin{itemize}
\item
  Para fijar el nugget a un valor p.e. 0.15 añadir las opciones:
  \texttt{fix.nugget\ =\ TRUE,\ nugget\ =\ 0.15}.
\item
  Se puede tener en cuenta anisotropía geométrica en los modelos de
  variograma a partir de los parámetros \texttt{psiA} (ángulo, en radianes,
  de la dirección de mayor dependencia espacial i.e.~con el
  máximo rango) y \texttt{psiR} (relación, mayor o igual que 1, entre los
  rangos máximo y mínimo). Se pueden fijar a distintos valores o
  estimarlos incluyendo las opciones \texttt{fix.psiA\ =\ FALSE} y \texttt{fix.psiR\ =\ \ \ \ \ FALSE} en las llamadas a las rutinas de ajuste.)
\end{itemize}

Representación gráfica junto al estimador empírico:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(vario.b, }\AttributeTok{main =} \StringTok{"Estimador empírico y modelos ajustados"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(vario.ml, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(vario.reml, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(vario.ols, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(vario.wls, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"ML"}\NormalTok{, }\StringTok{"REML"}\NormalTok{, }\StringTok{"OLS"}\NormalTok{, }\StringTok{"WLS"}\NormalTok{), }\AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{lwd =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-17-1} \end{center}

\hypertarget{inferencia-sobre-el-variograma}{%
\subsection{Inferencia sobre el variograma}\label{inferencia-sobre-el-variograma}}

Se pueden obtener dos tipos de envolventes (envelopes, i.e.~valores
máximos y mínimos aproximados) del variograma empírico mediante
simulación:

\begin{itemize}
\item
  Bajo la hipótesis de que no hay correlación espacial (obtenidos por
  permutaciones aleatorias de los datos sobre las posiciones
  espaciales), para estudiar si hay una dependencia
  espacial ``significativa''.
\item
  Bajo un modelo de variograma, para ilustrar la variabilidad del
  variograma empírico.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{env.indep }\OtherTok{\textless{}{-}} \FunctionTok{variog.mc.env}\NormalTok{(s100, }\AttributeTok{obj.var =}\NormalTok{ vario.b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog.env: generating 99 simulations by permutating data values
## variog.env: computing the empirical variogram for the 99 simulations
## variog.env: computing the envelops
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{env.model }\OtherTok{\textless{}{-}} \FunctionTok{variog.model.env}\NormalTok{(s100, }\AttributeTok{obj.var =}\NormalTok{ vario.b, }\AttributeTok{model =}\NormalTok{ vario.wls)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog.env: generating 99 simulations (with  100 points each) using the function grf
## variog.env: adding the mean or trend
## variog.env: computing the empirical variogram for the 99 simulations
## variog.env: computing the envelops
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(vario.b, }\AttributeTok{envelope =}\NormalTok{ env.indep)}
\FunctionTok{plot}\NormalTok{(vario.b, }\AttributeTok{envelope =}\NormalTok{ env.model)}
\FunctionTok{lines}\NormalTok{(vario.wls, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{max.dist =} \FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{12-geor_files/figure-latex/plot-variog-env-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)     }
\end{Highlighting}
\end{Shaded}

Para estudiar si hay una dependencia espacial ``significativa'' se puede
emplear también la rutina \texttt{sm.variogram} del paquete \texttt{sm}.
Estableciendo \texttt{model\ =\ "independent"}
devuelve un p-valor para contrastar la hipótesis nula de independencia
(i.e.~se acepta que hay una dependencia espacial si \(p \leq \alpha = 0.05\))
y un gráfico en el que se muestra el estimador empírico robusto, un estimador
suavizado y una región de confianza para el variograma suponiendo que el
proceso es independiente (i.e.~consideraríamos que hay dependencia
espacial si el variograma suavizado no está contenido en esa región).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sm)}
\FunctionTok{sm.variogram}\NormalTok{(s100}\SpecialCharTok{$}\NormalTok{coords, s100}\SpecialCharTok{$}\NormalTok{data, }\AttributeTok{model =} \StringTok{"independent"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Test of spatial independence: p =  0.024
\end{verbatim}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-18-1} \end{center}

\textbf{Nota}: Se puede realizar contrastes adicionales estableciendo el parámetro \texttt{model}
a \texttt{"isotropic"} o \texttt{"stationary"}.

\hypertarget{estimaciuxf3n-del-variograma-en-procesos-no-estacionarios}{%
\subsection{Estimación del variograma en procesos no estacionarios}\label{estimaciuxf3n-del-variograma-en-procesos-no-estacionarios}}

Cuando el proceso no es estacionario (no se puede emplear directamente los
estimadores empíricos) hay que eliminar la tendencia para estimar el variograma:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)) }
\FunctionTok{plot}\NormalTok{(}\FunctionTok{variog}\NormalTok{(wolfcamp, }\AttributeTok{max.dist =} \DecValTok{200}\NormalTok{)) }\CommentTok{\# Supone que el proceso es estacionario}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{variog}\NormalTok{(wolfcamp, }\AttributeTok{trend =} \SpecialCharTok{\textasciitilde{}}\NormalTok{coords, }\AttributeTok{max.dist =} \DecValTok{200}\NormalTok{)) }\CommentTok{\# Asume una tendencia lineal en las coordenadas}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## variog: computing omnidirectional variogram
\end{verbatim}

\begin{center}\includegraphics[width=0.8\linewidth]{12-geor_files/figure-latex/plot-variog-wolf-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicciuxf3n-espacial-kriging}{%
\section{Predicción espacial (kriging)}\label{predicciuxf3n-espacial-kriging}}

El paquete \texttt{geoR} dispone de opciones para los métodos kriging
tradicionales, que dependiendo de las suposiciones acerca de la función
de tendencia se clasifican en:

\begin{itemize}
\item
  \emph{Kriging simple} (\textbf{KS}): media conocida
\item
  \emph{Kriging ordinario} (\textbf{KO}): se supone que la media es constante
  y desconocida.
\item
  \emph{Kriging universal} (\textbf{KU}): también denominado kriging con modelo de
  tendencia, se supone que la media es una combinación
  lineal (desconocida) de las coordenadas o de otras
  variables explicativas.
\end{itemize}

Existen también opciones adicionales para kriging trans-normal (con
transformaciones Box-Cox para aproximarse a la normalidad y
transformación de nuevo de resultados a la escala original manteniendo
insesgadez). También admite modelos de variograma geométricamente
anisotrópicos.

Para obtener una rejilla discreta de predicción puede ser de utilidad la
función \texttt{expand.grid}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Rejilla regular 51x51 en cuadrado unidad}
\NormalTok{xx }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{l =} \DecValTok{51}\NormalTok{)}
\NormalTok{yy }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{l =} \DecValTok{51}\NormalTok{)}
\NormalTok{pred.grid }\OtherTok{\textless{}{-}} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{x =}\NormalTok{ xx, }\AttributeTok{y =}\NormalTok{ yy) }
\FunctionTok{plot}\NormalTok{(s100}\SpecialCharTok{$}\NormalTok{coords, }\AttributeTok{pch =} \DecValTok{20}\NormalTok{, }\AttributeTok{asp =} \DecValTok{1}\NormalTok{)}
\FunctionTok{points}\NormalTok{(pred.grid, }\AttributeTok{pch =} \DecValTok{3}\NormalTok{, }\AttributeTok{cex =} \FloatTok{0.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-19-1} \end{center}

El comando para realizar kriging ordinario con variograma \texttt{vario.wls}
sería:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ko.wls }\OtherTok{\textless{}{-}} \FunctionTok{krige.conv}\NormalTok{(s100, }\AttributeTok{loc =}\NormalTok{ pred.grid, }\AttributeTok{krige =} \FunctionTok{krige.control}\NormalTok{(}\AttributeTok{obj.m =}\NormalTok{ vario.wls))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## krige.conv: model with constant mean
## krige.conv: Kriging performed using global neighbourhood
\end{verbatim}

El resultado es una lista incluyendo predicciones (\texttt{ko.wls\$predict}) y
varianzas kriging (\texttt{ko.wls\$krige.var}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(ko.wls)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "predict"      "krige.var"    "beta.est"     "distribution" "message"     
## [6] "call"
\end{verbatim}

Para ver todas las opciones de kriging disponibles ejecutar
\texttt{?krige.control}. Para kriging con vecindario local (archivos de datos
grandes) se puede utilizar la función \texttt{ksline}.

Para representar las superficies se podría utilizar la función \texttt{image()},
aunque la última versión del método \texttt{image.kriging()} puede fallar al añadir
elementos (por lo menos en RMarkdown; tampoco es compatible con \texttt{par(mfrow)}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# oldpar \textless{}{-} par(mfrow = c(1, 2)) }
\CommentTok{\# image.kriging no es compatible con mfrow en últimas versiones}
\FunctionTok{image}\NormalTok{(ko.wls, }\AttributeTok{coords.data=}\NormalTok{s100}\SpecialCharTok{$}\NormalTok{coords, }\AttributeTok{main =} \StringTok{"Superficie de predicciones"}\NormalTok{)}
\FunctionTok{contour}\NormalTok{(ko.wls, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\#añadir gráfico de contorno}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-22-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{image}\NormalTok{(ko.wls, }\AttributeTok{coords.data=}\NormalTok{s100}\SpecialCharTok{$}\NormalTok{coords, }\AttributeTok{values =} \FunctionTok{sqrt}\NormalTok{(ko.wls}\SpecialCharTok{$}\NormalTok{krige.var), }\AttributeTok{main =} \StringTok{"Superficie de err. std. kriging"}\NormalTok{) }
\FunctionTok{contour}\NormalTok{(ko.wls, }\AttributeTok{values =} \FunctionTok{sqrt}\NormalTok{(ko.wls}\SpecialCharTok{$}\NormalTok{krige.var), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-22-2} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# par(oldpar)}
\end{Highlighting}
\end{Shaded}

Otras opciones:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{contour}\NormalTok{(ko.wls,}\AttributeTok{filled =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-23-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fcol }\OtherTok{\textless{}{-}} \FunctionTok{topo.colors}\NormalTok{(}\DecValTok{10}\NormalTok{)[}\FunctionTok{cut}\NormalTok{(}\FunctionTok{matrix}\NormalTok{(ko.wls}\SpecialCharTok{$}\NormalTok{pred,}\AttributeTok{nrow=}\DecValTok{51}\NormalTok{,}\AttributeTok{ncol=}\DecValTok{51}\NormalTok{)[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{],}\DecValTok{10}\NormalTok{,}\AttributeTok{include.lowest=}\ConstantTok{TRUE}\NormalTok{)]}
\FunctionTok{persp}\NormalTok{(ko.wls, }\AttributeTok{theta=}\SpecialCharTok{{-}}\DecValTok{60}\NormalTok{, }\AttributeTok{phi=}\DecValTok{40}\NormalTok{, }\AttributeTok{col=}\NormalTok{fcol)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-23-2} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{require}\NormalTok{(plot3D)) }
  \FunctionTok{stop}\NormalTok{(}\StringTok{\textquotesingle{}Required pakage \textasciigrave{}plot3D\textasciigrave{} not installed.\textquotesingle{}}\NormalTok{) }\CommentTok{\# install.packages(\textquotesingle{}plot3D\textquotesingle{})}

\FunctionTok{persp3D}\NormalTok{(xx, yy, }\FunctionTok{matrix}\NormalTok{(ko.wls}\SpecialCharTok{$}\NormalTok{predict, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(xx)), }\AttributeTok{theta=}\SpecialCharTok{{-}}\DecValTok{60}\NormalTok{, }\AttributeTok{phi=}\DecValTok{40}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-23-3} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{require}\NormalTok{(npsp)) \{}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"Required pakage \textasciigrave{}npsp\textasciigrave{} not installed!}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)   }
  \FunctionTok{cat}\NormalTok{(}\StringTok{"On windows, run \textasciigrave{}install.packages(\textquotesingle{}https://github.com/rubenfcasal/npsp/releases/download/v0.7{-}8/npsp\_0.7{-}8.zip\textquotesingle{}, repos = NULL)\textasciigrave{}}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)  }
\NormalTok{\} }\ControlFlowTok{else}  
  \FunctionTok{spersp}\NormalTok{(xx, yy, ko.wls}\SpecialCharTok{$}\NormalTok{predict, }\AttributeTok{theta=}\SpecialCharTok{{-}}\DecValTok{60}\NormalTok{, }\AttributeTok{phi=}\DecValTok{40}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{12-geor_files/figure-latex/unnamed-chunk-23-4} \end{center}

\hypertarget{validaciuxf3n-cruzada}{%
\subsection{Validación cruzada}\label{validaciuxf3n-cruzada}}

Para verificar si un modelo (de tendencia y variograma) describe adecuadamente
la variabilidad espacial de los datos (p.e. para comparar modelos), se emplea
normalmente la técnica de validación cruzada, función \texttt{xvalid} en \texttt{geoR}.
Por defecto la validación se realiza sobre los datos eliminando cada
observación (y utilizando las restantes para predecir), aunque se puede
utilizar un conjunto diferente de posiciones (o de datos) mediante el
argumento \texttt{location.xvalid} (y \texttt{data.xvalid}).

En el caso de procesos estacionarios permitiría diagnosticar si el modelo de
variograma describe adecuadamente la dependencia espacial de los datos:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xv.wls }\OtherTok{\textless{}{-}} \FunctionTok{xvalid}\NormalTok{(s100, }\AttributeTok{model =}\NormalTok{ vario.wls)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## xvalid: number of data locations       = 100
## xvalid: number of validation locations = 100
## xvalid: performing cross-validation at location ... 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 
## xvalid: end of cross-validation
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(xv.wls)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 Min.    1st Qu.     Median         Mean   3rd Qu.     Max.
## errors     -1.429944 -0.4017821 0.04881742 0.0008450629 0.3359677 1.319640
## std.errors -2.110654 -0.7048560 0.07804159 0.0011568059 0.5922810 2.228054
##                   sd
## errors     0.5299818
## std.errors 0.9190753
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xv.reml }\OtherTok{\textless{}{-}} \FunctionTok{xvalid}\NormalTok{(s100, }\AttributeTok{model =}\NormalTok{ vario.reml)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## xvalid: number of data locations       = 100
## xvalid: number of validation locations = 100
## xvalid: performing cross-validation at location ... 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 
## xvalid: end of cross-validation
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(xv.reml)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 Min.    1st Qu.     Median        Mean   3rd Qu.     Max.
## errors     -1.178020 -0.3109277 0.02326020 0.011894019 0.2631596 1.521489
## std.errors -2.419106 -0.7304294 0.07954355 0.009241635 0.5802049 2.690047
##                   sd
## errors     0.4813133
## std.errors 0.9906166
\end{verbatim}

Por defecto la función \texttt{plot} (\texttt{plot.xvalid}) muestra 10 gráficos
diferentes (para más información ejecutar \texttt{?plot.xvalid}), a grosso modo
los cinco primeros se corresponden con residuos simples (valores
observados menos predicciones) y los siguientes con residuos
estandarizados (dividiendo por la raíz cuadrada de la varianza de
predicción).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\AttributeTok{bottom =} \FloatTok{4.5}\NormalTok{, }\AttributeTok{left =} \DecValTok{4}\NormalTok{, }\AttributeTok{top =} \DecValTok{2}\NormalTok{, }\AttributeTok{right =} \DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(xv.wls, }\AttributeTok{ask =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=1\linewidth]{12-geor_files/figure-latex/plot-xvalid-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}

\CommentTok{\# plot(xv.reml)}
\end{Highlighting}
\end{Shaded}

\textbf{NOTA}: Para re-estimar los parámetros del modelo cada vez que se
elimina una observación (i.e.~validar el procedimiento de estimación)
añadir la opción \texttt{reest\ =\ TRUE} (puede requerir mucho tiempo de
computación).

\hypertarget{gls}{%
\chapter{Mínimos cuadrados generalizados en R}\label{gls}}

Uno de los modelos más utilizados en estadística para el caso de datos no homogéneos es el conocido modelo clásico de regresión lineal:
\[Y =\sum\limits_{j=0}^{p}X_{j}\beta_{j} +\varepsilon,\]
donde \(\boldsymbol{\beta }=(\beta_{0}, \ldots,\beta_{p})^{\top}\in \mathbb{R}^{p+1}\) es un vector desconocido, \(\left\{ X_{j}:j=0, \ldots,p\right\}\) un conjunto de variables explicativas (por comodidad asumiremos que \(X_0=1\)) y \(\varepsilon\) un error aleatorio (independiente) de media cero con \(Var(\varepsilon)=\sigma^{2}\).

Supongamos que el objetivo es la estimación eficiente de los parámetros de \(\boldsymbol{\beta}\) (\emph{variación de gran escala}), a partir de una muestra aleatoria simple (los datos observados)
\[\left\{ \left( {X_1}_i, \ldots, {X_p}_i, Y_{i} \right)  : i = 1, \ldots, n \right\}.\]
Bajo las hipótesis anteriores:
\[\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon},\]
siendo \(\mathbf{Y}=\left( Y_1, \ldots, Y_n \right)^{\top}\), \(\mathbf{X}\) una matriz \(n\times (p+1)\) con \(\mathbf{X}_{ij} = {X_{(j-1)}}_i\) y \(\boldsymbol{\varepsilon} = \left( \varepsilon_1, \ldots,\varepsilon_n \right)^{\top}\), con
\[Var\left( \mathbf{Y} \right) =Var\left( \boldsymbol{\varepsilon} \right) = \sigma^{2} \mathbf{I}_{n},\]
siendo \(\mathbf{I}_{n}\) la matriz identidad \(n\times n\).
En estas condiciones el estimador lineal insesgado de \(\boldsymbol{\beta}\) más eficiente (el óptimo bajo normalidad) resulta ser el estimador de mínimos cuadrados ordinarios (OLS, \emph{ordinary least squares}):
\begin{equation} 
  \hat{\boldsymbol{\beta}}_{ols}=(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^{\top}\mathbf{Y},
  \label{eq:beta-ols-rlm}
\end{equation}
que se obtiene al minimizar la correspondiente suma de cuadrados
\[\hat{\boldsymbol{\beta}}_{ols} = \arg \min_{\mathbf{\beta }}\left( \mathbf{Y}-\mathbf{X}\mathbf{\beta }\right)^{\top }\left( \mathbf{Y}-\mathbf{X}\mathbf{\beta }\right)\]
o al maximizar la verosimilitud asumiendo normalidad.
Además, puede verse fácilmente que
\[Var(\hat{\boldsymbol{\beta}}_{ols})=\sigma^{2}(\mathbf{X}^{\top}\mathbf{X})^{-1}.\]

Sin embargo la suposición de que los errores son independientes e idénticamente distribuidos influye crucialmente en la inferencia.
En el modelo anterior, en lugar de errores incorrelados, si suponemos que:
\[Var\left( \boldsymbol{\varepsilon} \right) =\boldsymbol{\Sigma},\]
obtenemos el modelo lineal de regresión generalizado y en este caso el estimador lineal óptimo de \(\boldsymbol{\beta}\) es el estimador de mínimos cuadrados generalizados (GLS, \emph{generalized least squares}; WLS, \emph{weighted least squares}, como caso particular si la matriz de covarianzas es diagonal):
\begin{equation} 
  \hat{\boldsymbol{\beta}}_{gls} =(\mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{X})^{-1} \mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{Y}.
  \label{eq:beta-gls-rlm}
\end{equation}

Podemos ver cómo se obtiene este estimador desde varios puntos de vista.
Uno de ellos es aplicar una transformación lineal a los datos de forma que sean incorrelados y tenga sentido aplicar el estimador OLS.
Para ello se emplea una factorización de la matriz de covarianzas (ver p.e. la \href{https://rubenfcasal.github.io/simbook/fact-cov.html}{Sección 7.3} de Fernández-Casal y Cao, 2021), por ejemplo la factorización de Cholesky:
\[\boldsymbol{\Sigma} = L L^\top,\]
donde \(L\) es una matriz triangular inferior (fácilmente invertible), por lo que:
\[\begin{aligned}
Var\left( L^{-1}\mathbf{Y} \right) & =Var\left( L^{-1}\boldsymbol{\varepsilon} \right) = L^{-1} \boldsymbol{\Sigma} L^{{-1}^\top} \\
&= L^{-1} LL^\top L^{\top^{-1}} = \mathbf{I}_{n}.
\end{aligned}\]
Aplicando esta transformación al modelo anterior:
\[\begin{aligned}
L^{-1}\mathbf{Y} &= L^{-1}\mathbf{X}\boldsymbol{\beta} + L^{-1}\boldsymbol{\varepsilon}\\
\tilde{\mathbf{Y}} &= \tilde{\mathbf{X}}\boldsymbol{\beta} + \tilde{\boldsymbol{\varepsilon}},
\end{aligned}\]
como \(Var(\tilde{\boldsymbol{\varepsilon}}) = Var\left( L^{-1}\boldsymbol{\varepsilon} \right) = \mathbf{I}_{n}\), al minimizar la suma de cuadrados
\[\left( \tilde{\mathbf{Y}}-\tilde{\mathbf{X}}\mathbf{\beta }\right)^{\top }\left( \tilde{\mathbf{Y}}-\tilde{\mathbf{X}}\mathbf{\beta }\right) \\ 
= \left( L^{-1}\mathbf{Y}-L^{-1}\mathbf{X}\mathbf{\beta }\right)^{\top }\left( L^{-1}\mathbf{Y}-L^{-1}\mathbf{X}\mathbf{\beta }\right) \\
= \left( \mathbf{Y}-\mathbf{X}\mathbf{\beta }\right)^{\top } L^{{-1}^\top}L^{-1}  \left( \mathbf{Y}-\mathbf{X}\mathbf{\beta }\right) \\
= \left( \mathbf{Y}-\mathbf{X}\mathbf{\beta }\right)^{\top } \boldsymbol{\Sigma}^{-1}\left( \mathbf{Y}-\mathbf{X}\mathbf{\beta }\right)\]
obtenemos el estimador lineal óptimo:
\[\begin{aligned}
\hat{\boldsymbol{\beta}}_{gls} &=(\tilde{\mathbf{X}}^{\top}\tilde{\mathbf{X}})^{-1}\tilde{\mathbf{X}}^{\top}\tilde{\mathbf{Y}} \\
&=\left(\left( L^{-1}\mathbf{X}\right)^{\top}\left( L^{-1}\mathbf{X}\right)\right)^{-1}\left( L^{-1}\mathbf{X}\right)^{\top}L^{-1}\mathbf{Y} \\
&= \left(\mathbf{X}^{\top}L^{{-1}^\top}L^{-1} \mathbf{X}\right)^{-1} \mathbf{X}^{\top}L^{{-1}^\top}L^{-1} \mathbf{Y} \\
&= (\mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{X})^{-1} \mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{Y}.
\end{aligned}\]

Si \(\boldsymbol{\Sigma}=\sigma^{2} \mathbf{I}_{n}\), los estimadores \eqref{eq:beta-ols-rlm} y \eqref{eq:beta-gls-rlm} coinciden; pero en caso contrario las estimaciones basadas en el modelo anterior pueden llegar a ser altamente ineficientes.
Puede verse fácilmente que en el caso general:
\[Var\left( \hat{\boldsymbol{\beta}}_{gls} \right)=(\mathbf{X}^{\top}\boldsymbol{\Sigma}^{-1} \mathbf{X})^{-1}, \\
Var\left( \hat{\boldsymbol{\beta}}_{ols} \right) =(\mathbf{X}^{\top}\mathbf{X})^{-1} (\mathbf{X}^{\top}\boldsymbol{\Sigma}\mathbf{X})(\mathbf{X}^{\top}\mathbf{X})^{-1},\]
resultando además que \(Var( \hat{\boldsymbol{\beta}}_{ols}) - Var( \hat{\boldsymbol{\beta}}_{gls} )\) es una matriz semidefinida positiva (e.g.~Searle, 1971, Sección 3.3).

En la práctica la matriz de covarianzas suele ser desconocida y habría que estimarla.
El procedimiento habitual, para evitar la estimación de \(n(n+1)/2\) parámetros adicionales a partir del
conjunto de \(n\) observaciones, suele ser asumir un modelo paramétrico adecuado (ver comentarios al final de la Sección \ref{modelos-clasicos-espaciales}).

Para más detalles, incluyendo el enfoque de máxima verosimilitud y su aplicación en la práctica para la regresión con series de tiempo, ver por ejemplo el apéndice \href{https://socialsciences.mcmaster.ca/jfox/Books/Companion/appendices/Appendix-Timeseries-Regression.pdf}{Time-Series Regression and Generalized Least Squares in R} de \href{https://socialsciences.mcmaster.ca/jfox/Books/Companion/}{Fox (2019)}.
La teoría para la estimación por máxima verosimilitud en el caso temporal (unidimensional) es totalmente análoga a la del caso espacial (multidimensional), descrita en la Sección \ref{ml-fit} (bajo la hipótesis habitual de normalidad).

\hypertarget{ejemplo-aquifer}{%
\chapter{Ejemplo de análisis geoestadístico}\label{ejemplo-aquifer}}

El objetivo es realizar un análisis geoestadístico del conjunto de datos \texttt{aquifer} (considerando como variable de interés \texttt{aquifer\$head} y asumiendo la presencia de una tendencia espacial lineal), siguiendo el procedimiento descrito en la Sección \ref{objetivos-esquema} (y en la introducción del Capítulo \ref{modelado}).

\hypertarget{carga-de-datos-y-creaciuxf3n-del-objeto-sf}{%
\section{\texorpdfstring{Carga de datos y creación del objeto \texttt{sf}:}{Carga de datos y creación del objeto sf:}}\label{carga-de-datos-y-creaciuxf3n-del-objeto-sf}}

En este caso, cómo es habitual, los datos están almacenados en un \texttt{data.frame} y la recomendación es emplear \texttt{st\_as\_sf()} para convertirlos a un objeto \texttt{sf} (Sección \ref{sf-intro}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"datos/aquifer.RData"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(sf)}
\NormalTok{aquifer}\SpecialCharTok{$}\NormalTok{head }\OtherTok{\textless{}{-}}\NormalTok{ aquifer}\SpecialCharTok{$}\NormalTok{head}\SpecialCharTok{/}\DecValTok{100} \CommentTok{\# en cientos de pies (escala más manejable...)}
\NormalTok{aquifer\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_as\_sf}\NormalTok{(aquifer, }\AttributeTok{coords =} \FunctionTok{c}\NormalTok{(}\StringTok{"lon"}\NormalTok{, }\StringTok{"lat"}\NormalTok{), }\AttributeTok{remove =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{agr =} \StringTok{"constant"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Por comodidad se establece \texttt{remove\ =\ FALSE} para mantener las coordenadas como posibles variables explicativas (el objeto con las observaciones debe contener todas las variables explicativas incluidas en el modelo de tendencia; también el objeto con las posiciones de predicción).

En caso necesario también habría que establecer el CRS (Sección \ref{crs}) e incluso podría ser necesario transformar los datos a coordenadas proyectadas mediante \texttt{st\_transform()}(Sección \ref{operaciones-geometrias}).

\hypertarget{anuxe1lisis-exploratorio}{%
\section{Análisis exploratorio}\label{anuxe1lisis-exploratorio}}

El primer paso es comenzar por un análisis exploratorio de los datos (Sección \ref{sp-eda}).
Nos centraremos en el modelado de los datos, pero seguramente interesaría analizar si hay datos atípicos\ldots{}

Estaríamos interesados en la simetría y normalidad de la respuesta (o del error).
Podríamos empezar por realizar un análisis descriptivo unidimensional:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ aquifer\_sf}\SpecialCharTok{$}\NormalTok{head}
\FunctionTok{summary}\NormalTok{(z)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   10.24   15.48   17.97   20.02   25.40   35.71
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(z, }\AttributeTok{xlab =} \StringTok{"piezometric{-}head"}\NormalTok{, }\AttributeTok{main =} \StringTok{""}\NormalTok{, }\AttributeTok{freq =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{density}\NormalTok{(z), }\AttributeTok{col =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-3-1} \end{center}

Nos interesaría estudiar si la media es constante o hay una tendencia espacial (analizar la variabilidad de gran escala).
Podríamos analizar la distribución espacial de los datos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(aquifer\_sf[}\StringTok{"head"}\NormalTok{], }\AttributeTok{pch =} \DecValTok{20}\NormalTok{, }\AttributeTok{cex =} \DecValTok{2}\NormalTok{, }\AttributeTok{breaks =} \StringTok{"quantile"}\NormalTok{, }\AttributeTok{nbreaks =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-4-1} \end{center}

y generar gráficos de dispersión de la respuesta frente a coordenadas (o frente a otras posibles variables explicativas):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ aquifer\_sf}\SpecialCharTok{$}\NormalTok{lon}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ aquifer\_sf}\SpecialCharTok{$}\NormalTok{lat}
\NormalTok{old.par }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{omd =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.05}\NormalTok{, }\FloatTok{0.95}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.95}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(x, z)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{lowess}\NormalTok{(x, z), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{col =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(y, z)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{lowess}\NormalTok{(y, z), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{col =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=1\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-5-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(old.par)}
\end{Highlighting}
\end{Shaded}

Como resultado de este análisis se propondría un modelo inicial para la tendencia
(incluyendo el caso de media constante, de la forma \texttt{respuesta\ \textasciitilde{}\ 1}, que se correspondería con el kriging ordinario).
En este caso parece razonable considerar (como punto de partida) un modelo lineal \texttt{head\ \textasciitilde{}\ lon\ +\ lat} para la tendencia (modelo del kriging universal).

Podríamos empezar por ajustar el modelo por OLS (cuidado con los resultados de inferencia, ya que en principio no sería razonable asumir que las observaciones son independientes y por ejemplo la varianza estaría subestimada) y analizar los residuos\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trend.ols }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(head }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lon }\SpecialCharTok{+}\NormalTok{ lat, }\AttributeTok{data =}\NormalTok{ aquifer\_sf)}
\FunctionTok{summary}\NormalTok{(trend.ols)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = head ~ lon + lat, data = aquifer_sf)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.6700 -1.6141 -0.3074  1.4823  6.5117 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 25.913266   0.389636   66.51   <2e-16 ***
## lon         -0.067519   0.003439  -19.64   <2e-16 ***
## lat         -0.059862   0.004066  -14.72   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.033 on 82 degrees of freedom
## Multiple R-squared:  0.892,  Adjusted R-squared:  0.8894 
## F-statistic: 338.8 on 2 and 82 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(trend.ols)}
\FunctionTok{summary}\NormalTok{(z)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -3.6700 -1.6141 -0.3074  0.0000  1.4823  6.5117
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(z, }\AttributeTok{xlab =} \StringTok{"ols residuals"}\NormalTok{, }\AttributeTok{main =} \StringTok{""}\NormalTok{, }\AttributeTok{freq =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{density}\NormalTok{(z), }\AttributeTok{col =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-6-1} \end{center}

El análisis de la variabilidad de pequeña escala se realizaría a través de las semivarianzas (clásicas o robustas, Sección \ref{vario-muestrales}), pero solo consideraremos los estimadores muestrales, para el modelado de la dependencia espacial.

\hypertarget{modelado-de-la-dependencia-1}{%
\section{Modelado de la dependencia}\label{modelado-de-la-dependencia-1}}

\hypertarget{estimaciuxf3n-experimental-del-variograma}{%
\subsection{Estimación experimental del variograma}\label{estimaciuxf3n-experimental-del-variograma}}

Como se muestra en la Sección \ref{vario-muestrales}, las estimaciones empíricas del semivariograma se obtienen con la función \href{https://r-spatial.github.io/gstat/reference/variogram.html}{\texttt{variogram()}}.

En el caso de tendencia no constante la estimación del variograma se haría a partir de los residuos, Sección \ref{trend-fit}, especificando la fórmula del modelo de tendencia como primer argumento de la función \texttt{variogram()} (si la tendencia es constante, la fórmula sería del tipo \texttt{respuesta\ \textasciitilde{}\ 1}, y la estimación del variograma se obtendría directamente de las observaciones).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gstat)}
\CommentTok{\# maxlag \textless{}{-} 0.5*sqrt(sum(diff(matrix(st\_bbox(aquifer\_sf), nrow = 2, byrow = TRUE))\^{}2))}
\NormalTok{maxlag }\OtherTok{\textless{}{-}} \DecValTok{150}
\NormalTok{vario }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(head }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lon }\SpecialCharTok{+}\NormalTok{ lat, aquifer\_sf, }\AttributeTok{cutoff =}\NormalTok{ maxlag)}
\CommentTok{\# por defecto considera 15 saltos (width = cutoff/15)}
\end{Highlighting}
\end{Shaded}

Habría que determinar el número de saltos (por defecto 15, \texttt{width\ =\ cutoff/15}) y el salto máximo (por defecto 1/3 del máximo salto posible) para la estimación del variograma (nos interesaría que fuese lo mejor posible cerca del origen).
Para seguir las recomendaciones de Journel y Huijbregts (1978), de considerar a lo sumo hasta la mitad del máximo salto posible (podría ser preferible menor) y saltos con aportaciones de al menos 30 pares de datos (se puede relajar cerca del origen), podemos representar las estimaciones junto con el número de aportaciones:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(vario, }\AttributeTok{plot.numbers =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-8-1} \end{center}

Si hay datos atípicos sería preferible emplear una versión robusta de este estimador.
Además, estamos asumiendo isotropía, aunque lo ideal sería asegurarse de que es una hipótesis razonable (ver comentarios al final de la Sección \ref{vario-muestrales} y Sección \ref{anisotropia}).

\hypertarget{ajuste-de-un-modelo-vuxe1lido}{%
\subsection{Ajuste de un modelo válido}\label{ajuste-de-un-modelo-vuxe1lido}}

El paso final en el modelado es el ajuste por WLS de un modelo válido (Sección \ref{ls-fit}; la recomendación es emplear pesos inversamente proporcionales a la varianza \texttt{fit.method\ =\ 2}).
En este caso un modelo de variograma esférico parece razonable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{nugget =} \ConstantTok{NA}\NormalTok{) }\CommentTok{\# Valores iniciales por defecto}
\CommentTok{\# modelo \textless{}{-} vgm(psill = 3, model = "Sph", range = 75, nugget = 0) \# Valores iniciales}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(vario, modelo, }\AttributeTok{fit.method =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

NOTA: Si aparecen problemas de convergencia se puede probar a cambiar los valores iniciales de los parámetros.

Imprimiendo el resultado del ajuste obtenemos las estimaciones de los parámetros, que podríamos interpretar (ver Sección \ref{procesos-estacionarios} y Sección \ref{efecto-variog-kriging}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model    psill    range
## 1   Nug 1.095133  0.00000
## 2   Sph 3.044034 63.39438
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nugget }\OtherTok{\textless{}{-}}\NormalTok{ fit}\SpecialCharTok{$}\NormalTok{psill[}\DecValTok{1}\NormalTok{]}
\NormalTok{sill }\OtherTok{\textless{}{-}}\NormalTok{ nugget }\SpecialCharTok{+}\NormalTok{ fit}\SpecialCharTok{$}\NormalTok{psill[}\DecValTok{2}\NormalTok{]}
\NormalTok{range }\OtherTok{\textless{}{-}}\NormalTok{ fit}\SpecialCharTok{$}\NormalTok{range[}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

NOTA: Cuidado, en el caso de un variograma exponencial, el parámetro que aparece como \texttt{range} es un parámetro de escala proporcional al verdadero rango práctico (tres veces ese valor).

Si quisiésemos comparar el ajuste de distintos modelos se podría considerar el valor mínimo de la función objetivo WLS, almacenado como un atributo del resultado (aunque la recomendación sería emplear validación cruzada):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{attr}\NormalTok{(fit, }\StringTok{"SSErr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.424426
\end{verbatim}

En cualquier caso la recomendación es analizar gráficamente el ajuste de los modelos.
Para representar las estimaciones empíricas junto con un único ajuste, se
podría emplear \texttt{plot.gstatVariogram()}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Cuidado con plot.variogramModel() si se pretende añadir elementos}
\CommentTok{\# plot(fit, cutoff = maxlag, ylim = c(0, 4.5))}
\CommentTok{\# with(vario,  points(dist, gamma))}
\FunctionTok{plot}\NormalTok{(vario, fit)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-12-1} \end{center}

Para añadir más elementos mejor hacerlo ``a mano'':

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(vario}\SpecialCharTok{$}\NormalTok{dist, vario}\SpecialCharTok{$}\NormalTok{gamma, }\AttributeTok{xlab =} \StringTok{"distance"}\NormalTok{, }\AttributeTok{ylab =}  \StringTok{"semivariance"}\NormalTok{, }
     \AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{max}\NormalTok{(range}\SpecialCharTok{*}\FloatTok{1.1}\NormalTok{, maxlag)), }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, sill}\SpecialCharTok{*}\FloatTok{1.1}\NormalTok{))}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{variogramLine}\NormalTok{(fit, }\AttributeTok{maxdist =} \FunctionTok{max}\NormalTok{(range}\SpecialCharTok{*}\FloatTok{1.1}\NormalTok{, maxlag)))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \DecValTok{0}\NormalTok{, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ range, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ nugget, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ sill, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-13-1} \end{center}

\hypertarget{predicciuxf3n-espacial-ku}{%
\section{Predicción espacial (KU)}\label{predicciuxf3n-espacial-ku}}

Para generar la rejilla de predicción consideramos un buffer de radio 40 en torno a las posiciones espaciales:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{buffer }\OtherTok{\textless{}{-}}\NormalTok{ aquifer\_sf }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{st\_geometry}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{st\_buffer}\NormalTok{(}\DecValTok{40}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

En lugar de emplear una rejilla \texttt{sf}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# grid \textless{}{-} buffer \%\textgreater{}\% st\_make\_grid(n = c(50, 50), what = "centers") \%\textgreater{}\% st\_intersection(buffer)}
\end{Highlighting}
\end{Shaded}

por comodidad es preferible emplear una rejilla \texttt{stars}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(stars)}
\NormalTok{grid }\OtherTok{\textless{}{-}}\NormalTok{ buffer }\SpecialCharTok{\%\textgreater{}\%}  \FunctionTok{st\_as\_stars}\NormalTok{(}\AttributeTok{nx =} \DecValTok{50}\NormalTok{, }\AttributeTok{ny =} \DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Si suponemos un modelo (no constante) para la tendencia, es necesario añadir los valores de las variables explicativas a la rejilla de predicción:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coord }\OtherTok{\textless{}{-}} \FunctionTok{st\_coordinates}\NormalTok{(grid)}
\NormalTok{grid}\SpecialCharTok{$}\NormalTok{lon }\OtherTok{\textless{}{-}}\NormalTok{ coord}\SpecialCharTok{$}\NormalTok{x}
\NormalTok{grid}\SpecialCharTok{$}\NormalTok{lat }\OtherTok{\textless{}{-}}\NormalTok{ coord}\SpecialCharTok{$}\NormalTok{y}
\end{Highlighting}
\end{Shaded}

Además, en este caso recortamos la rejilla para filtrar predicciones alejadas de las observaciones:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid }\OtherTok{\textless{}{-}}\NormalTok{ grid }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{st\_crop}\NormalTok{(buffer)}
\end{Highlighting}
\end{Shaded}

Obtenemos las predicciones mediante kriging universal (Sección \ref{kuniversal} y Sección \ref{kriging-gstat}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ head }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lon }\SpecialCharTok{+}\NormalTok{ lat, }\AttributeTok{locations =}\NormalTok{ aquifer\_sf, }\AttributeTok{model =}\NormalTok{ fit,}
              \AttributeTok{newdata =}\NormalTok{ grid)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [using universal kriging]
\end{verbatim}

\textbf{\emph{ERROR en krige}}: cambia las coordenadas del objeto stars

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{st\_coordinates}\NormalTok{(grid))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        x                 y         
##  Min.   :-181.86   Min.   :-28.03  
##  1st Qu.:-100.73   1st Qu.: 33.25  
##  Median : -16.22   Median : 97.09  
##  Mean   : -16.22   Mean   : 97.09  
##  3rd Qu.:  68.29   3rd Qu.:160.93  
##  Max.   : 149.42   Max.   :222.21
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{st\_coordinates}\NormalTok{(pred))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        x                 y         
##  Min.   :-181.86   Min.   : 53.83  
##  1st Qu.:-100.73   1st Qu.:115.11  
##  Median : -16.22   Median :178.95  
##  Mean   : -16.22   Mean   :178.95  
##  3rd Qu.:  68.29   3rd Qu.:242.79  
##  Max.   : 149.42   Max.   :304.08
\end{verbatim}

Posible solución: añadir el resultado a \texttt{grid}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid}\SpecialCharTok{$}\NormalTok{var1.pred }\OtherTok{\textless{}{-}}\NormalTok{ pred}\SpecialCharTok{$}\NormalTok{var1.pred}
\NormalTok{grid}\SpecialCharTok{$}\NormalTok{var1.var }\OtherTok{\textless{}{-}}\NormalTok{ pred}\SpecialCharTok{$}\NormalTok{var1.var}
\end{Highlighting}
\end{Shaded}

Finalmente representamos las predicciones y las varianzas kriging:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(grid[}\StringTok{"var1.pred"}\NormalTok{], }\AttributeTok{breaks =} \StringTok{"equal"}\NormalTok{, }\AttributeTok{col =} \FunctionTok{sf.colors}\NormalTok{(}\DecValTok{64}\NormalTok{), }\AttributeTok{key.pos =} \DecValTok{4}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Predicciones kriging"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-22-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(grid[}\StringTok{"var1.var"}\NormalTok{], }\AttributeTok{breaks =} \StringTok{"equal"}\NormalTok{, }\AttributeTok{col =} \FunctionTok{sf.colors}\NormalTok{(}\DecValTok{64}\NormalTok{), }\AttributeTok{key.pos =} \DecValTok{4}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Varianzas kriging"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-22-2} \end{center}

También podríamos emplear el paquete \texttt{ggplot2}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(gridExtra)}
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{geom\_stars}\NormalTok{(}\AttributeTok{data =}\NormalTok{ grid, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ var1.pred, }\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
    \FunctionTok{scale\_fill\_viridis\_c}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{data =}\NormalTok{ aquifer\_sf) }\SpecialCharTok{+}
    \FunctionTok{coord\_sf}\NormalTok{(}\AttributeTok{lims\_method =} \StringTok{"geometry\_bbox"}\NormalTok{)}
\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{geom\_stars}\NormalTok{(}\AttributeTok{data =}\NormalTok{ grid, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ var1.var, }\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
    \FunctionTok{scale\_fill\_viridis\_c}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{data =}\NormalTok{ aquifer\_sf) }\SpecialCharTok{+}
    \FunctionTok{coord\_sf}\NormalTok{(}\AttributeTok{lims\_method =} \StringTok{"geometry\_bbox"}\NormalTok{)}
\FunctionTok{grid.arrange}\NormalTok{(p1, p2, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=1\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-23-1} \end{center}

\hypertarget{validaciuxf3n-cruzada-1}{%
\section{Validación cruzada}\label{validaciuxf3n-cruzada-1}}

Para realizar una diagnosis del modelo de tendencia y variograma (y para seleccionar parámetros o comparar modelos) podemos emplear la técnica de validación cruzada Sección \ref{validacion-cruzada}, mediante la función \texttt{krige.cv()}.

Por defecto emplea LOOCV y puede requerir de mucho tiempo de computación (no está implementado eficientemente en \texttt{gtsat}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{system.time}\NormalTok{(cv }\OtherTok{\textless{}{-}} \FunctionTok{krige.cv}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ head }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lon }\SpecialCharTok{+}\NormalTok{ lat, }\AttributeTok{locations =}\NormalTok{ aquifer\_sf,}
                           \AttributeTok{model =}\NormalTok{ fit))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    user  system elapsed 
##    0.86    0.08    0.94
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(cv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Classes 'sf' and 'data.frame':   85 obs. of  7 variables:
##  $ var1.pred: num  15 23.5 22.9 24.6 17 ...
##  $ var1.var : num  3.08 2.85 2.32 2.81 2.05 ...
##  $ observed : num  14.6 25.5 21.6 24.6 17.6 ...
##  $ residual : num  -0.3357 1.9962 -1.3101 -0.0792 0.5478 ...
##  $ zscore   : num  -0.1914 1.1821 -0.8608 -0.0472 0.3829 ...
##  $ fold     : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ geometry :sfc_POINT of length 85; first list element:  'XY' num  42.8 127.6
##  - attr(*, "sf_column")= chr "geometry"
##  - attr(*, "agr")= Factor w/ 3 levels "constant","aggregate",..: NA NA NA NA NA NA
##   ..- attr(*, "names")= chr [1:6] "var1.pred" "var1.var" "observed" "residual" ...
\end{verbatim}

Si el número de observaciones es grande puede ser preferible emplear k-fold CV (y como la partición en grupos es aleatoria se recomendaría fijar previamente la semilla de aleatorización):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\FunctionTok{system.time}\NormalTok{(cv }\OtherTok{\textless{}{-}} \FunctionTok{krige.cv}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ head }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lon }\SpecialCharTok{+}\NormalTok{ lat, }\AttributeTok{locations =}\NormalTok{ aquifer\_sf,}
                           \AttributeTok{model =}\NormalTok{ fit, }\AttributeTok{nfold =} \DecValTok{10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    user  system elapsed 
##    0.14    0.02    0.16
\end{verbatim}

Para seleccionar modelos podemos considerar distintas medidas, implementadas en la siguiente función:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary\_cv }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cv.data, }\AttributeTok{na.rm =} \ConstantTok{FALSE}\NormalTok{,}
                       \AttributeTok{tol =} \FunctionTok{sqrt}\NormalTok{(.Machine}\SpecialCharTok{$}\NormalTok{double.eps)) \{}
\NormalTok{  err }\OtherTok{\textless{}{-}}\NormalTok{ cv.data}\SpecialCharTok{$}\NormalTok{residual      }\CommentTok{\# Errores}
\NormalTok{  obs }\OtherTok{\textless{}{-}}\NormalTok{ cv.data}\SpecialCharTok{$}\NormalTok{observed}
\NormalTok{  z }\OtherTok{\textless{}{-}}\NormalTok{ cv.data}\SpecialCharTok{$}\NormalTok{zscore}
\NormalTok{  w }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{/}\FunctionTok{pmax}\NormalTok{(cv.data}\SpecialCharTok{$}\NormalTok{var1.var, tol) }\CommentTok{\# Ponderación según varianza kriging}
  \ControlFlowTok{if}\NormalTok{(na.rm) \{}
\NormalTok{    is.a }\OtherTok{\textless{}{-}} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(err)}
\NormalTok{    err }\OtherTok{\textless{}{-}}\NormalTok{ err[is.a]}
\NormalTok{    obs }\OtherTok{\textless{}{-}}\NormalTok{ obs[is.a]}
\NormalTok{    z }\OtherTok{\textless{}{-}}\NormalTok{ z[is.a]}
\NormalTok{    w }\OtherTok{\textless{}{-}}\NormalTok{ w[is.a]}
\NormalTok{  \}}
\NormalTok{  perr }\OtherTok{\textless{}{-}} \DecValTok{100}\SpecialCharTok{*}\NormalTok{err}\SpecialCharTok{/}\FunctionTok{pmax}\NormalTok{(obs, tol)  }\CommentTok{\# Errores porcentuales}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
    \CommentTok{\# Medidas de error tradicionales}
    \AttributeTok{me =} \FunctionTok{mean}\NormalTok{(err),           }\CommentTok{\# Error medio}
    \AttributeTok{rmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)), }\CommentTok{\# Raíz del error cuadrático medio}
    \AttributeTok{mae =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(err)),     }\CommentTok{\# Error absoluto medio}
    \AttributeTok{mpe =} \FunctionTok{mean}\NormalTok{(perr),         }\CommentTok{\# Error porcentual medio}
    \AttributeTok{mape =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(perr)),   }\CommentTok{\# Error porcentual absoluto medio}
    \AttributeTok{r.squared =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{((obs }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(obs))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{), }\CommentTok{\# Pseudo R{-}cuadrado}
    \CommentTok{\# Medidas de error que tienen en cuenta la varianza kriging}
    \AttributeTok{dme =} \FunctionTok{mean}\NormalTok{(z),            }\CommentTok{\# Error estandarizado medio}
    \AttributeTok{dmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(z}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)),    }\CommentTok{\# Error cuadrático medio adimensional}
    \AttributeTok{rwmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{weighted.mean}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, w)) }\CommentTok{\# Raíz del ECM ponderado}
\NormalTok{  ))}
\NormalTok{\}}

\FunctionTok{summary\_cv}\NormalTok{(cv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           me         rmse          mae          mpe         mape    r.squared 
##  0.058039856  1.788446500  1.407874022 -0.615720059  7.852363328  0.913398424 
##          dme         dmse        rwmse 
##  0.001337332  1.118978878  1.665958815
\end{verbatim}

Las tres últimas medidas tienen en cuenta la estimación de la varianza kriging.
El valor del error cuadrático medio adimensional debería ser próximo a 1 si hay concordancia entre las varianzas kriging y las varianzas observadas.

Para detectar datos atípicos, o problemas con el modelo, podemos generar distintos gráficos.
Por ejemplo, gráficos de dispersión de valores observados o residuos estándarizados frente a predicciones:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{old\_par }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(observed }\SpecialCharTok{\textasciitilde{}}\NormalTok{ var1.pred, }\AttributeTok{data =}\NormalTok{ cv, }\AttributeTok{xlab =} \StringTok{"Predicción"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Observado"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{a =} \DecValTok{0}\NormalTok{, }\AttributeTok{b =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(zscore }\SpecialCharTok{\textasciitilde{}}\NormalTok{ var1.pred, }\AttributeTok{data =}\NormalTok{ cv, }\AttributeTok{xlab =} \StringTok{"Predicción"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Residuo estandarizado"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{), }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=1\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-27-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(old\_par)}
\end{Highlighting}
\end{Shaded}

Gráficos con la distribución espacial de los residuos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(cv[}\StringTok{"residual"}\NormalTok{], }\AttributeTok{pch =} \DecValTok{20}\NormalTok{, }\AttributeTok{cex =} \DecValTok{2}\NormalTok{, }\AttributeTok{breaks =} \StringTok{"quantile"}\NormalTok{, }\AttributeTok{nbreaks =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-28-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(cv[}\StringTok{"zscore"}\NormalTok{], }\AttributeTok{pch =} \DecValTok{20}\NormalTok{, }\AttributeTok{cex =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-28-2} \end{center}

Además de los gráficos estándar para analizar la distribución de los residuos estandarizados o detectar atípicos:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Histograma}
\NormalTok{old\_par }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\FunctionTok{hist}\NormalTok{(cv}\SpecialCharTok{$}\NormalTok{zscore, }\AttributeTok{freq =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{density}\NormalTok{(cv}\SpecialCharTok{$}\NormalTok{zscore), }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{)}
\CommentTok{\# Gráfico de normalidad}
\FunctionTok{qqnorm}\NormalTok{(cv}\SpecialCharTok{$}\NormalTok{zscore)}
\FunctionTok{qqline}\NormalTok{(cv}\SpecialCharTok{$}\NormalTok{zscore, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{)}
\CommentTok{\# Boxplot}
\NormalTok{car}\SpecialCharTok{::}\FunctionTok{Boxplot}\NormalTok{(cv}\SpecialCharTok{$}\NormalTok{zscore, }\AttributeTok{ylab =} \StringTok{"Residuos estandarizados"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=1\linewidth]{14-ejemplo_aquifer_files/figure-latex/unnamed-chunk-29-1} \end{center}

\begin{verbatim}
## [1] 78
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(old\_par)}
\end{Highlighting}
\end{Shaded}

\hypertarget{referencias}{%
\chapter{Referencias}\label{referencias}}

\textbf{Bibliografía básica}

Bivand, R.S., Pebesma, E.J. y Gómez-Rubio, V. (2008). \emph{Applied Spatial Data Analysis with R}. Springer.

Diggle, P. y Ribeiro, P.J. (2007). \emph{Model-based Geostatistics}. Springer.

Schabenberger, O. y Gotway, C.A. (2005). \emph{Statistical Methods for Spatial Data Analysis}. Chapman and Hall.

\textbf{Bibliografía complementaria}

Chilès, J.P. y P. Delfiner (2012). \emph{Geostatistics: modeling spatial uncertanity}. Wiley.

Cressie, N. (1993). \emph{Statistics for Spatial Data}. John Wiley.

Wikle, C.K., Zammit-Mangion, A. y Cressie, N. (2019). \emph{Spatio-temporal Statistics with R}. Chapman and Hall/CRC (accesible \href{https://spacetimewithr.org}{online}).

\hypertarget{links}{%
\section{Enlaces}\label{links}}

\textbf{\emph{Repositorio}}: \href{https://github.com/rubenfcasal/simbook}{rubenfcasal/simbook}

\textbf{Recursos para el aprendizaje de R}: En este \href{https://rubenfcasal.github.io/post/ayuda-y-recursos-para-el-aprendizaje-de-r}{post} se muestran algunos recursos que pueden ser útiles para el aprendizaje de R y la obtención de ayuda.

Ayuda online:

\begin{itemize}
\item
  Ayuda en línea sobre funciones o paquetes: \href{https://rdrr.io/}{rdrr.io}, \href{https://www.rdocumentation.org/}{RDocumentation}
\item
  Buscador \href{http://rseek.org/}{RSeek}
\item
  \href{http://stackoverflow.com/questions/tagged/r}{StackOverflow}, \href{https://es.stackoverflow.com/questions/tagged/r}{en castellano}
\item
  \href{https://stats.stackexchange.com}{Cross Validated}
\end{itemize}

En \href{https://bookdown.org}{\textbf{\emph{bookdown}}} está disponible una selección de libros escritos con este paquete:

\begin{itemize}
\item
  Grolemund, G. (2014). \emph{\href{https://rstudio-education.github.io/hopr}{Hands-on programming with R: Write your own functions and simulations}}, \href{http://shop.oreilly.com/product/0636920028574.do}{O'Reilly}.
\item
  Lovelace, R., Nowosad, J., y Muenchow, J. (2019). \emph{\href{https://geocompr.robinlovelace.net}{Geocomputation with R}}, \href{https://www.routledge.com/9781138304512}{CRC}.
\item
  Pebesma, E., y Bivand, R. (2021). \emph{\href{https://r-spatial.org/book}{Spatial Data Science}}.
\item
  Wickham, H. (2015). \emph{\href{http://r-pkgs.had.co.nz/}{R packages: organize, test, document, and share your code}} (actualmente 2ª edición en desarrollo con H. Bryan), \href{http://shop.oreilly.com/product/0636920034421.do}{O'Reilly, 1ª edición}.
\item
  Wickham, H. (2019). \emph{\href{https://adv-r.hadley.nz/}{Advanced R, 2ª edición}}, \href{https://www.amazon.com/dp/0815384572}{Chapman \& Hall}, \href{http://adv-r.had.co.nz/}{1ª edición.}.
\item
  Wickham, H., y Grolemund, G. (2016). \emph{\href{http://r4ds.had.co.nz}{R for data science: import, tidy, transform, visualize, and model data}}, \href{https://es.r4ds.hadley.nz}{online-castellano}, \href{http://shop.oreilly.com/product/0636920034407.do}{O'Reilly}.
\end{itemize}

En el \href{(https://bookdown.org/home/archive/)}{listado completo} se incluyen algunos en castellano:

\begin{itemize}
\item
  Fernández-Casal R. y Cao R. (2022). \emph{\href{https://rubenfcasal.github.io/simbook}{Simulación Estadística}}, \href{https://github.com/rubenfcasal/simbook}{github}, \href{https://rubenfcasal.github.io/simbook2}{segunda edición} (en proceso de elaboración).
\item
  Fernández-Casal R., Costa J. y Oviedo M. (2022). \emph{\href{https://rubenfcasal.github.io/aprendizaje_estadistico}{Aprendizaje Estadístico}}, \href{https://github.com/rubenfcasal/aprendizaje_estadistico}{github}.
\item
  Fernández-Casal R. y Cotos-Yáñez T.R. (2018). \emph{\href{https://rubenfcasal.github.io/bookdown_intro}{Escritura de libros con bookdown}}, \href{https://github.com/rubenfcasal/bookdown_intro}{github}. Incluye un apéndice con una \href{https://rubenfcasal.github.io/bookdown_intro/rmarkdown.html}{Introducción a RMarkdown}.
\item
  Gil Bellosta, C.J. (2018). \emph{\href{https://www.datanalytics.com/libro_r}{R para profesionales de los datos: una introducción}}.
\end{itemize}

Para referencias adicionales ver el libro:

\begin{itemize}
\tightlist
\item
  Baruffa, O. (2022). \emph{\href{https://www.bigbookofr.com}{Big Book of R}}: Your last-ever bookmark (hopefully\ldots).
\end{itemize}

\hypertarget{bibliografuxeda-completa}{%
\section{Bibliografía completa}\label{bibliografuxeda-completa}}

\textbf{\emph{Work in progress\ldots{}}}

El listado completo de libros y artículos se incluirá aquí\ldots{}

Tobler, W. (1970). A computer movie simulating urban growth in the Detroit region. \emph{Economic Geography}, \textbf{46}, 234-240.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\hypertarget{ref-Bivand2013}{}%
Bivand, R. S., Pebesma, E., y Gómez-Rubio, V. (2013). \emph{Applied Spatial Data Analysis with {R}} (Second). Springer. \url{http://www.asdar-book.org/}

\leavevmode\hypertarget{ref-Pebesma2018}{}%
Pebesma, E. (2018). {Simple Features for R: Standardized Support for Spatial Vector Data}. \emph{{The R Journal}}, \emph{10}(1), 439-446. \url{https://doi.org/10.32614/RJ-2018-009}

\leavevmode\hypertarget{ref-Pebesma2021}{}%
Pebesma, E., y Bivand, R. (2021). \emph{Spatial Data Science}. \url{https://keen-swartz-3146c4.netlify.app}

\leavevmode\hypertarget{ref-Pebesma2005}{}%
Pebesma, E. J., y Bivand, R. S. (2005). Classes and methods for spatial data in {R}. \emph{R News}, \emph{5}(2), 9-13. \url{https://CRAN.R-project.org/doc/Rnews/}

\end{CSLReferences}

\end{document}
